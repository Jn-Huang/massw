{"id": "01f161fe-dd40-45dd-89bd-fb1562771d73", "Context": "Capturing contextual information within event forecasting is challenging due to several factors: (i) uncertainty of context structure and formulation, (ii) high dimensional features, and (iii) adaptation of features over time.", "Key Idea": "The authors propose a novel graph convolutional network for predicting future social events by extracting and learning graph representations from historical/prior event documents.", "Method": "The authors employ a graph convolutional network to predict future events and identify sequences of dynamic graphs as event context. They extract and learn graph representations from historical/prior event documents.", "Outcome": "Experimental results on multiple real-world data sets show that the proposed method is competitive against various state-of-the-art methods for social event prediction.", "Future Impact": "The proposed method could be beneficial in real-world applications such as automated analysis generation and resource allocation as it captures dynamic properties of event contexts as social indicators."}
{"id": "0b31e456-4944-47e5-80ed-deaf6421c375", "Context": "The paper proposes a tool, Directed Dialogue Protocols (DDPs) for interface design based on Katou0027s (1986) method of verbal data collection by question-asking protocols.", "Key Idea": "The paper proposes three extensions to the question-asking method: atomic tasks, interventions by the experimenter, and sequential disclosure to improve the process of verbal data collection.", "Method": "The paper discusses the design and application of the tool, DDPs. The method was applied to identify design choices that improve learnability and usability into a productu0027s user-interface.", "Outcome": "The paper doesn't present any measurable outcomes of this study but discusses the identified design choices that improve learnability and usability into a productu0027s user-interface. ", "Future Impact": "The method proposed in this paper can impact future studies in human-computer interaction and design that could utilize DDPs as a tool for facilitating the quantization of verbal data and improving the design of learnable and usable interfaces."}
{"id": "07c3daea-a88c-4a67-9aac-20ef0ec62e79", "Context": "Non-pharmacological interventions are the most common and the most effective for people with dementia. Using biographical or personalized materials has been proven to benefit these interventions, but it can be challenging to obtain and maintain such information.", "Key Idea": "The authors propose a web platform to collect and manage biographical materials in a streamlined manner, enabling reminiscence and other biographical cognitive stimulation practices for people with dementia.", "Method": "The authors conducted a case study with one psychologist and three patients across two weeks. The patients' data were collected using the web platform, and the impact of the therapy was measured.", "Outcome": "The web platform improved the collection of meaningful data about the patients, and the therapy's overall awareness was maintained. The study showed improvements in the collection of patient data and maintenance of the therapy's overall awareness.", "Future Impact": "The proposed platform could be extended to open new horizons in biographical cognitive interventions and personalized treatments for people with dementia."}
{"id": "081d6673-3c7c-4aec-b101-cf55d75ac718", "Context": "Previous partial permutation synchronization algorithms are often computationally intensive and memory-demanding.", "Key Idea": "The authors propose an improved algorithm, CEMP-Partial, for estimating the corruption levels of the observed partial permutations, and subsequently propose MatchFAME, a fast, accurate, and memory-efficient matching algorithm based on sparse matrix operations.", "Method": "The authors prove the CEMP-Partial algorithm's ability to classify corrupted and clean partial permutations. The authors also demonstrate the accuracy, speed, and memory efficiency of MatchFAME on synthetic and real datasets.", "Outcome": "MatchFAME shows state-of-the-art accuracy, speed, and memory efficiency compared to previous PPS algorithms and is able to classify corrupted and clean partial permutations under certain assumptions.", "Future Impact": "The improved algorithm and resulting matching algorithm may enable more efficient and accurate multi-object matching for large-scale structure-from-motion datasets."}
{"id": "14b0ebd1-b654-4eed-bdd8-ebeb74250b15", "Context": "In the few-shot relational triple extraction (FS-RTE), one extracts relational triples from plain texts by utilizing only few annotated samples. The entity-then-relation paradigm, which first extracts all entities and then classifies their relations, ignores the entity discrepancy between relations.", "Key Idea": "The authors propose a novel task decomposition strategy, Relation-then- Entity, for FS-RTE and a model, RelATE to instantiate this strategy. RelATE builds a dual-level attention to aggregate relation-relevant information to detect the relation occurrence and utilizes the annotated samples of the detected relations to extract the corresponding head/tail entities.", "Method": "The authors experimentally show that RelATE outperforms previous work by an absolute gain (18.98%, 28.85% in F1 in two few-shot settings).", "Outcome": "RelATE outperforms previous models with an absolute improvement of 18.98% and 28.85% F1 scores.", "Future Impact": "N/A"}
{"id": "16c1b4ae-73f8-4c23-8bdb-b931ade1baa5", "Context": "Various tasks in decision making and decision support require selecting a preferred subset of items from a given set of feasible items based on individual attribute values.", "Key Idea": "The paper proposes to solve the problem of computing an optimal subset of items given a specified preference based on the attribute values of individual elements within the set.", "Method": "The paper presents two algorithm classes: direct set construction and implicit enumeration as solutions to appropriate CSPs. New algorithms for each class are presented and compared empirically against previous results.", "Outcome": "The problem is shown to be NP-hard in the general case, and the proposed heuristic search methods modelled as CSPs perform better than previous approaches.", "Future Impact": "The new algorithms proposed in this paper could provide a foundation for solving more complex decision-making problems with conflicting preferences. "}
{"id": "10c15fe5-c315-4b6d-8910-e6bc3279c817", "Context": "Social event detection in an incremental learning setting, where acquiring, preserving, and extending knowledge are major concerns.", "Key Idea": "The authors propose a novel Knowledge-Preserving Incremental Heterogeneous Graph Neural Network (KPGNN) for incremental social event detection that explores the expressive power of GNNs for knowledge extraction and continuously adapts to incoming data by adopting contrastive loss terms.", "Method": "The authors use KPGNN for incremental social event detection, adopting contrastive loss terms that cope with a changing number of event classes in the inductive learning ability of GNNs to detect events and expand its knowledge from previously unseen data. They also adopt a mini-batch subgraph sampling strategy for scalable training and periodically remove obsolete data to maintain a dynamic embedding space.", "Outcome": "Extensive experiments demonstrate the superiority of KPGNN over various baselines.", "Future Impact": "The proposed KPGNN has the potential to improve applications in fields such as product recommendation and crisis management by providing valuable insights into group social behaviors and public concerns."}
{"id": "18f27ced-9f37-45d7-9b76-6663c349d408", "Context": "Cross-modal retrieval is a challenge where one type of data is used as a query to retrieve relevant data of another type. Existing approaches learn a common subspace in a joint manner, which requires all modalities to be involved in the training process.", "Key Idea": "The authors propose a novel cross-modal retrieval method called Scalable Deep Multimodal Learning (SDML) that trains modality-specific networks independently to transform multimodal data into a predefined common subspace.", "Method": "The authors train m modality-specific networks independently for m modalities and project the data into the predefined common subspace to achieve multimodal learning. The authors perform comprehensive experimental results on four benchmark datasets to demonstrate that SDML is effective and efficient.", "Outcome": "The proposed method (SDML) is effective and efficient in multimodal learning and outperforms the state-of-the-art methods in cross-modal retrieval on four benchmark datasets.", "Future Impact": "The proposed method could be useful in real-world applications, making cross-modal retrieval more scalable, efficient, and effective especially when handling samples from different modalities."}
{"id": "1b0e4045-d39b-4bea-8dec-e747f5c674f5", "Context": "Probabilistic databases have been developed to manage imprecise information inherent in applications such as sensor monitoring systems, location-based services, and biological databases.", "Key Idea": "The authors propose two efficient algorithms to discover frequent patterns and association rules from probabilistic data under the Possible World Semantics.", "Method": "The authors propose two algorithms that discover frequent patterns from probabilistic data in either top-down or bottom-up manners. The algorithms can also be extended to discover maximal frequent patterns. The authors conduct experiments on real and synthetic datasets to validate the performance of their proposed methods.", "Outcome": "The performance of the proposed methods is validated through extensive experiments conducted on real and synthetic datasets.", "Future Impact": "N/A"}
{"id": "1946f496-f6cd-4736-8c30-a6ae70baa8b2", "Context": "Existing click models treat intrinsic relevance as an atomic query-document-specific parameter, which is solely estimated from historical clicks without using any content information about a document or relationship among the clicked/skipped documents under the same query.", "Key Idea": "The authors propose a novel Bayesian Sequential State model for click modeling, where the document content and dependencies among the sequential click events within a query are characterized by a set of descriptive features via a probabilistic graphical model.", "Method": "The authors apply the posterior regularized Expectation Maximization algorithm for parameter learning and tailor the model to meet specific ranking-oriented properties, e.g., pairwise click preferences. Experiment results show that the proposed model is effective compared with state-of-the-art click models.", "Outcome": "The experimental results demonstrate that the proposed model is effective compared with state-of-the-art click models.", "Future Impact": "The proposed model may lead to the improvement of click models and better understanding of user-click behavior with richer information exploited from the user clicks."}
{"id": "1e396f93-a73e-4d33-9a8e-56097a8c3c28", "Context": "Deep learning has yielded state-of-the-art performance on many natural language processing tasks including named entity recognition (NER), but requires large amounts of labeled data.", "Key Idea": "Combining deep learning with active learning drastically reduces the amount of labeled training data required.", "Method": "The authors introduce a lightweight architecture called CNN-CNN-LSTM and carry out incremental active learning. The authors use standard datasets for the task.", "Outcome": "The proposed model achieves nearly state-of-the-art performance on standard datasets for NER while being computationally much more efficient.", "Future Impact": "The proposed approach of combining deep learning with active learning could potentially be applied to other NLP tasks and be used with different architectures for further improvement of the performance."}
{"id": "192f7803-df4d-40c0-b816-ba34339026b3", "Context": "Most current single image super-resolution (SR) methods use empirical risk minimisation, which often produces blurry and over-smoothed images. A more desirable approach would employ maximum a posteriori (MAP) inference, preferring solutions that always have a high probability under the image prior, making them appear more plausible.", "Key Idea": "The authors propose to use amortised MAP inference whereby they calculate the MAP estimate directly using a convolutional neural network to achieve plausible image outputs.", "Method": "The authors introduce a novel neural network architecture intended for the amortised MAP inference. They propose three methods to solve the optimisation problem, Generative Adversarial Networks (GAN), denoiser-guided SR, and a baseline method using a maximum-likelihood-trained image prior. The authors tested the proposed methods on real image data.", "Outcome": "The GAN-based approach outperformed the other two proposed methods when tested on real image data.", "Future Impact": "The amortised MAP inference method proposed in this study has potential use in a wide range of image-processing tasks beyond image super-resolution."}
{"id": "1dea5ec2-d311-4c03-bba5-e38d7a62fbd4", "Context": "The paper tackles the problem of spotting signs occurring in video sequences. The paper proposes to model spatio-temporal signatures of signs using an extension of sequential patterns that contain temporal intervals.", "Key Idea": "The authors proposed Sequential Interval Patterns (SIP) to model spatio-temporal signatures and a novel multi-class classifier called Hierarchical Sequential Pattern Tree (HSP-Tree) that organises different Sequential Interval Patterns in a hierarchical tree structure to enable exploration of any subsequence sharing that exists between SIPs of different classes.", "Method": "The authors evaluated the proposed method on both concatenated isolated sign sequences and continuous sign sequences and shows that the proposed method is superior in robustness and accuracy compared to state-of-the-art sign recognition approaches.", "Outcome": "The proposed method achieves superior robustness and accuracy compared to the state-of-the-art sign recognition approach.", "Future Impact": "N/A"}
{"id": "2a220303-8653-497f-b2b5-c829583c2714", "Context": "Counting and sampling directed acyclic graphs from a Markov equivalence class are fundamental tasks in graphical causal analysis.", "Key Idea": "The authors propose polynomial-time algorithms for counting and sampling directed acyclic graphs from a Markov equivalence class, solving a long-standing open problem in this area.", "Method": "The authors present effective and easily implementable algorithms. They conduct experiments to compare the performance of their method with that of state-of-the-art methods.", "Outcome": "The authors show that their algorithms significantly outperform state-of-the-art methods in terms of computational efficiency for counting and sampling directed acyclic graphs.", "Future Impact": "The proposed algorithms have practical implications for graphical causal analysis and can be applied to real-world datasets."}
{"id": "1ef9b762-e9be-46c5-ad19-090fe16200c4", "Context": "Paper addresses the issue of accurately deriving pointing information from a corresponding gesture in human-robot interaction.", "Key Idea": "The paper proposes a novel approach that fuses information from two different input streams, head pose estimated by visually tracking the face, and hand pointing orientation using Dempster-Shafer theory of evidence, to decide on the pointed object.", "Method": "The proposed approach tracks off-plane face rotations and hand pointing orientation to fuse information and estimate pointed targets.", "Outcome": "The method is validated experimentally and proven effective in realistic application setups.", "Future Impact": "The method could enhance the accuracy of pointed target identification in human-robot interaction setups and similar applications."}
{"id": "1e5571af-71cf-40b8-ba2a-18b42cae5b42", "Context": "The paper addresses knowledge-based sequence mining.", "Key Idea": "The authors introduce a new framework for knowledge-based sequence mining using Answer Set Programming (ASP), and show how preferred patterns of interest can be easily extracted.", "Method": "The authors demonstrate their framework using several modular extensions, and use ASP's preference handling capacities to mine patterns of interest with expert-declared importance. The authors also compare the effectiveness of their approach with a related sequence mining mechanism through empirical study.", "Outcome": "The paper demonstrates that the proposed approach can easily incorporate domain-specific knowledge in the form of preferred patterns, which is effective in real-world sequence mining tasks.", "Future Impact": "The proposed knowledge-based sequence mining framework can contribute to the development of more intelligent pattern mining algorithms and systems. Future research might explore improving the scalability and efficiency of the approach."}
{"id": "24e29617-a320-450a-aaa5-19d8700d74b7", "Context": "Matrix completion has been a crucial problem in machine learning and involves filling in missing values in a given matrix. Existing synchronous algorithms have not been efficient in solving this problem.", "Key Idea": "The authors proposed NOMAD, a non-locking and asynchronous decentralized algorithm with non-blocking communication between processors for matrix completion. One key feature of the algorithm is that it is lock-free and ownership of a variable is asynchronously transferred between processors.", "Method": "The authors' method is an extensive empirical evaluation that shows NOMAD's superior performance to existing synchronous algorithms on commodity hardware and HPC cluster both in multi-core and distributed memory scenarios.", "Outcome": "NOMAD outperforms synchronous algorithms in both commodity hardware and HPC cluster. NOMAD's variable updates are serializable despite being asynchronously updated.", "Future Impact": "N/A"}
{"id": "206d2d53-dbaf-4a2f-810d-856309d8eb83", "Context": "The paper proposes a neural head reenactment system.", "Key Idea": "The system is driven by a latent pose representation learned solely on image reconstruction losses, which can successfully decompose pose from identity and perform cross-person reenactment.", "Method": "The authors show the effectiveness of the proposed system by predicting the foreground segmentation and reproducing mimics of the driving person. The authors also demonstrate that the learned descriptors are useful for keypoint prediction and pose-based retrieval.", "Outcome": "The proposed system successfully predicts the foreground segmentation and can perform cross-person reenactment. The learned descriptors are useful for keypoint prediction and pose-based retrieval.", "Future Impact": "The proposed system has potential applications in the fields of computer vision and graphics, such as entertainment, video communication, and virtual reality."}
{"id": "2065b977-7782-4981-ad70-3121a2315687", "Context": "The authors propose a correlated bigram LSA approach for unsupervised LM adaptation for automatic speech recognition.", "Key Idea": "The authors integrate unigram and bigram LSA into the N-gram LM via marginal adaptation and linear interpolation respectively, achieving improved results on both the Mandarin RT04 test set and the large-scale evaluation on Arabic.", "Method": "The model is trained using variational EM and fractional Kneser-Ney smoothing is proposed to handle fractional counts. Bootstrapping of bigram LSA from unigram LSA is used to address scalability issues.", "Outcome": "The proposed approach yields a 6%-8% relative perplexity reduction and 2.5% relative character error rate reduction compared to applying only unigram LSA on the Mandarin RT04 test set. A 3% relative word error rate reduction is achieved on the large-scale evaluation on Arabic.", "Future Impact": "N/A"}
{"id": "36d7073a-d006-4a4a-850f-ca7a3f0ca19b", "Context": "Many important problems can be framed as learning from graph data. Previous methods either do not scale well or lack expressivity.", "Key Idea": "The authors propose a framework for learning convolutional neural networks for arbitrary graphs, regardless of whether they are directed or undirected and have discrete or continuous node and edge attributes. The authors present a general approach to extracting locally connected regions from graphs.", "Method": "The authors demonstrate the effectiveness and efficiency of the proposed method compared to previous methods, using established benchmark datasets.", "Outcome": "The learned feature representations are competitive with state-of-the-art graph kernels, and their computation is highly efficient.", "Future Impact": "The proposed framework has the potential to advance the state of the art in learning from graph data, enabling the development of deep learning models for graph data that are scalable and expressive. It may also find applications in various fields, such as social network analysis and drug discovery."}
{"id": "2eb66e5a-472c-4db1-b02f-47fe5eb7e71e", "Context": "The proposed model does not need semantic information such as paraphrase pairs or syntactic information such as constituency parses. The proposed model relies solely on the inductive bias found in attention-based architectures such as Transformers.", "Key Idea": "The authors propose QKVAE, a generative model that exhibits disentangled latent representations of syntax and semantics using a decoder that reads latent variables where one variable infers keys and another infers values.", "Method": "The authors run experiments on latent representations and syntax/semantics transfer to validate QKVAE's disentangled syntax and semantics. The authors compare QKVAE's syntax transfer capabilities to supervised models and evaluate the amount of data required for comparable supervised models to outperform QKVAE.", "Outcome": "QKVAE displays clear signs of disentangled syntax and semantics according to experiments on latent representations and syntax/semantics transfer. QKVAE displays competitive syntax transfer capabilities compared to supervised models with less data.", "Future Impact": "The proposed model could potentially be applied to solving related unsupervised NLP tasks, such as multilingual text generation and dialogue generation."}
{"id": "37da719b-8db9-4523-8a4a-3f2eef238978", "Context": "The paper deals with image watermarking and recovery of tampered images.", "Key Idea": "The key idea is to use a fragile watermarking with self-embedding scheme that does not use authentication bits. The authors propose a spread spectrum-based watermarking scheme using block-based embedding and DCT-based compression.", "Method": "The authors propose a fragile watermarking scheme using self-embedding. The watermark is embedded in the blocks of an image using DCT-based compression. The authors use simulation to test the effectiveness of the proposed method.", "Outcome": "The simulation results demonstrate that the proposed method provides good recovery performance.", "Future Impact": "The proposed method could be applied in other multimedia fields to protect intellectual property, such as video and audio watermarking."}
{"id": "29dd9fd3-6c98-4e4b-b70c-0474ff361419", "Context": "Building a deformable shape model for a new species requires 3D data. The accurate shape model is not available for birds despite being a species with almost double the number of species as mammals.", "Key Idea": "The authors propose a method to capture new bird species using an articulated template and images of that species.", "Method": "The authors fit the articulated template to each training sample to disentangle pose and shape and learn a shape space that captures variation among and within bird species from image evidence. The authors learn models of multiple bird species from the CUB dataset and contribute new species-specific and multi-species shape models.", "Outcome": "The authors show that their learned 3D shape space better reflects the phylogenetic relationships among birds than learned perceptual features through the use of a low-dimensional embedding.", "Future Impact": "The proposed method can be extended to capture shape models of other animal species beyond birds using articulated templates and images, facilitating downstream reconstruction tasks. The learned 3D shape space can also be used in downstream computer vision tasks."}
{"id": "370141c7-e1bb-4010-9938-efcad6cf2e62", "Context": "Innovations in neural architectures have fostered significant breakthroughs in language modeling and computer vision. Novel architectures often result in challenging hyper-parameter choices and training instability if the network parameters are not properly initialized. A number of architecture-specific initialization schemes have been proposed.", "Key Idea": "The authors propose GradInit, an automated and architecture agnostic method for initializing neural networks using a simple scalar multiplier to adjust the layer norms to improve convergence and test performance.", "Method": "The authors apply GradInit to many convolutional architectures, including architectures without normalization layers, and the original Transformer architecture for machine translation. The authors optimize the scalar multiplier using a simple numerical scheme.", "Outcome": "GradInit improves the convergence and test performance of many convolutional architectures and improves the stability of the original Transformer architecture for machine translation.", "Future Impact": "GradInit offers an automated and architecture-agnostic approach for initializing neural networks, which could improve the stability and convergence of various neural architectures in the future. GradInit could become a standard method for initializing neural networks, as it does not depend on architecture-specific initialization schemes."}
{"id": "31ab88b5-e66f-4b69-98b6-7a470dce9875", "Context": "Conditional neural networks play an important role in sequence-to-sequence modeling tasks. In conditional neural networks, the output of a model is often influenced by a conditioning vector, in addition to the input.", "Key Idea": "The authors propose a novel approach of neural network conditioning by learning intermediate layer activations based on the conditioning vector to eliminate the cost of the increased model size.", "Method": "The authors explore the proposed approach and show that learned activation functions can produce models with comparable or better quality, while decreasing model sizes. The authors evaluate the approach on the personalized sound enhancement and personalized ASR tasks.", "Outcome": "The authors find that conditioning via activation function learning is an effective modeling strategy. The proposed approach produces conditional models with comparable or better quality while decreasing the model size, making them ideal candidates for on-device deployment.", "Future Impact": "The proposed approach can reduce computational costs and memory footprints for conditional neural network models, making them more feasible for deployment on devices with limited resources."}
{"id": "3ac464c2-2214-4bf2-a6b6-03da2498cb03", "Context": "Query scheduling is a fundamental problem in database management systems and has received renewed attention due to the rise of the Database as a Service (DaaS) model. Researchers have focused on different scheduling algorithms, but little is known about what information these algorithms should know about the queries to be scheduled.", "Key Idea": "The authors investigate using histograms describing the distribution of likely query execution times as input to the query scheduler and propose a novel distribution-based scheduling algorithm called Shepherd.", "Method": "The authors compare the proposed Shepherd algorithm with state-of-the-art point-based methods through extensive experimentation with synthetic and TPC workloads.", "Outcome": "The authors show that the proposed Shepherd algorithm substantially outperforms state-of-the-art point-based methods.", "Future Impact": "The proposed approach can improve query scheduling algorithms and can be explored in more complex distributed environments like cloud-based deployments."}
{"id": "2b5cc037-4841-4fb1-85ff-673230198be1", "Context": "This paper focuses on the problem of recovering a life-long incomplete m x n matrix of rank r with columns arriving online over time. The matrix completion problem is widely applied to various domains including recommendation systems, computer vision, and system identification. Prior works have considered the noise-free case, but designing provable algorithms under realistic noise models is a challenge.", "Key Idea": "The authors propose algorithms for life-long matrix completion that are tolerant to two different realistic noise models: bounded deterministic noise and sparse random noise. The algorithms have low sample complexity as compared to previous results in the noise-free case.", "Method": "The authors present algorithms for both bounded deterministic noise and sparse random noise and study the scenario where the hidden matrix lies on a mixture of subspaces. The proposed algorithms are evaluated experimentally on both synthetic and real-world datasets.", "Outcome": "The proposed algorithms return a matrix of small error with sample complexity almost as small as the best prior results in the noiseless case for the bounded deterministic noise model. For the sparse random noise model, the proposed algorithm exactly recovers an mu_0-incoherent matrix by probability at least 1 - delta with sample complexity as small as O(mu_0rnlog(r/delta)), advancing the state-of-the-art work and matching the lower bound in the worst case.", "Future Impact": "The proposed algorithms for life-long matrix completion that are tolerant to realistic noise models could significantly improve the performance of recommendation systems, computer vision, and system identification tasks that are vulnerable to data corruption and incompleteness. The study of the scenario where the hidden matrix lies on a mixture of subspaces could lead to more efficient algorithms with even lower sample complexity."}
{"id": "3b076d81-3ed0-4d57-84e8-4145f67052bd", "Context": "Referring expressions and other object descriptions should be maximal under the Local Brevity, No Unnecessary Components, and Lexical Preference preference rules; otherwise, they may lead hearers to infer unwanted conversational implicatures.", "Key Idea": "The authors propose a polynomial time generation algorithm that incorporates preference rules to avoid unwanted conversational implicatures while generating referring expressions.", "Method": "The authors incorporate Local Brevity, No Unnecessary Components, and Lexical Preference preference rules into a polynomial time generation algorithm. The authors also discuss alternative formalizations of conversational implicature that make the generation task NP-Hard.", "Outcome": "N/A", "Future Impact": "The proposed polynomial time algorithm can be used to generate referring expressions and other object descriptions that avoid conversational implicatures, which have implications in natural language processing and communication applications."}
{"id": "3b6e7572-2ef8-4565-a3b7-301a3fd38acd", "Context": "Backward locking and update locking are sources of inefficiency in backpropagation that prevent from concurrently updating layers. Local error signals have been suggested as a solution to train network blocks asynchronously to overcome these limitations", "Key Idea": "The authors propose a differentiable algorithm named SEDONA to automate the process of discovering the optimal configuration for local training.", "Method": "The authors run experiments to show that their algorithm can discover transferable decoupled architectures for VGG and ResNet variants and they evaluate their approach on CIFAR-10, Tiny-ImageNet, and ImageNet.", "Outcome": "The authors report consistently better performance on the evaluated tasks compared to end-to-end backpropagation and other state-of-the-art greedy-leaning methods. They also report up to a 2× speedup over backpropagation in total training time.", "Future Impact": "The proposed search algorithm could be applied to larger and more complex models to further improve performance and speed, and reduce reliance on human design and intuition."}
{"id": "45b76955-9670-4664-939c-f5a61eb597df", "Context": "The paper proposes a novel metric for auditing group fairness in ranked lists by accounting for varying user behaviors and allowing non-binary protected attributes to enable investigating inherently continuous attributes.", "Key Idea": "The authors model user attention as varying rather than assuming a logarithmic loss in importance as a function of the rank and allow non-binary protected attributes to enable measurements across aggregated sets of search results, rather than separately for each result list, to better address the human factors inherent in fair group representation in ranked lists.", "Method": "The authors propose a novel metric and perform three simulated fairness audits using the metric.", "Outcome": "The metric can better address the human factors inherent in fair group representation in ranked lists.", "Future Impact": "N/A"}
{"id": "4164fd9a-7ab8-4013-b416-a205231f10f2", "Context": "Plan recognition has been shown to be solvable using modified planning algorithms without the need for a plan library", "Key Idea": "The authors extend the above approach to probabilistic plan recognition by defining the posterior goal probabilities in terms of cost differences of achieving the goal under two conditions: complying with observations and not complying with them. These posterior probabilities are computed using off-the-shelf classical planners.", "Method": "The authors use two calls to a classical planner to compute the cost difference mentioned above and posterior goal probabilities. The authors provide examples to illustrate the quality, flexibility, and scalability of their approach.", "Outcome": "The authors show that their approach efficiently solves the problem of probabilistic plan recognition. They do not provide measurable results.", "Future Impact": "The proposed approach could simplify the process of probabilistic plan recognition by using off-the-shelf classical planners and could extend the applicability of probabilistic plan recognition to a wider range of scenarios."}
{"id": "438caf1c-5c7e-4283-a3cd-bbab302df185", "Context": "Active learning commonly uses uncertainty or diversity sampling selection, aiming to select data points from the pool of unlabeled data. Of these, uncertainty and diversity sampling are best-known acquisition functions.", "Key Idea": "The authors present Contrastive Active Learning - an acquisition function called CAL - that selects contrastive examples. CAL selects similar data points in the feature space, which have maximally different predictive likelihoods.", "Method": "The authors compare CAL with diverse acquisition functions in four natural language understanding tasks and seven datasets. The authors conduct an extensive ablation study of the proposed method and analyze all actively acquired datasets.", "Outcome": "CAL consistently outperforms or equals the best performing baseline across all tasks, on both in-domain and out-of-domain data.", "Future Impact": "CAL achieves a better trade-off between selecting the right examples by calculating similarity and predictive differences between example pairs. The authors expect that CAL can improve datasets in various domains where acquiring the right examples is key, such as medical and legal domains."}
{"id": "48bacac1-1ca9-4be8-90e6-470596de0e26", "Context": "Previous studies have explored (semi-) unsupervised methods of learning polarity of words and phrases for the purpose of building a lexicon automatically in sentiment analysis.", "Key Idea": "The authors propose to use structural clues to extract polar sentences from Japanese HTML documents and build lexicon from the extracted sentences. The structural clues have extremely high precision at the cost of recall.", "Method": "The authors explore the use of structural clues to extract polar sentences from Japanese HTML documents, and build lexicon from the extracted polar sentences. They compensate for the low recall using a massive collection of HTML documents.", "Outcome": "The authors were able to extract enough polar sentence corpus from the massive collection of HTML documents to build a lexicon for sentiment analysis.", "Future Impact": "N/A"}
{"id": "432f5702-7b7d-4995-812e-40925f1a18dd", "Context": "The research effort in machine learning is generally focused on conditional modeling when x is high dimensional. The authors address the opposite case of high dimensional y.", "Key Idea": "The authors propose the Landmark Selection Method for Multiple Output Prediction. Their approach involves selecting a small subset of the dimensions of y and modeling x → yL and yL → y to obtain a conditional model x → y that has convenient statistical properties.", "Method": "The authors provide several multilabel classification and multivariate regression experiments across different datasets to compare the proposed method with one-vs-all approach and several sophisticated multiple output prediction methods.", "Outcome": "The proposed method outperforms one-vs-all approach as well as several sophisticated multiple output prediction methods when tested on several datasets for multilabel classification and multivariate regression problems.", "Future Impact": "N/A"}
{"id": "4e6f8004-9384-4c5c-8d7f-265410a290df", "Context": "Several deep learning methods have been proposed for completing partial data from shape acquisition setups. However, these methods only complete the partial shape with a single output, ignoring the ambiguity when reasoning the missing geometry.", "Key Idea": "The authors pose a multi-modal shape completion problem and propose to use a conditional generative modeling approach to complete the partial shape via a one-to-many mapping.", "Method": "The authors develop a method that learns a multimodal distribution of possible results and conditions the completion on this distribution. They evaluate their approach on several datasets.", "Outcome": "The authors demonstrate the merit of their approach in completing partial shapes with both diversity and quality. They compare their approach against several baseline methods and variants of their method qualitatively and quantitatively.", "Future Impact": "This proposed method may have potential applications in fields such as robotics and autonomous driving, where partial data may come from sensors with varying degrees of accuracy and completeness."}
{"id": "4fdcceeb-f50f-4c4f-8b92-5985498114f8", "Context": "The authors discuss the problem of recovering the three-dimensional motion of a non-rigid object from a sequence of stereo images. Feature correspondence over multiple frames is assumed.", "Key Idea": "The authors propose a method of using algebraic geometry and polynomial equations to recover the 3D motion of a non-rigid object undergoing uniform expansion and shearing from stereo images.", "Method": "The authors reduce the problem of recovering the 3D motion uniquely to the solution of a set of homogeneous polynomial equations using the commutative algebra software package MACAULAY, and the Fortran polynomial continuation program POLSYS. The approach depends on feature correspondence over multiple frames.", "Outcome": "It is shown that the proposed method requires only two stereo snapshots with four points correspondence to determine the motion uniquely.", "Future Impact": "N/A"}
{"id": "532e797a-4b72-488a-80e4-03713d3c8435", "Context": "Existing methods for Non-Rigid Structure-from-Motion (NRSfM) rely on linear low-order or low-rank shape models. These methods are not effective when the observed object is performing non-linear motion.", "Key Idea": "The authors propose a new strategy to NRSfM that exploits the property of shape recurrency, which is a generalization of the concept of rigidity.", "Method": "The authors reduce NRSfM to a rigid-SfM method using camera view clustering and automatic recurrency detection. The proposed method is evaluated with experiments on both simulated sequences and real data.", "Outcome": "The proposed method is demonstrated to be effective in the reconstruction of non-rigid dynamic shapes, as shown by experiments on both simulated sequences and real data.", "Future Impact": "The proposed method offers a novel perspective on rethinking structure-from-motion, opening up possibilities for novel problems in the field."}
{"id": "58279154-e623-46d2-a431-cc409e094e2c", "Context": "The paper addresses a model of analogy-driven theorem proving that is more general and cognitively more adequate than previous approaches.", "Key Idea": "The authors propose an analogy-driven proof-plan construction method that employs a source proof-plan to guide the construction of a proof-plan for the target problem.", "Method": "The model works at the level of proof-plans and includes a reformulation of the source proof-plan. Several well-known theorems were processed using this approach.", "Outcome": "Using the proposed analogy-driven proof-plan construction method, the authors were able to prove several theorems that could not be proven by previous approaches.", "Future Impact": "N/A"}
{"id": "56992082-e04e-4a8b-a985-abfea27fc2e0", "Context": "Dynamic network pruning achieves runtime acceleration by dynamically determining the inference paths based on different inputs.", "Key Idea": "The authors propose a method for explicitly modeling discrete weight channel selections to achieve more sparse runtime inference paths and visualizing the network decision paths for model interpretability.", "Method": "The authors conduct experiments on CIFAR10 and ImageNet datasets to demonstrate the effectiveness of their approach. They also propose an adversarial example detection algorithm by discriminating the runtime decision features.", "Outcome": "The proposed dynamic network achieves higher prediction accuracy under similar computing budgets on CIFAR10 and ImageNet datasets compared to traditional static pruning methods and other dynamic pruning approaches. The proposed adversarial detection algorithm significantly improves the state-of-the-art detection rate across multiple attacks.", "Future Impact": "The proposed method provides an opportunity to build an interpretable and robust model with higher accuracy and reduced computing costs, which can be applied in various fields involving large-scale neural networks and adversarial attacks."}
{"id": "49309d5a-5959-4f8f-ae30-9fd2350f0cbc", "Context": "Deploying CNNs on constrained devices poses a challenge due to the huge memory and compute resources required by CNNs. Existing compression techniques struggle to be computationally friendly.", "Key Idea": "The authors propose focused quantization, a novel quantization strategy that exploits the weight distributions after fine-grained pruning and dynamically discovers the most efficient numerical representation for weights in layers with varying sparsities. The proposed method significantly reduces model sizes and replaces expensive multiplications with cheaper bit-shift operations.", "Method": "The proposed method is evaluated on ResNet-50 and ResNet-18. The authors achieve a compression ratio of 18.08x with only 0.24% loss in top-5 accuracy, outperforming existing compression methods on ResNet-50.  They also show that ResNet-18 is higher in compression ratios and more hardware efficient than other state-of-the-art quantization methods given the same throughput.", "Outcome": "Focused quantization achieves a significantly reduced model size with a minimal loss in accuracy. The proposed method outperforms existing compression methods on ResNet-50 in terms of compression ratios and accuracy and is more hardware efficient than other state-of-the-art quantization methods in ResNet-18.", "Future Impact": "The proposed focused quantization method may enable CNN deployment on constrained devices where traditional compression techniques struggle to provide computationally friendly solutions."}
{"id": "5b9f94f9-d93f-455d-a110-007ad67ada6d", "Context": "Existing specification languages for tree based grammars do not support identifier management adequately.", "Key Idea": "The paper argues that XMG provides an effective treatment of identifiers for a linguist-friendly grammar design.", "Method": "The authors demonstrate that Coreference Handling in XMG provides a sophisticated treatment of identifiers irrespective of the quantity of cross-referencing. They provide examples of the mechanism in XMG using multiple examples.", "Outcome": "N/A", "Future Impact": "N/A"}
{"id": "5b47ca6b-ff9b-429c-adb1-ad9a171eea0e", "Context": "The paper discusses the building of style-adapted maximum entropy language models for speech recognition, given a large corpus of written language data and a small corpus of speech transcripts. The linear interpolation method is typically used in such cases.", "Key Idea": "The authors investigate a Bayesian adaptation method for building style-adapted maximum entropy language models that consistently outperforms linear interpolation.", "Method": "The authors perform experiments to show the superiority of the Bayesian adaptation method over linear interpolation.", "Outcome": "Experiments show that the Bayesian adaptation method consistently outperforms linear interpolation in building style-adapted maximum entropy language models for speech recognition.", "Future Impact": "N/A"}
{"id": "5a3da6ef-67b0-41bc-a994-fc5ff455a27b", "Context": "Online reviews play a crucial role in today's electronic commerce, but due to pervasive spam reviews, customers may be misled, and decent stores may be defamed by malicious reviews. The problem of detecting spam reviews in singleton reviews is challenging.", "Key Idea": "The authors propose to detect spam attacks in singleton review based on the unusually correlated temporal patterns via identification and construction of a multidimensional time series based on aggregate statistics.", "Method": "The authors propose a hierarchical algorithm to robustly detect the time windows where such spam attacks are likely to have happened. The algorithm also pinpoints such windows in different time resolutions to facilitate faster human inspection.", "Outcome": "Experimental results show that the proposed method is effective in detecting singleton review attacks which was found to be a significant source of spam reviews, largely affecting the ratings of online stores.", "Future Impact": "The proposed approach provides a practical solution in detecting review spam in online e-commerce which is widely applicable to other applications dealing with bursty events."}
{"id": "5d87de73-77d4-4efd-b8e1-d7561b13f69f", "Context": "The paper addresses the problem of preposition sense disambiguation and evaluates its results against the SemEval 2007 Preposition Sense Disambiguation datasets.", "Key Idea": "The authors present a supervised classification approach for disambiguating preposition senses by using linguistically motivated features derived from both sides of the preposition utilized through phrase structure.", "Method": "The authors employed five different classifiers to test the effectiveness of proposed approach.", "Outcome": "The approach shows an increased accuracy that outperforms the best system in the SemEval task.", "Future Impact": "N/A"}
{"id": "5c268324-e160-489d-9722-6b59d5e3471b", "Context": "The Web accessibility is limited as the majority of designers do not know how to design more usable and accessible websites for disabled people.", "Key Idea": "The authors propose a new approach to achieve a more accessible Web through better knowledge-acquisition mechanisms and designing mechanisms that elicit knowledge from minorities of Web users in order to include marginal Web users.", "Method": "The approach includes detecting the Web designer's needs for knowledge, collecting this knowledge from minorities of Web users, and designing mechanisms that elicit such knowledge from Web users.", "Outcome": "The proposed approach can build a more accessible Web for the visually-impaired knowledge contributors and enable self-interested designers to be more accessible through better knowledge-acquisition mechanisms.", "Future Impact": "The approach presents a model for designing for marginalized users and promotes inclusion in the design process, which can be replicated to different areas of design to promote inclusion in their fields."}
{"id": "5dccca98-2b58-47e3-9b8f-3b1888aa3976", "Context": "Despite the vision of real-time data warehousing, the heterogeneity of today’s IT environment and increasing demands from mobile users pose significant challenges to be overcome by the traditional middleware solutions.", "Key Idea": "The authors propose a new middleware paradigm called space based computing to meet the challenges of creating real-time data warehousing in heterogeneous platforms and systems. ", "Method": "The paper presents space-based computing as an innovative middleware component that offers a level of abstraction superior to conventional middleware solutions, including distributed transactions and the seamless integration of mobile devices using open standards. The authors present a real-time build-up of data warehouses as an example of how this approach could work in practice.", "Outcome": "N/A", "Future Impact": "The proposed approach may have a significant impact on the development of real-time data warehousing and other applications that require seamless integration of heterogeneous platforms and systems while improving the performance of middleware solutions."}
{"id": "5e1f387c-d883-4d1f-8397-e4a533a3387b", "Context": "Hyperspectral imaging suffers from various sources of degradations, and lack of accurate ground-truth 'clean' hyperspectral signals makes restoration tasks challenging. Traditional neural networks struggle to train correctly due to limited available data.", "Key Idea": "The authors propose a new approach to hyperspectral image restoration based on sparse coding principles, merging classical techniques with deep learning to allow training of parameters without significant data requirements.", "Method": "The proposed spectral-spatial sparse coding model is applied to various denoising benchmarks and is shown to be computationally efficient while significantly outperforming the current state of the art.", "Outcome": "The proposed spectral-spatial sparse coding model is shown to be highly effective in improving denoising benchmarks.", "Future Impact": "The hybrid approach based on sparse coding principles proposed in this paper is a promising avenue for future research in hyperspectral imaging restoration and may be useful for other applications with limited training data."}
{"id": "69aacc53-6730-4db0-b420-9a45b96a642e", "Context": "Finding the configuration of a collection of geometric bodies that satisfies a set of given constraints is a significant geometric reasoning problem.", "Key Idea": "Automatically synthesizing a set of specialized routines called plan fragments from first principles about geometric bodies, actions, and topology and using them to solve the geometric constraint satisfaction problem.", "Method": "The paper proposes an approach that synthesizes the plan fragments automatically using first principles about geometric bodies, actions, and topology.", "Outcome": "The proposed approach is shown to solve the geometric constraint satisfaction problem efficiently by employing a set of specialized routines called plan fragments.", "Future Impact": "The proposed approach may be used in applications relying on geometric reasoning, such as computer-aided design (CAD), and may pave the way for more efficient and automated solutions for geometric constraint satisfaction problems."}
{"id": "68f8d058-1403-4066-b3d3-a8a2836b35e1", "Context": "The paper focuses on the problem of imperfect vector training labels with registration uncertainty, which is important in applications such as streamline classification on Earth imagery or tissue segmentation on medical imagery.", "Key Idea": "The authors propose a novel deep learning framework that explicitly quantifies vector labels' registration uncertainty and a registration-uncertainty-aware loss function to train neural networks with uncertain label locations.", "Method": "The authors design an iterative uncertainty reduction algorithm by estimating the posterior of true vector label locations distribution based on a Gaussian process and evaluate their approach on real-world datasets in National Hydrography Dataset refinement.", "Outcome": "The proposed approach significantly outperforms several baselines in both the registration uncertainty estimations performance and classification performance.", "Future Impact": "The proposed framework has the potential to improve the efficiency of annotating precise vector labels, potentially leading to significant cost savings in image analysis applications that rely on such labels. The uncertainty quantification method may be useful in other image analysis applications as well."}
{"id": "6dc39f88-d613-4ec0-b70d-d5daa6f3643c", "Context": "BitGourmet is a novel data analysis system that supports deterministic approximate query processing (DAQ).", "Key Idea": "BitGourmet operates on a carefully selected data subset to satisfy the user-defined precision constraint by dividing each column vertically, bit-by-bit, and uses a specialized query processing engine that evaluates queries on subsets of these bit vectors.", "Method": "The proposed system executes aggregation queries and produces deterministic bounds that contain the true value. The specialized query processing engine uses scenario-specific query optimizer, quality, and cost models to decide the optimal bit selection and execution plan. In the demonstration, the authors show that DAQ realizes an interesting trade-off between result quality and execution time making data analysis more interactive.", "Outcome": "The proposed system provides deterministic bounds that are guaranteed to contain the true value and operates in case of user-defined precision constraints. The authors also demonstrate that DAQ realizes an interesting trade-off between result quality and execution time that results in more interactive data analysis.", "Future Impact": "The authors do not explicitly state the Impact of their work, but the proposed approach could potentially reduce the computational cost of data analysis and provide deterministic bounds with user-defined precision constraints. Further research in this direction may lead to more interactive data analysis and reduced computational costs."}
{"id": "6de74297-fb80-448f-b7ae-41f8d9701044", "Context": "Previous literatures have used different imaging models to describe central catadioptric and fisheye cameras separately, and they have not been considered within a unified imaging model.", "Key Idea": "The authors present a unified imaging model that can be used to describe both central catadioptric and fisheye cameras, and show that existing calibration methods for central catadioptric cameras can be directly applied to fisheye cameras.", "Method": "The authors propose a unified imaging model for both central catadioptric and fisheye cameras. They demonstrate how fisheye images can be transformed into central catadioptric images under this new model, and how this model enables the use of existing calibration methods for central catadioptric cameras on fisheye cameras as well.", "Outcome": "The experimental results of calibration from some central catadioptric and fisheye images confirm the validity and usefulness of the proposed unified imaging model.", "Future Impact": "The unified imaging model proposed in this study can be used to develop new calibration methods for fisheye cameras that are metric, and can also be used to develop new imaging techniques that require a unified model for both central catadioptric and fisheye cameras."}
{"id": "73e353a8-e0d6-466f-af93-6fccf38fcb18", "Context": "Video-grounded dialogues require additional reasoning over dialogue context to answer questions in a multi-turn setting. Dialogue context is mostly used as a simple text input without modeling the inherent information flows at the turn level in previous approaches.", "Key Idea": "The authors propose to discover information flows among dialogue turns through a semantic graph constructed based on lexical components in each question and answer, and introducing a new approach that learns to predict reasoning paths over this semantic graph.", "Method": "The authors construct semantic graphs based on dialogue context, and propose a model that predicts reasoning paths through the graph. Additionally, their reasoning model processes both visual and textual information through this reasoning path and the propagated features are used to generate the answer.  ", "Outcome": "Experimental results demonstrate the effectiveness of the proposed method.", "Future Impact": "N/A"}
{"id": "7b0671d7-c8f6-4e81-828b-c73958a6a63a", "Context": "The paper describes the design experience of an interactive exhibit about medieval music with three major goals: educational value, entertainment aspects, and historic authenticity.", "Key Idea": "The authors focused on the design challenges and solutions of an interactive exhibit about medieval music that balances educational value, entertainment aspects, and historic authenticity.", "Method": "The authors describe their design experience in developing the interactive exhibit that relies on audio as its only feedback channel.", "Outcome": "The paper presents insight into the challenges in designing an interactive exhibit about medieval music with three major goals: educational value, entertainment aspects, and historic authenticity, and how they could be solved.", "Future Impact": "N/A"}
{"id": "754f792b-fcf3-42f4-bb2c-5c1dcce21d7a", "Context": "The authors argue in favor of using formal meaning representations for natural language. An important use case is the problem of identifying the possible antecedents of anaphoric expressions.", "Key Idea": "The authors propose that a formal meaning representation should have structural properties that facilitate the identification of possible antecedents for anaphoric expressions.", "Method": "The authors do not describe a specific experiment. The research is theoretical and involves proposing a set of structural properties that a formal meaning representation should have.", "Outcome": "N/A", "Future Impact": "The adoption of formal meaning representations with structural properties to facilitate the identification of possible antecedents may improve the ability of computational models to deal with anaphoric expressions."}
{"id": "7c065e41-7c2e-430e-a918-6a776037bf50", "Context": "The paper summarizes the SIGMOD 2005 panel on Databases and Information Retrieval: Rethinking the Great. The goal of the panel was to discuss whether we should rethink data management systems architectures to truly merge Database (DB) and Information Retrieval (IR) technologies.", "Key Idea": "The panel discusses whether we should rethink data management systems architectures to truly merge Database (DB) and Information Retrieval (IR) technologies.", "Method": "The panel was a discussion session held at the SIGMOD 2005 conference with high attendance and lively discussions.", "Outcome": "N/A", "Future Impact": "N/A"}
{"id": "7d850699-212d-466b-976f-0afed0653fef", "Context": "The authors build on their previous work from HOO 2011 Shared Task to extend it for determiner and preposition error detection in non-native English essays from the Cambridge Learner Corpus FCE Dataset.", "Key Idea": "The authors propose a missing determiner detector and incorporate word clustering to their n-gram prediction approach to improve the determiner and preposition error detection.", "Method": "The authors extend their n-gram-based data-driven prediction approach from HOO 2011 Shared Task to improve determiner and preposition error detection. They used word clustering to group semantically similar words and incorporated it into the prediction approach.", "Outcome": "N/A", "Future Impact": "The proposed approach can be applied to other languages to identify determiner and preposition errors in non-native speaker essays during automated essay scoring and may improve the accuracy of grammatical error correction systems."}
{"id": "7b21425c-a2b7-4d19-b030-a8350b2a7a80", "Context": "Conditional set generation learns a mapping from an input sequence of tokens to a set. Several NLP tasks are instances of set generation.", "Key Idea": "The authors propose a novel algorithm called SETAUG to jointly model the set cardinality and output, endowing any Seq2Seq model with the signals of order-invariance and cardinality.", "Method": "The SETAUG algorithm is designed to augment any Seq2Seq model and enable it with the capabilities of order-invariance and cardinality. The authors show that training a Seq2Seq model with this augmented data resulted in an average relative improvement of 20% on four benchmark datasets.", "Outcome": "The proposed SETAUG algorithm achieved an average relative improvement of 20% on four benchmark datasets. The Seq2Seq models achieved superior performance on entity typing and dialogue emotion tagging.", "Future Impact": "SETAUG is a model-independent data augmentation approach that may improve the performance of various Seq2Seq models across different domains. This technique could be applied to other set generation tasks, enabling improvements in various NLP applications."}
{"id": "6ecf725b-661e-4897-8169-22d71826d0e8", "Context": "Different Open Information Extraction (OIE) tasks require different types of information, so the OIE field requires strong adaptability of OIE algorithms to meet different task requirements.", "Key Idea": "The authors propose a new adaptable and efficient OIE system called OIE@OIA which follows the methodology of Open Information eXpression (OIX) to parse a sentence to an Open Information Annotation (OIA) graph and then adapts the graph to different OIE tasks with simple rules.", "Method": "The authors implement an end-to-end OIA generator by annotating a dataset and designing an efficient learning algorithm for the OIA graph. The authors adapt the proposed system to accomplish three popular OIE tasks and show that it achieves new SOTA performances on these tasks with fewer training samples.", "Outcome": "The proposed OIE@OIA system achieves new state-of-the-art (SOTA) performances on the three popular OIE tasks and requires significantly fewer training samples than other end-to-end OIE baselines.", "Future Impact": "The OIE@OIA system can adapt to different OIE tasks with simple rules, which could lead to the development of more efficient and adaptable OIE algorithms in the future."}
{"id": "816707fd-9214-4435-ac40-b2655e55c9d0", "Context": "Pretrained language models (PLMs) have achieved superhuman performance on many benchmarks", "Key Idea": "The authors introduce CoDA21, a challenging benchmark that measures natural language understanding (NLU) capabilities of PLMs by aligning definitions with appropriate context.", "Method": "CoDA21 requires understanding of contexts and definitions, including complex inference and world knowledge. The authors compare performance of humans and PLMs on CoDA21.", "Outcome": "The authors find a large gap between human and PLM performance on CoDA21, suggesting that it measures an aspect of NLU that is not sufficiently covered in existing benchmarks.", "Future Impact": "CoDA21 could be used as a new benchmark to evaluate the performance of PLMs and other NLP models in terms of natural language understanding. It could also motivate researchers to develop NLP models with better NLU capabilities that exceed human performance."}
{"id": "802a5b78-a022-4d38-bfb3-f28eee4ef89a", "Context": "Neural network-based dependency parsing has attracted much interest due to its advantages in overcoming the data sparsity and the feature engineering problem. However, modeling the complicated syntactic and semantic compositions of the dense neural features is still a challenge.", "Key Idea": "The authors propose two heterogeneous gated recursive neural networks: Tree-GRNN and DAG-GRNN and integrate them to automatically learn the compositions of the dense features for transition-based dependency parsing.", "Method": "The authors use Tree-GRNN to model the feature combinations for the trees in the stack with partial dependency structures. They use DAG-GRNN to model the feature combinations for the nodes whose dependency relations have not been built yet. The authors evaluate the proposed model on two benchmark datasets: PTB3 and CTB5.", "Outcome": "The experiment results show that the proposed model is effective for dependency parsing, achieving state-of-the-art results on the PTB3 dataset and competitive results on the CTB5 dataset.", "Future Impact": "The proposed method can potentially benefit various natural language processing tasks that rely on dependency parsing, such as machine translation, text summarization, and sentiment analysis."}
{"id": "80698baf-89cb-4a50-9f5c-0c74151b798b", "Context": "The paper aims to examine how students in a MOOC can be motivated to do a better job during peer grading.", "Key Idea": "The paper proposes a controlled study to examine how 'grading the graders' (examining the peer-grading work of students) can motivate students to do a better job when grading assignments.", "Method": "The authors conducted a controlled study on over a thousand students on a popular MOOC, asking two questions to differentiate how to motivate students and validate their hypothesis. The quality of the peer grading is compared and examined to test their hypothesis.", "Outcome": "The study found strong statistical evidence that 'grading the graders' can increase the quality of peer grading.", "Future Impact": "The paper provides a potential motivation strategy for instructors to integrate in their peer-grading evaluation process in MOOCs and could encourage further research into how to motivate students in online education."}
{"id": "8737b031-f77c-4f32-8a68-4be9b0c9ecf8", "Context": "Training a deep network to perform semantic segmentation requires large amounts of labeled data. Researchers have investigated the use of synthetic data to reduce the manual effort of annotating real images.", "Key Idea": "The authors propose a new method for using synthetic data that builds on foreground-background segmentation. They treat foreground objects in a detection-based manner and background pixels in a more traditional classification-based manner.", "Method": "The authors perform experiments on Cityscapes and CamVid datasets using models trained only on synthetic data.", "Outcome": "The proposed method achieves state-of-the-art performance on Cityscapes, outperforming other methods that use a mix of synthetic and real data.", "Future Impact": "Our approach provides a drastically different and more efficient way of handling synthetic images, which can lead to more rapid development and deployment of semantic segmentation models by reducing the need for real images. Further research could investigate the use of this method on other types of computer vision tasks beyond semantic segmentation."}
{"id": "8ae36735-e4ac-48da-bd2b-5538a6a00a73", "Context": "Social networking sites can use user-provided traits such as interests and demographics to provide better content to match their usersu0027 interests. Accurate probability estimates are needed to determine the correct content to return.", "Key Idea": "The authors propose a maximum entropy constraint to address the bias introduced by collective inference methods, and a massively scalable variational inference algorithm for large scale relational networks.", "Method": "The authors analyze the effect of full semi-supervised RML and conduct experiments on seven real-world datasets to demonstrate their method's improvement over baselines.", "Outcome": "The proposed method outperforms baselines on seven real-world datasets, including large scale networks with over five million edges.", "Future Impact": "The proposed method provides a framework for accurately predicting user preferences in massive relational network domains, which has numerous applications in recommendation and matching systems in social networking sites and e-commerce platforms."}
{"id": "9292bc08-a70f-4adb-a6d7-920728893a39", "Context": "The paper discusses propositional argumentation systems obtained by gradually extending the underlying language and associated monotonic logics.", "Key Idea": "The authors show the equivalence between a stronger argumentation system in a full classical language and a system of causal reasoning.", "Method": "The authors discuss the implications of this correspondence between the two systems.", "Outcome": "The paper establishes the equivalence between stronger argumentation system and system of causal reasoning.", "Future Impact": "N/A"}
{"id": "93bf12a1-2174-43e3-9cd4-c2b8aeed2f93", "Context": "Unsupervised domain mapping aims to learn a mapping between two unmatched datasets such that a sample in one can be translated to its analog in another", "Key Idea": "The authors propose a method to learn a one-sided mapping between two unmatched datasets, without having to learn the inverse mapping.", "Method": "The authors present a method for learning the mapping that maintains the distance between a pair of samples using a proposed distance loss function. The proposed method is compared to the existing circularity-based constraint through experiments.", "Outcome": "The proposed method can learn one-sided mapping between unmatched datasets and leads to preferable numerical results over the existing circularity-based constraint.", "Future Impact": "N/A"}
{"id": "8aedb046-2f51-4229-bc19-ea6db98355cb", "Context": "Ranking webpages has been a significant organizational structure of the web, affecting various web applications such as web search and crawling. Researchers previously used a HostGraph with the random walk model to rank websites.", "Key Idea": "The authors proposed a novel method named AggregateRank rooted in the theory of stochastic complement that accurately approximates the sum of PageRank and has lower computational complexity than PageRank.", "Method": "The authors mathematically proved that the probability of visiting a website by the random web surfer should be equal to the sum of the PageRank values of the pages inside that website. The authors proposed AggregateRank, which has lower computation complexity than PageRank and performed an experimental evaluation of AggregateRank in comparison to previous methods.", "Outcome": "AggregateRank is a better method for ranking websites than previous methods. Both theoretical analysis and experimental evaluation support the effectiveness of AggregateRank.", "Future Impact": "N/A"}
{"id": "99bef0ca-923c-480d-a89e-9a2f27e02157", "Context": "Abstraction has emerged as a key enabler for solving large incomplete-information games over the last dozen years.", "Key Idea": "The paper reviews key developments in abstraction, including reasons for abstracting games, practical algorithms for information and action abstraction, recent theoretical breakthroughs on strategy quality, and reverse mapping opponent's actions into the abstraction.", "Method": "The author reviews existing literature and presents various algorithms and theoretical results.", "Outcome": "N/A", "Future Impact": "The paper discusses current and future research in the field of abstraction for solving large incomplete-information games."}
{"id": "9999e1df-f439-4f62-bd03-337e494e9da3", "Context": "The paper discusses a data type encapsulation scheme that enables natural expression of space operations using base language operators.", "Key Idea": "The authors propose a data type encapsulation scheme using a conceptual separation of operators and procedure calls in the base language, which results in a powerful and expressive language.", "Method": "The authors implemented the proposed scheme and provide several examples to demonstrate its effectiveness.", "Outcome": "The paper does not mention any quantitative or qualitative outcomes of the proposed scheme.", "Future Impact": "The proposed scheme provides a way for programmers to achieve data encapsulation and can potentially improve code readability and maintainability. It may inspire other researchers to explore similar approaches."}
{"id": "977698a6-56ef-4e57-94c5-b3a68a451a80", "Context": "Emotion cause extraction is a challenging task compared to emotion classification.", "Key Idea": "The authors propose a new QA-based approach that models context information using a new mechanism to store relevant context in different memory slots.", "Method": "The authors use deep memory networks to frame emotion cause identification as a reading comprehension task in QA and extract both word level sequence and lexical features. They evaluate their proposed method on a recently released dataset and compare it with competitive baselines.", "Outcome": "The proposed method achieves the state-of-the-art performance on a recently released emotion cause dataset, outperforming a number of competitive baselines by at least 3.01% in F-measure.", "Future Impact": "N/A"}
{"id": "9748b061-590a-4602-9015-a68e879ffced", "Context": "HCI researchers are looking for customized liquid-based material printing platforms with desirable features. Conventional printing systems like inkjet or pneumatic syringe-based have limitations in printing a wide range of materials with different processing requirements.", "Key Idea": "The authors propose a design strategy for building and customizing modularized parts of a liquid-based smart material printing platform. The printing platform supports open-source, customizable software", "Method": "The authors followed design principles, building and customizing modularized parts of a liquid-based smart material platform. They demonstrated the system design using three use cases to show the material variability and customizability for different users with different demands.", "Outcome": "The liquid-based smart material printing platform xPrint provides the ability to print a large range of materials, including synthesized polymers and natural micro-organism-living cells, with a printing resolution from 10μm up to 5mm (droplet size).", "Future Impact": "The proposed strategy offers a flexible way for researchers and designers to build a liquid-based material printer optimized to meet their specific material requirements. It can potentially be used to print a wide range of customized materials for various applications."}
{"id": "927df1bd-273a-4088-8c56-2e79cac37072", "Context": "K-means is one of the most popular data processing algorithms, and a proper initialization is crucial for obtaining a good final solution. K-means++ initialization algorithm achieves this secret by obtaining an initial set of centers that is provably close to the optimum solution.", "Key Idea": "The authors propose k-means||, a parallelizable initialization algorithm that drastically reduces the number of passes needed to obtain a good initialization for k-means. The proposed method obtains a nearly optimal solution after a logarithmic number of passes.", "Method": "The authors perform experimental evaluations on real-world large-scale data to demonstrate the superiority of k-means|| over k-means++ in both sequential and parallel settings.", "Outcome": "The proposed initialization algorithm k-means|| outperforms k-means++ in both sequential and parallel settings when evaluated on real-world large-scale data.", "Future Impact": "The proposed initialization algorithm can improve the performance of k-means on massive data by reducing the time and computational resources needed to obtain a good initialization. The methodology of k-means|| can be generalized to other clustering algorithms that could lead to the improvement of various machine learning applications."}
{"id": "9b95b592-1562-4ef9-b0ed-e0655fadc73b", "Context": "The paper presents a general formulation for geodesic distance propagation of surfaces on a 3-manifold. The paper sets up a partial differential equation governing the propagation of surfaces at equal geodesic distance.", "Key Idea": "The paper proposes a geodesic distance evolution scheme for surface matching on a 3-manifold, which generalizes a result of Kimmel et al. [11] and provides a way to compute distance maps on manifolds. Moreover, the propagation equation is generalized to any number of dimensions.", "Method": "The authors use an eulerian formulation with level-sets and develops a stable numerical algorithm based on the extended partial differential equation to compute the geodesic distance propagation.", "Outcome": "The paper proposes a new method for surface matching, and the matching paths are obtained as the orbits of the vector field defined as the sum of two distance map's gradient values. The proposed method works for large deformation and arbitrary topology.", "Future Impact": "The proposed method can find applications in computational geometry, computer graphics, and medical imaging for matching and registration of the surfaces in different domains. It can also pave the way for further research in using geodesic distance propagation for distance maps on manifolds."}
{"id": "9f641e23-3886-4ac6-b65e-28db86ee48be", "Context": "Google unveiled the generalized second price (GSP) auction, against the usual recommendation of using Vickrey-Clarke-Groves (VCG) auction.", "Key Idea": "Advertisers' preferences map to a model called value maximization instead of profit maximization. For value maximizers, GSP is the truthful auction. GSP is an auction whose prices are truthful for value maximizers, which can be applied to arbitrary single-parameter domains.", "Method": "The authors provide a deep justification for the success of GSP. They explain their model on advertisers' preferences and demonstrate its implications.", "Outcome": "GSP is a successful auction model for advertisers' preferences consisting of value maximizers. GSP is a powerful auction with elegant simplicity.", "Future Impact": "N/A"}
{"id": "9cd7e7e1-8893-4db6-8327-48f098187699", "Context": "Twitter provides an important alternative information channel to traditional media during natural disasters, but the amount and diversity of messages poses the challenge of information overload to end users.", "Key Idea": "The authors develop an automatic classifier of tweets to feed a mobile application that reduces the difficulties that citizens face to get relevant information during natural disasters.", "Method": "The authors build and validate a ground truth dataset from the Chilean earthquake of 2010 and present the process to build a classifier that filters tweets relevant and non-relevant to an earthquake. The authors show in detail the effect of class imbalance and dimensionality reduction over 5 classifiers.", "Outcome": "The authors present important considerations at the moment of building these systems and show how the performance of these models is affected by class imbalance and dimensionality reduction.", "Future Impact": "The proposed system could help citizens more easily access relevant information during natural disasters, which could improve preparedness and response. Additionally, the study's findings on dealing with class imbalance and dimensionality reduction could be applied to other classification tasks in the field of natural language processing."}
{"id": "a5bc5ab8-70fb-4dff-824b-7606228e44a9", "Context": "There is a need to embed mathematical expressions in Web pages, but the notations available are difficult to learn.", "Key Idea": "EzMath provides a new notation for embedding mathematical expressions that is easy to learn.", "Method": "N/A", "Outcome": "The outcome of the paper is the proposed notation for embedding mathematical expressions in Web pages.", "Future Impact": "N/A"}
{"id": "a722b600-3725-4738-a47b-435aebd63e13", "Context": "Smart home devices have evolved to include products that monitor, automate, and present themselves as human, but this has raised privacy concerns among users who expect privacy in their homes.", "Key Idea": "The authors propose a design philosophy for intelligent agents in the smart home that prioritize privacy and respect for the user's private space, and offer an alternative to the current way of building smart home devices.", "Method": "The authors apply their design philosophy to develop privacy-empowering technologies for the smart home.", "Outcome": "N/A", "Future Impact": "The proposed design philosophy could influence the future development of smart home devices by prioritizing user privacy and respect for private spaces."}
{"id": "a10dafe9-6093-47f0-8429-7b62c46566ea", "Context": "Enterprise mashup scenarios often involve feeds derived from data created primarily for eye consumption, such as email, news, calendars, blogs, and web feeds. These data sources can test the capabilities of current data mashup products, as the attributes needed to perform join, aggregation, and other operations are often buried within unstructured feed text.", "Key Idea": "The authors propose the integration of SystemT, an information extraction system from IBM Research, with IBM's InfoSphere MashupHub to build domain-specific annotators with SystemT's declarative rule language, AQL, to convert unstructured text into structured information.", "Method": "The authors demonstrate the integration of the SystemT information extraction system with IBM's InfoSphere MashupHub by using domain-specific annotators to combine structured and unstructured information.", "Outcome": "The demo shows how to build domain-specific annotators with SystemT's declarative rule language, AQL, and how to use these annotators to combine structured and unstructured information in an enterprise mashup.", "Future Impact": "N/A"}
{"id": "a1739057-ef00-4b01-9c26-4ab2b5d5708e", "Context": "The increasing use of data mining tools requires a Knowledge Discovery and Data Mining System (KDDMS) that optimizes for sequence of queries and multiple simultaneous queries scenario. This paper focuses on frequent pattern mining queries involving one or multiple datasets.", "Key Idea": "The authors propose a systematic mechanism featuring a knowledgeable cache to optimize the mining queries and algorithms to design an architecture for implementing the mechanism.", "Method": "The authors present a new algorithm for optimizing the system architecture. Experimental evaluation is done with both real and synthetic datasets to show the effectiveness of the proposed mechanism.", "Outcome": "The proposed mechanism achieves a speedup up to a factor of 9 compared with non-caching or non-optimization systems.", "Future Impact": "N/A"}
{"id": "ad69e31c-2c7f-4db0-916c-3deccaab37fd", "Context": "The paper focuses on developing a machine learning approach to Go and related board games, particularly on learning a good evaluation function in a scalable way.", "Key Idea": "The authors propose a system that automatically learns the propensity of local patterns from a library of games, feeds it into a recursive neural network, and produces local outputs that represent local territory ownership probabilities for developing a strategic evaluation function for the game of Go.", "Method": "The authors use a library of local tactical patterns, integrate patterns across the board, and develop a Bayesian network-based recursive neural network for developing the evaluation function. They use datasets of amateur and professional games for training and testing the system.", "Outcome": "The system trained using only 9x9 amateur game data performs surprisingly well on a test set derived from 19x19 professional game data.", "Future Impact": "The system has potential applications in developing better evaluation functions for other board games. Possible directions for further improvement include exploring better patterns of intel and using reinforcement learning techniques in addition to supervised learning."}
{"id": "b0ad60d7-3a3a-42c2-acbc-fba55e708ba0", "Context": "The meaning of a lexeme often varies due to the specific surrounding context in natural language.", "Key Idea": "The authors propose a technique to produce a context-dependent 'meaning' representation for a lexeme in a specific surrounding context by representing the 'meaning' of a lexeme in a specific context through a list of semantically replaceable elements composed of other lexemes from the experimental lexicon.", "Method": "The authors perform experiments with two lexicons, English words, and individual words and phrases. The resulting lists can be used to compare the 'meaning' of conceptual units and can also serve as features for machine learning approaches to classify semantic roles and relationships.", "Outcome": "The authors successfully developed a general new technique to produce a context-dependent 'meaning' representation for a lexeme in a specific surrounding context. The resulting lists can be used to compare the 'meaning' of conceptual units in different contexts and can also be used as features for machine learning approaches.", "Future Impact": "The technique proposed by the authors may lead to more effective natural language processing tools that can accurately capture the contextual meaning of words, phrases, and sentences in various domains."}
{"id": "adfd8058-64b3-4062-953c-034b732e2fa0", "Context": "The paper presents a video coding scheme using texture synthesis, where P and B-frames are parametrically coded with the help of DEMD algorithm and I-frames are coded with the help of H.264.", "Key Idea": "The paper proposes the use of Directional Empirical Mode Decomposition (DEMD) algorithm for texture synthesis of P and B-frames, and wavelet decomposition of residual image to perform multi-resolution parametric modeling of image data for video compression.", "Method": "The authors perform experiments to demonstrate the effectiveness of the proposed algorithm, where subsequent IMF images are synthesized with the help of correlation search and wavelet decomposition over residual image.", "Outcome": "The proposed algorithm achieves significant video compression with acceptable quality and enables scalable coding of IMF parameters.", "Future Impact": "The proposed algorithm can be used to improve video compression and enable high scalability with improved perceptual quality in real-time video streaming applications like live video streaming, video conferencing, and IPTV."}
{"id": "bd84a1fd-ee85-4ac9-a6ae-e534b6013506", "Context": "The paper considers convolutional networks from a reproducing kernel Hilbert space viewpoint.", "Key Idea": "The authors establish harmonic decompositions of convolutional networks, which are expansions into sums of elementary functions of increasing order related to the spherical harmonics.", "Method": "The authors use harmonic analysis techniques to obtain characterizations of the integral operators associated with convolutional networks and statistical bounds for them.", "Outcome": "N/A", "Future Impact": "The harmonic decomposition framework could provide a new perspective on the representation power and expressiveness of convolutional networks, and potentially lead to new insights and improvements in their design and optimization."}
{"id": "b391a193-83e3-4f11-801f-1842647d626e", "Context": "Previous studies have employed graph-based deep learning methods for action unit detection. However, dependencies among action units in real-world data are often noisy.", "Key Idea": "The authors propose an uncertain graph neural network (UGN) in which the probabilistic mask captures individual dependencies among action units and uncertainties.", "Method": "The authors propose an adaptive weighted loss function and perform experiments on two benchmark datasets, BP4D and DISFA.", "Outcome": "The proposed UGN model achieves the state-of-the-art performance for AU detection on BP4D and DISFA dataset.", "Future Impact": "Using an uncertain graph neural network with an adaptive weighted loss function could lead to better results for other tasks with noisy dependencies and data imbalances."}
{"id": "b14f2bc1-607f-4d8b-a731-b4afdf30a633", "Context": "Current explanation datasets often employ synthetic data with simple reasoning structures, which cannot express more complex reasoning processes, such as the rebuttal to a reasoning step and the degree of certainty of the evidence.", "Key Idea": "The authors propose a comprehensive logical reasoning explanation form that includes three main components: the condition of rebuttal, logical formulae, and reasoning strength indicated by degrees of certainty.", "Method": "The authors propose a comprehensive benchmark, and evaluate the performance of the current state-of-the-art models on this new explanation form.", "Outcome": "The experimental results show that generating reasoning graphs remains a challenging task for current models even with the help of giant pre-trained language models.", "Future Impact": "The proposed benchmark can be used as a standardized tool to evaluate logical reasoning capabilities. The benchmark can also drive future research in developing models that can handle more complex real-life scenarios."}
{"id": "b6b29c8a-7c8c-444c-b434-2ff9e166d9aa", "Context": "Offline Reinforcement Learning (RL) aims to learn policies from previously collected datasets without exploring the environment. Directly applying off-policy algorithms to offline RL usually fails due to the extrapolation error caused by the out-of-distribution (OOD) actions.", "Key Idea": "The authors propose a purely uncertainty-driven offline algorithm called Pessimistic Bootstrapping for offline RL (PBRL) that conducts uncertainty quantification via the disagreement of bootstrapped Q-values and performs pessimistic updates by penalizing the value function based on the estimated uncertainty to tackle extrapolation error.", "Method": "The authors propose a novel OOD sampling method. They show that such OOD sampling and pessimistic bootstrapping yields provable uncertainty quantifier in linear MDPs, thus providing the theoretical underpinning for PBRL. The authors conduct experiments on D4RL benchmark and compare the performance of PBRL with the state-of-the-art algorithms.", "Outcome": "The experiments on D4RL benchmark show that PBRL has better performance compared to the state-of-the-art algorithms.", "Future Impact": "The proposed PBRL algorithm could be applied to various problems such as robotics, self-driving cars, and others, where collecting new data is challenging. Further exploration could be done in using PBRL algorithm on continuous control and real-world problems."}
{"id": "c268a190-6974-4190-8f48-db5dcbda8bc8", "Context": "The challenge of data variety in multiple formats like relational and semi-structured data has led to the constraint of traditional databases in handling data in different formats.", "Key Idea": "The authors propose a multi-model processing framework for joining relational and semi-structured data and a worst-case optimal join algorithm that guarantees intermediate results no larger than the worst-case join result.", "Method": "The authors design a worst-case optimal join algorithm and compare it with baseline join methods using preliminary results.", "Outcome": "The multi-model algorithm proposed by the authors outperforms the baseline join methods in terms of running time and intermediate result size.", "Future Impact": "The proposed multi-model processing framework and worst-case optimal join algorithm could potentially lead to faster join processing and improved handling of different formats of data, solving the challenges posed by the data variety in the modern data management ecosystem."}
{"id": "c5c22c6f-e9e9-4b0a-ac57-d3baa100033b", "Context": "The paper deals with structured stochastic convex optimization problems with a large number of linear constraints, which is a common problem in SDP-relaxations of combinatorial problems.", "Key Idea": "The authors propose two novel conditional gradient-based methods that process only a subset of the constraints at each iteration to gain a computational advantage over prior works that require full passes.", "Method": "The proposed algorithms rely on variance reduction and smoothing used in conjunction with conditional gradient steps. Preliminary numerical experiments are provided for illustrating the practical performance of the methods.", "Outcome": "The authors provide rigorous convergence guarantees for their proposed algorithms and demonstrate their practical performance through preliminary numerical experiments.", "Future Impact": "Further research can investigate the suitability of these methods for other types of optimization problems and improve their efficiency and scalability."}
{"id": "ca53b2c4-2912-4515-aae6-938c3f268a60", "Context": "The authors address the problem of detecting epidemic tendency by mining search logs.", "Key Idea": "The authors propose an algorithm to select epidemic related queries/terms by using click-through information. They adopt linear regression to model epidemic occurrences and frequencies of epidemic related terms in search logs.", "Method": "The authors use click-through information to select epidemic-related terms, followed by linear regression to model epidemic occurrences and the frequencies of epidemic-related terms in search logs. They compare the performance of combining different epidemic-related terms against using a single epidemic-related term.", "Outcome": "The proposed algorithm is effective in identifying ERTs that show a high correlation with epidemic occurrences. The authors show that combining different ERTs performs better than using a single ERT.", "Future Impact": "N/A"}
{"id": "c676aecf-7468-4258-bb41-22bc1811bc3a", "Context": "Community search is a fundamental problem aiming to find a connected subgraph containing the given query nodes in a social network. Most of the existing community search models only focus on the internal cohesiveness of a community. However, a high-quality community often has high modularity, making dense connections inside communities and sparse connections to the nodes outside the community.", "Key Idea": "The authors present Density Modularity based Community Search (DMCS) for searching communities which have high modularity and contain all the query nodes.", "Method": "The authors design a new graph modularity function named Density Modularity. To efficiently address DMCS, they present new algorithms that run in log-linear time to the graph size. The authors conduct extensive experimental studies in real-world and synthetic networks.", "Outcome": "The proposed algorithm achieves up to 8.5 times higher accuracy in terms of NMI than the baseline algorithms in the conducted experiments.", "Future Impact": "N/A"}
{"id": "c37e0f9f-1654-4f1f-b812-bf6f67c0c840", "Context": "Recent research has shown the susceptibility of deep networks to adversarial attacks. Developing defenses against such attacks is an active research area, with some approaches proposing robust models that are immune to such adversaries, while other techniques attempt to detect such adversarial inputs.", "Key Idea": "The authors present a novel statistical approach for adversarial detection in image classification. The approach is based on constructing a per-class feature distribution and detecting adversaries based on comparison of features of a test image with the feature distribution of its class.", "Method": "The authors make use of various statistical distances such as ED (Energy Distance) and MMD (Maximum Mean Discrepancy) for adversarial detection, and analyze the performance of each metric. They experimentally show that their approach achieves good adversarial detection performance on MNIST and CIFAR-10 datasets irrespective of the attack method, sample size, and degree of adversarial perturbation.", "Outcome": "The authors show that their proposed approach achieves good adversarial detection performance on MNIST and CIFAR-10 datasets irrespective of the attack method, sample size, and degree of adversarial perturbation.", "Future Impact": "The proposed method may lead to better defense mechanisms to combat adversarial attacks on deep learning-based AI systems, especially in cases where developing robust models immune to adversarial inputs is difficult."}
{"id": "c3aa9543-0695-42b4-99af-d033e3912801", "Context": "The real estate industry is a largely untapped area by the KDD community despite its enormous size and prominence. The lack of synergy is due to the industry's lack of appreciation for data science methods and the Data Science community's unawareness of challenging real estate problems suited to its methods.", "Key Idea": "The paper provides an introduction to real estate for data scientists and outlines a spectrum of data science problems that are suited to data science methods, which can be utilized in real estate to provide solutions to these problems.", "Method": "The paper presents concrete examples from three companies: Airbnb, a short-term rental marketplace, Cherre, a real estate data integration platform, and Compass, the largest independent real estate brokerage in the U.S.", "Outcome": "N/A", "Future Impact": "The paper opens up the possibility of utilizing Data Science methods in the real estate industry, leading to more sophisticated and efficient methods in the industry, improved market analysis resulting in lower risk and more reliable forecasts, among others."}
{"id": "ce74316d-c5dc-47f1-b0c4-0591bc3fb4b6", "Context": "Several methods have been proposed to evaluate queries over a native XML DBMS, where the queries specify both path and keyword constraints. These methods include graph traversal approaches optimized with auxiliary structures known as structure indexes and approaches based on information-retrieval style inverted lists.", "Key Idea": "The authors propose a strategy that integrates both structure indexes and inverted lists to evaluate branching path expression queries in a wide range of methods.", "Method": "The authors propose an algorithm for branching path expressions based on the integration of structure indexes and inverted lists. The algorithm is evaluated over the Niagara XML DBMS.", "Outcome": "The experiments demonstrate the benefits of integrating structure indexes and inverted lists. Additionally, the authors integrate these techniques with the Threshold Algorithm proposed by Fagin et al. to obtain instance optimal algorithms to push down top k computation.", "Future Impact": "N/A"}
{"id": "dca09f6f-b63a-42a1-9eb5-fbfa45bc6389", "Context": "Activity logs collected from wearable devices are challenging to model due to their heterogeneous nature, complex interdependencies, and diverse scale and resolution.", "Key Idea": "The authors propose FitRec, an LSTM-based model that captures two levels of context information, context within a specific activity, and context across a user's activity history for personalized fitness recommendations.", "Method": "The authors develop context-aware sequential models to capture the personalized and temporal patterns of the fitness data. The authors propose, and evaluate the model on, a novel dataset containing over 250 thousand workout records coupled with hundreds of millions of parallel sensor measurements (e.g., heart rate, GPS), and metadata.", "Outcome": "FitRec is able to learn contextual, personalized, and activity-specific dynamics of users' heart rate profiles during exercise and outperforms baselines on several personalized recommendation tasks.", "Future Impact": "The proposed context-aware approach paves the way for utilizing wearables data for personalized exercise scheduling, workout recommendation, and heart rate anomaly detection."}
{"id": "db900c02-9a35-4a83-aa19-15b763259100", "Context": "Deep learning and Convolutional Neural Networks (CNN) have become essential in image recognition and signal processing applications. Quantum computing is a powerful computing paradigm that has applications in several fields, including machine learning.", "Key Idea": "The authors propose a quantum algorithm for evaluating and training deep convolutional neural networks called the Quantum CNN (QCNN), which can reproduce the outputs of the classical CNN and allows non-linearities and pooling operations.", "Method": "The authors present numerical simulations for the classification of the MNIST dataset to provide practical evidence for the efficiency of the QCNN.", "Outcome": "The proposed QCNN algorithm shows potential speedups over classical CNNs for evaluation and training, and can be used for larger kernels, high-dimensional inputs, and high-depth input channels. The numerical simulation presented shows evidence for the efficiency of the proposed algorithm.", "Future Impact": "The proposed QCNN algorithm could allow new frontiers in the image recognition domain, and may have practical implications for using quantum computing to speed up deep learning tasks."}
{"id": "ddf8f49c-342a-4cd0-8b3b-b588af08ed0d", "Context": "Soboroff, Nicholas and Cahan proposed an approach for evaluating retrieval systems even when relevance judgments are absent. They demonstrated that their methodology is correlated with actual evaluations.", "Key Idea": "The authors propose assessing the similarity of retrieved results to quantify similarity among retrieval systems in the absence of relevance judgments.", "Method": "The authors evaluate retrieval systems based on the similarity of their retrieved results. They compare the effectiveness of their method to the methodology proposed by Soboroff et~al. and demonstrate highly correlated results.", "Outcome": "The proposed methodology allows for evaluation of retrieval systems in absence of relevance judgments with reasonable accuracy. The methodology effectively evaluates and ranks retrieval systems by popularity rather than performance.", "Future Impact": "N/A"}
{"id": "ccae9338-7379-4af1-8fea-8945ba429c5c", "Context": "Object tracking is a challenging problem in computer vision. Deep learning is increasingly being used to improve tracking accuracy by extracting powerful features. Pairwise loss is the commonly used loss function in Siamese network for object tracking.", "Key Idea": "The authors propose a novel triplet loss that is added to the Siamese network framework to extract expressive deep features for object tracking. Triplet loss utilizes more elements for training to achieve a more powerful feature via the combination of original samples.", "Method": "The authors perform experiments on three real-time trackers based on the Siamese network and evaluate the proposed triplet loss on several popular tracking benchmarks.", "Outcome": "The proposed triplet loss outperforms the baseline trackers in terms of tracking accuracy while maintaining comparable accuracy with recent state-of-the-art real-time trackers. The proposed variants operate at almost the same frame-rate as the baseline trackers.", "Future Impact": "The proposed triplet loss could be applied to other tasks that require feature extraction from Siamese networks. Future work could explore other ways to combine different forms of losses to generate better features while maintaining good performance."}
{"id": "dd282632-ee41-45da-add8-d68d89c57e2d", "Context": "Classification activation map (CAM), utilizing the classification structure to generate pixel-wise localization maps, is a crucial mechanism for weakly supervised object localization (WSOL). However, CAM prefers to discern global discriminative factors rather than regional object cues, making it challenging to locate objects based on regional features.", "Key Idea": "The authors propose a plug-and-play mechanism called BagCAMs to improve the regional localization in WSOL without refining or re-training the baseline structure. BagCAMs adopts a proposed regional localizer generation (RLG) strategy to define a set of regional localizers to discern region-wise object factors for localization tasks. The regional localizers are effectively weighted to form the final localization map.", "Method": "The authors adopt BagCAMs to improve the performance of baseline WSOL methods and compare it with other state-of-the-art models on three WSOL benchmarks.", "Outcome": "The proposed BagCAMs mechanism improves the performance of baseline WSOL methods to achieve state-of-the-art results on three WSOL benchmarks.", "Future Impact": "N/A"}
{"id": "dfba01c5-a632-4394-8607-9a32f20e526c", "Context": "The paper presents a system that automatically builds a 3D scene model containing geometric information and photometric information under various illumination conditions, from real images.", "Key Idea": "To extract photometric information, the paper computes a low-dimensional linear space of the spatio-illumination volume, represented by a set of basis images.", "Method": "The authors use structure-from-motion and correlation-based stereo techniques to match pixels between images of different viewpoints and to reconstruct the scene in 3D space. The photometric property is extracted from images taken under different illumination conditions.", "Outcome": "The model can be used to create realistic renderings from different viewpoints and illumination conditions. Applications include object recognition, virtual reality, and product advertisement.", "Future Impact": "The approach presented in this paper can potentially be applied to other domains, and can improve object recognition and product advertisement industries."}
{"id": "ded9a095-d94d-4ccd-8825-283ec4bb7093", "Context": "There is increasing interest in adopting UX within corporate environments, and what competencies translate to effective UX design. This paper addresses the gap between pedagogy and UX practice through the lens of competence.", "Key Idea": "The paper explores how students perceive their own competence in UX design and how it shifts over time as they begin internships and full-time positions in UX. A co-construction of identity between designer and environment is proposed as a factor affecting competence.", "Method": "The authors conducted a 12-week longitudinal study of surveys and interviews with students and early professionals in UX and collected data on their competence level and factors influencing it.", "Outcome": "The study proposes a co-construction of identity between designer and environment as a factor affecting competence in UX over time. The paper emphasizes the importance of considering this relationship and various factors, including tool and representational knowledge, complexity, and corporate culture, when assessing competency in UX design.", "Future Impact": "The paper suggests opportunities for future research in building an understanding of competency in UX design based on the proposed co-construction of identity and considering various factors that influence it."}
{"id": "e1a191db-6463-4be9-883d-dfc7fb05c5f4", "Context": "The paper presents a novel dependency parsing method that enforces two structural properties on dependency trees to better represent the set of admissible dependency structures in treebanks.", "Key Idea": "The authors cast the problem of dependency parsing with bounded block degree and well-nestedness as an integer linear program that is solved using Lagrangian Relaxation. They derive a heuristic and an exact method based on a Branch-and-Bound search.", "Method": "The authors solve the Integer Linear Program using Lagrangian Relaxation from which they derive a heuristic and an exact method based on a Branch-and-Bound search. They compare their methods to a baseline unconstrained parser.", "Outcome": "Experimentally, the authors show that their methods are efficient and competitive compared to the baseline unconstrained parser while enforcing structural properties in all cases.", "Future Impact": "The proposed approach can better represent the set of admissible dependency structures in treebanks and connect dependency parsing to context-sensitive grammatical formalisms."}
{"id": "e58b9947-7a3a-414d-a0e8-d6cf02ed7127", "Context": "With recent advances in radio-frequency identification (RFID), wireless sensor networks, and Web-based services, physical things are becoming an integral part of the emerging ubiquitous Web.", "Key Idea": "The paper proposes a unified probabilistic based framework that fuses information across relationships between users and things to make more accurate recommendations, addressing the things recommendation problem in IoT. The framework exploits the merits of social relationships and thing-thing correlations, inheriting the matrix factorization's advantages.", "Method": "The proposed approach is validated based on an Internet of Things platform, and its effectiveness is demonstrated through experimental results.", "Outcome": "The experimental results demonstrate the feasibility and effectiveness of the proposed approach.", "Future Impact": "N/A"}
{"id": "e2466d98-98f9-41a8-8a38-e862adc2ed47", "Context": "This paper explores the importance of IT Governance models for public organizations, as well as serves as a basis for further research in IT Governance adoption models.", "Key Idea": "The authors present an IT Governance model that can be easily adopted by both practitioners and researchers. ", "Method": "The authors perform a literature review in IT Governance, as well as an empirical survey using a questionnaire based on COBIT 4.1 maturity model used to investigate IT Governance practice in multiple case studies from the Kingdom of Bahrain.", "Outcome": "The research will enable public sector organizations to adopt an IT Governance model in a simple and dynamic manner, which provides a clear focus for decision-making attention. The model provides a basis for further research in IT Governance adoption models.", "Future Impact": "The proposed IT Governance model can be adopted by public sector organizations in the future, which may improve IT Governance processes."}
{"id": "e827ee51-aafd-4f3b-99ca-60a5e289a555", "Context": "The paper addresses the PASCAL 2005 Recognizing Textual Entailment Challenge.", "Key Idea": "The authors aim to test the practicability of a purely logical approach for recognizing textual entailment. The authors extract atomic propositions from the text and the entailment hypothesis and express it in a custom logical notation.", "Method": "The authors use Link Parser to extract and encode the propositions. They detect independent entailment relations using Otter and WordNet.", "Outcome": "The proposed logical approach is successful in recognizing the entailment relation between the input text and hypothesis.", "Future Impact": "N/A"}
{"id": "e10b883a-ded6-4b4e-9934-6daba2d2f2b2", "Context": "Existing semantic hashing methods generate binary codes for documents based on similarity in a keyword feature space, which does not fully reflect semantic relationships that go beyond keyword matching. Tag information is often associated with documents in many real-world applications, but it has not been fully exploited yet.", "Key Idea": "The authors propose a new hashing approach called Semantic Hashing using Tags and Topic Modeling (SHTTM) to address the limitations in existing methods by incorporating tag information and similarity information from probabilistic topic modeling.", "Method": "The authors propose a unified framework that employs a formal latent factor model to ensure that hashing codes are consistent with tag information and preserve document topic/semantic similarity. An iterative coordinate descent algorithm is used for learning the optimal hashing codes. The authors conduct extensive empirical studies on four different datasets to demonstrate the advantages of the proposed SHTTM approach against several other state-of-the-art semantic hashing techniques.", "Outcome": "Experimental results indicate that the proposed SHTTM approach outperforms several other state-of-the-art semantic hashing methods on four different datasets. Furthermore, the combination of utilizing tag information and topic modeling in the unified framework obtains even better results.", "Future Impact": "The proposed SHTTM approach has potential applications in large-scale similarity search in various fields such as information retrieval and computer vision."}
{"id": "f23bdd28-b2d6-4a42-a56c-c9774f6451b5", "Context": "With the development of hypersonic vehicles in near space such as X-51A, HTV-2 and so on, tracking for them is becoming a new task and hotspot.", "Key Idea": "The paper introduces a learning tracking algorithm for hypersonic targets using the Sine model and IMM algorithm that learns the target tracking error characteristics to adjust the sampling rate adaptively.", "Method": "The proposed algorithm is compared with single accurate model algorithm and general IMM algorithms with fixed sampling rate through simulation experiments.", "Outcome": "Through the simulation experiments, it is proved that the proposed algorithm can effectively improve the tracking accuracy.", "Future Impact": "N/A"}
{"id": "ea414544-c89c-4039-8227-23b11e9a1239", "Context": "The paper presents a method to identify single-snippet answers to definition questions in question answering systems that supplement web search engines.", "Key Idea": "The authors propose a practically unsupervised learning method that leverages on-line encyclopedias and dictionaries to generate positive and negative definition examples, which are then used to train an SVM.", "Method": "The authors generate positive and negative definition examples using on-line encyclopedias and dictionaries. These examples are used to train an SVM to separate the two classes. The trained SVM is used to identify single-snippet answers to definition questions.", "Outcome": "The proposed method is experimentally shown to be viable, outperforming the alternative of training the system on questions and news articles from TREC. The proposed method helps the search engine handle definition questions significantly better.", "Future Impact": "N/A"}
{"id": "eb15ebe7-aa58-4a98-8f9e-939967c6359f", "Context": "The paper addresses the synchronization problem on multi-graphs, that are graphs with more than one edge connecting the same pair of nodes, where edges are labelled with the ratio of the incident vertices, and labels belong to a group.", "Key Idea": "The authors propose MultiSynch, a principled constrained eigenvalue optimization algorithm that can deal with any linear group, to address the multi-graph synchronization problem.", "Method": "The proposed MultiSynch algorithm is presented based on a constrained eigenvalue optimization technique. The authors evaluate the algorithm on both synthetic and real datasets.", "Outcome": "The authors prove empirically that the averaging approach is less precise and accurate than the proposed algorithm. MultiSynch shows better performance both on synthetic and real datasets.", "Future Impact": "N/A"}
{"id": "f41bfd75-a6b0-44d7-a842-b117797ebd7e", "Context": "The paper focuses on how to generate features from various data representations for efficient answer extraction. The authors mainly discuss feature generation in parse trees.", "Key Idea": "The authors propose and compare three methods to represent syntactic features in Support Vector Machines: feature vector, string kernel, and tree kernel.", "Method": "The authors conduct experiments on the TREC question answering task to compare the proposed feature generation methods. The contribution of individual features is also presented.", "Outcome": "The features generated from the more structured data representations significantly improve the performance based on the surface text features. However, the specific outcomes of the experiments are not provided.", "Future Impact": "N/A"}
{"id": "f2c9f8c3-f9d1-4cae-b7ae-a919ada1daaf", "Context": "Access to online visual search engines implies sharing of private user content -- the query images. Existing retrieval systems may not sufficiently protect the privacy of user images.", "Key Idea": "The authors introduce the concept of targeted mismatch attack for deep learning based retrieval systems to generate an adversarial image to conceal the query image.", "Method": "The authors design various loss functions for the adversarial image construction, including loss functions for unknown global pooling operation or input resolution by the retrieval system. They evaluate the attacks on standard retrieval benchmarks and compare the retrieved results with the original and adversarial image.", "Outcome": "The authors successfully generate adversarial images with very different content but lead to similar retrieval results on standard benchmarks. They also demonstrate successful attacks on partially unknown systems.", "Future Impact": "This paper highlights the privacy implications of online visual search engines and could lead to the development of more robust retrieval systems to better protect user privacy."}
{"id": "f3cef657-1887-42a7-9e11-8fdf54f8fa90", "Context": "This paper introduces kernel continual learning, a variant of continual learning that leverages the non-parametric nature of kernel methods to tackle catastrophic forgetting.", "Key Idea": "Kernel continual learning is introduced combining kernel methods with continual learning by episodically learning task-specific classifiers based on kernel ridge regression and by formulating kernel continual learning as a variational inference problem.", "Method": "Kernel continual learning is formulated as a variational inference problem to learn a data-driven kernel for each task by incorporating a random Fourier basis as the latent variable. The variational posterior distribution over the random Fourier basis is inferred from the coreset of each task. The authors perform extensive evaluation on four benchmarks.", "Outcome": "Experiments show the effectiveness and promise of kernels for continual learning as kernel continual learning systematically avoids task interference in the classifiers and achieves more efficient continual learning based on episodic memory.", "Future Impact": "Kernel continual learning is a promising direction for addressing catastrophic forgetting in continual learning and improving model efficiency. Further research may focus on evaluating this approach against more complex problems and exploring its limitations."}
{"id": "f32e53d5-c7f4-407e-a5cb-26fef230b5fd", "Context": "Matrix factorization is widely used for recommendation by learning latent embeddings of users and items from user-item interaction data. However, previous methods assume the learned embeddings are static or homogeneously evolving with the same diffusion rate.", "Key Idea": "The authors propose a dynamic matrix factorization model, Dynamic Bayesian Logistic Matrix Factorization (DBLMF), to learn heterogeneous user and item embeddings that are drifting with inconsistent diffusion rates.", "Method": "The authors extend logistic matrix factorization to model the probability a user would interact with an item at a given timestamp and a diffusion process to connect latent embeddings over time. An efficient Bayesian inference algorithm has also been proposed to make DBLMF scalable on large datasets.", "Outcome": "The proposed method has been extensively experimented on real datasets and is compared to the state-of-the-art methods, demonstrating its effectiveness.", "Future Impact": "DBLMF proposes a novel way to model drifting embeddings in recommendation systems and has been demonstrated to be effective in real datasets, signaling its potential to improve the quality of recommendations in various scenarios."}
{"id": "f32d6bc3-d75e-4e84-8bfa-3c83578281dc", "Context": "Transaction log analysis allows examination of both user commands and system responses when conducting an online information search. The objective is to monitor the extent to which systems are used and determine the actual user patterns when conducting an information search.", "Key Idea": "The authors propose transaction log analysis as a powerful methodology to discover how systems are used and assist in the improvement of existing and future systems.", "Method": "Machine-readable transaction log tapes from online catalogs are obtained and analyzed mathematically. This involves parsing user sessions, utilizing Markov chain analysis, and developing state transition probability matrices to illustrate the probability of proceeding from one state to another.", "Outcome": "The methodology allows for the monitoring and evaluation of information systems and can assist in system design. Patron use and system response patterns from several online public catalogs have been obtained by transaction log tapes.", "Future Impact": "The predictive power of the methodology may allow real-time aids to be developed for monitoring and evaluation of information systems."}
{"id": "f82f2e26-5437-4397-b781-50668ce5851b", "Context": "Alignment is trained in a previous stage as the translation model in Statistical Machine Translation (SMT) systems. Alignment model parameters are not tuned in function of the translation task but only indirectly.", "Key Idea": "The authors propose a novel framework for discriminative training of alignment models with automated translation metrics as maximization criterion, optimizing alignments for the translation task, and not needing link labels at the word level.", "Method": "The authors evaluate their framework in terms of automatic translation evaluation metrics to observe an improvement in translation quality.", "Outcome": "Evaluation of the proposed framework shows an observed improvement in translation quality.", "Future Impact": "The proposed framework may be applied to other machine translation models, leading to a more direct and optimized approach to achieve high-quality translations without the need for additional labeled data."}
{"id": "fb538ce2-abf4-4bd8-b35c-1bfe3ab9f48e", "Context": "The complex word identification task refers to the process of identifying difficult words in a sentence from the perspective of readers belonging to a specific target audience. This task has immense importance in the field of lexical simplification.", "Key Idea": "The authors propose two systems for identifying complex words using various lexical and semantic features.", "Method": "The authors developed one system using Naive Bayes and another based on Random Forest Classifiers. They incorporated rule-based processing techniques to improve the results.", "Outcome": "The Naive Bayes classifier based system achieves the maximum G-score of 76.7% for identifying complex words in SemEval-2016 shared task 11 after incorporating rule based post-processing techniques.", "Future Impact": "N/A"}
{"id": "f4f1bbaf-c1a2-44d5-8305-27235fa69d62", "Context": "There has been a lot of interest in the analysis of (social) networks, and with the growing complexity of heterogeneous data, feature-rich networks have emerged as a powerful modeling approach.", "Key Idea": "The tutorial provides a unified perspective on feature-rich networks, focusing on different modeling approaches, in particular multiplex and attributed networks, to devise novel algorithms and tools for the analysis of such networks.", "Method": "The tutorial outlines important principles, methods, and tools for the analysis of feature-rich networks, and provides future research directions in this emerging field.", "Outcome": "N/A", "Future Impact": "The tutorial could lead to the development of more effective methods and tools that enable better analysis of feature-rich networks, which could have implications for data science, data mining, web mining, and web science."}
{"id": "ffd14676-a525-479f-a74e-2c5d3a85c510", "Context": "There has been a recent revival of interest in parallel systems in which computation is performed by excitatory and inhibitory interactions within a network of relatively simple, neuronlike units. This paper considers the difficulties involved in representing shapes in parallel systems.", "Key Idea": "The authors suggest ways of representing shapes in parallel systems which provides a mechanism for shape perception and visual attention, and allows a novel interpretation of the Gestalt slogan.", "Method": "N/A", "Outcome": "N/A", "Future Impact": "The proposed mechanism for shape perception and visual attention can be extended to other domain-specific problems involving the representation of complex shapes such as in medical imaging, robotics, and autonomous driving."}
{"id": "f64fdfde-7e93-411b-865a-1e29d71c95b2", "Context": "Large-scale topic models are basic tools for feature extraction and dimensionality reduction in many applications. Hierarchical topic models (HTMs) can learn topics of various levels of abstraction leading to better generalization compared to their flat counterparts. Scalable systems for flat topic models cannot handle HTM due to their complicated data structures and susceptibility to local optima.", "Key Idea": "The authors study the hierarchical latent Dirichlet allocation (hLDA) model, propose an efficient partially collapsed Gibbs sampling algorithm for hLDA and an initialization strategy to deal with local optima introduced by tree-structured models. The authors also propose efficient data layout for vectorizing HTM as well as distributed data structures to address system challenges in building scalable systems for HTMs.", "Method": "The authors perform empirical studies to show the efficiency of their proposed system which is 87 times more efficient than previous open-source implementation for hLDA. The authors demonstrate their scalability on a 131-million-document corpus with 28 billion tokens. They extract 1,722 topics from the corpus with 50 machines in just 7 hours. ", "Outcome": "The proposed system is significantly more efficient than the previous open-source implementation for hLDA. The system can scale to thousands of CPU cores and can process a corpus 4-5 orders of magnitude larger than previously used. ", "Future Impact": "The proposed system can be used in practical applications such as feature extraction and dimensionality reduction for large datasets. The system can be further developed to address system challenges for other HTMs and for other statistical models beyond topic models."}
{"id": "feb75e1f-7838-48ca-9a78-cc31b717e5bf", "Context": "The paper discusses the problem of finding fraudulent content on a crowd-sourced review site due to businesses adding themselves to multiple websites to more easily be discovered. The existing work uses supervised machine learning and focuses only on textual and stylometry features.", "Key Idea": "The authors propose OneReview, a system for finding fraudulent content on a crowd-sourced review site, using correlations with other independent review sites and focusing on anomalous changes in a business’s reputation across multiple review sites.", "Method": "The authors utilize Change Point Analysis method on the reviews of every business independently on every website, and then use the proposed Change Point Analyzer to evaluate change-points, detect suspicious reviews, and identify them as fraudulent. They used crowd-labeling and k-cross validation to obtain 97% accuracy on their ground truth.", "Outcome": "The proposed model classified 61,983 Yelp reviews, about 8% of all reviews, as fraudulent. It identified 3,980 businesses with fraudulent reviews, as well as, 14,910 suspected spam, where at least 40% of their reviews are classified as fraudulent.", "Future Impact": "OneReview could be used to tackle fraudulent reviews on other platforms or to analyze the change in a business's reputation across different time periods or geographical regions."}
{"id": "fed7302a-43a7-412e-8ace-d07905e38c3c", "Context": "One-class collaborative filtering is difficult due to the challenge of interpreting and modeling the latent signal from the missing class. ", "Key Idea": "The authors propose a Bayesian generative model approach for implicit collaborative filtering that treats the latent signal as an unobserved random graph connecting users with items they might have encountered.", "Method": "The authors use stochastic gradient descent and mean field variational inference over random graph samples for large-scale distributed learning, and compare the proposed model to a state-of-the-art baseline on real-world data.", "Outcome": "The proposed model achieves better performance than the state-of-the-art baseline on real-world data.", "Future Impact": "The proposed model can be used to improve one-class collaborative filtering in real-world systems such as the Xbox Live architecture. Future work could explore applying this model to other recommendation systems."}
{"id": "9821d5f7-72b0-4841-a54f-d2af4a04ea3a", "Context": "The paper addresses the problem of inverse rendering where estimating the spherical harmonic illumination coefficients and texture parameters in a specular invariant colour subspace is challenging.", "Key Idea": "The authors propose a novel approach for inverse rendering based on a linear basis approximation of surface texture, which can account for non-Lambertian specular reflectance and complex illumination of the same light source colour.", "Method": "The proposed approach involves fitting a 3D morphable model to a single colour image of faces through the solution of bilinear equations in a specular invariant colour subspace. This approach recovers statistical texture model parameters without relying on computationally expensive analysis-by-synthesis techniques.", "Outcome": "The proposed approach recovers texture model parameters with an accuracy comparable to that of more computationally expensive methods, while requiring only the solution of convex optimization problems.", "Future Impact": "The proposed approach could be extended to other objects besides faces, potentially offering a more efficient and accurate solution to the problem of inverse rendering."}
