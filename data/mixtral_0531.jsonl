{"id": "01f161fe-dd40-45dd-89bd-fb1562771d73", "Context": "Event forecasting is an important task for applications such as automated analysis generation and resource allocation. However, capturing contextual information within event forecasting is challenging due to several factors such as uncertainty of context structure, high dimensional features, and adaptation of features over time.", "Key Idea": "The authors propose a novel graph convolutional network that extracts and learns graph representations from historical/prior event documents to predict the occurrence of future events and identify sequences of dynamic graphs as event context.", "Method": "The authors perform experiments on multiple real-world data sets to evaluate the proposed graph convolutional network against various state-of-the-art methods for social event prediction.", "Outcome": "Experimental results show that the proposed method is competitive against various state-of-the-art methods for social event prediction.", "Future Impact": "N/A"}
{"id": "07c3daea-a88c-4a67-9aac-20ef0ec62e79", "Context": "Non-pharmacological interventions, such as reminiscence and biographical cognitive stimulation practices, are common and effective for people with dementia. However, obtaining and maintaining biographical or personalized materials can be challenging.", "Key Idea": "The authors created a web platform that supports the work of psychologists in collecting and managing biographical materials for use in reminiscence and other biographical cognitive stimulation practices.", "Method": "The authors conducted a case study with one psychologist and three patients, using the platform for a period of two weeks.", "Outcome": "The results of the case study showed improvements in the collection of meaningful data about a person and in maintaining awareness of the therapy as a whole.", "Future Impact": "The platform has the potential to be widely adopted in the field of dementia care, improving the quality and efficiency of non-pharmacological interventions."}
{"id": "081d6673-3c7c-4aec-b101-cf55d75ac718", "Context": "Previous partial permutation synchronization (PPS) algorithms for multi-object matching involve computation-intensive and memory-demanding matrix operations which become intractable for large scale structure-from-motion datasets.", "Key Idea": "The authors propose a new algorithm, CEMP-Partial, for estimating the corruption levels of the observed partial permutations, which allows for the implementation of a nonconvex weighted projected power method without spectral initialization.", "Method": "The authors prove that under adversarial corruption, with certain assumptions, CEMP-Partial is able to exactly classify corrupted and clean partial permutations and demonstrate the state-of-the-art accuracy, speed and memory efficiency of the method on both synthetic and real datasets.", "Outcome": "The new PPS algorithm, MatchFAME, only involves sparse matrix operations and enjoys lower time and space complexities in comparison to previous PPS algorithms.", "Future Impact": "N/A"}
{"id": "0b31e456-4944-47e5-80ed-deaf6421c375", "Context": "The development of user interface design tools is based on Katou's (1986) method of verbal data collection, 'question-asking protocols.'", "Key Idea": "The authors propose 'directed dialogue protocols', an extension to the question-asking method that includes an experimental procedure of atomic tasks, interventions by the experimenter, and a technique for answering subject queries called sequential disclosure.", "Method": "N/A", "Outcome": "The proposed method has identified design choices which build learnability and usability into a product's user-interface.", "Future Impact": "N/A"}
{"id": "10c15fe5-c315-4b6d-8910-e6bc3279c817", "Context": "Most existing methods for incremental social event detection learn limited amounts of knowledge as they ignore the rich semantics and structural information contained in social data and cannot memorize previously acquired knowledge.", "Key Idea": "The authors propose a novel Knowledge-Preserving Incremental Heterogeneous Graph Neural Network (KPGNN) for incremental social event detection that models complex social messages into unified social graphs to facilitate data utilization and explores the expressive power of GNNs for knowledge extraction.", "Method": "The authors use KPGNN to detect social events by adopting contrastive loss terms that cope with a changing number of event classes, leveraging the inductive learning ability of GNNs to efficiently detect events and extend its knowledge from previously unseen data, and using a mini-batch subgraph sampling strategy for scalable training.", "Outcome": "KPGNN requires no feature engineering, has few hyperparameters to tune and extensive experiment results demonstrate the superiority of KPGNN over various baselines.", "Future Impact": "N/A"}
{"id": "14b0ebd1-b654-4eed-bdd8-ebeb74250b15", "Context": "In few-shot relational triple extraction (FS-RTE), the goal is to extract relational triples from plain texts using only a few annotated samples. Previous work extracts all entities and then classifies their relations, which ignores the entity discrepancy between relations.", "Key Idea": "The authors propose a novel task decomposition strategy called Relation-then-Entity (RelATE) for FS-RTE. It first detects relations in a sentence and then extracts the corresponding head/tail entities of the detected relations.", "Method": "The authors propose a model called RelATE that builds a dual-level attention to aggregate relation-relevant information to detect the relation occurrence and uses the annotated samples of the detected relations to extract the corresponding head/tail entities.", "Outcome": "The proposed model outperforms previous work by an absolute gain of 18.98% and 28.85% in F1 in two few-shot settings.", "Future Impact": "N/A"}
{"id": "16c1b4ae-73f8-4c23-8bdb-b931ade1baa5", "Context": "Various decision making tasks require selecting a preferred subset of items from a given set of feasible items, and recent work has considered methods for specifying such preferences based on the attribute values of individual elements within the set.", "Key Idea": "This paper proposes new algorithms for computing an optimal subset given a specification, based on direct set construction, and implicit enumeration as solutions to appropriate CSPs.", "Method": "The authors present new algorithms in each class and compare them empirically against previous results.", "Outcome": "The authors show that the problem is NP-hard in the general case and that heuristic search methods are necessary.", "Future Impact": "The proposed algorithms may improve or extend the current state-of-the-art in solving the problem of computing an optimal subset given a specification."}
{"id": "18f27ced-9f37-45d7-9b76-6663c349d408", "Context": "Most existing cross-modal retrieval approaches learn a common subspace in a joint manner, where the data from all modalities have to be involved during the whole training process, and the optimal parameters of different modality-specific transformations are dependent on each other. These approaches require the whole model to be retrained when handling samples from new modalities.", "Key Idea": "The authors propose a novel cross-modal retrieval method called Scalable Deep Multimodal Learning (SDML) that predefines a common subspace in which the between-class variation is maximized while the within-class variation is minimized. It trains modality-specific networks independently to transform the multimodal data into the predefined common subspace, which can be scalable to the number of modalities.", "Method": "The authors train m modality-specific networks for m modalities (one network for each modality) to transform the multimodal data into the predefined common subspace. They conduct comprehensive experimental results on four widely-used benchmark datasets to evaluate the effectiveness and efficiency of the proposed method.", "Outcome": "The proposed SDML method is effective and efficient in multimodal learning and outperforms the state-of-the-art methods in cross-modal retrieval.", "Future Impact": "N/A"}
{"id": "192f7803-df4d-40c0-b816-ba34339026b3", "Context": "Most current single image SR methods use empirical risk minimization, often with a pixel-wise mean squared error (MSE) loss. However, the outputs from such methods tend to be blurry, over-smoothed and generally appear implausible.", "Key Idea": "The authors introduce new methods for amortized MAP inference, where they calculate the MAP estimate directly using a convolutional neural network. They propose a neural network architecture that performs a projection to the affine subspace of valid SR solutions, and propose three methods to solve the optimization problem: Generative Adversarial Networks (GAN), denoiser-guided SR, and a baseline method using a maximum-likelihood-trained image prior.", "Method": "The authors perform experiments using the proposed amortized MAP inference methods on real image data and compare the results with the baseline method.", "Outcome": "The experiments show that the GAN based approach performs best on real image data.", "Future Impact": "The authors establish a connection between GANs and amortized variational inference as in e.g. variational autoencoders."}
{"id": "1946f496-f6cd-4736-8c30-a6ae70baa8b2", "Context": "Existing click models treat intrinsic relevance as an atomic query-document-specific parameter, which is solely estimated from historical clicks without using any content information about a document or relationship among the clicked/skipped documents under the same query. This leads to limitations in fully exploring the information about a document's relevance quality and making predictions for unseen documents.", "Key Idea": "The authors propose a novel Bayesian Sequential State model for click modeling that characterizes document content and dependencies among sequential click events within a query by a set of descriptive features via a probabilistic graphical model.", "Method": "The authors apply the posterior regularized Expectation Maximization algorithm for parameter learning and tailor the model to meet specific ranking-oriented properties, such as pairwise click preferences.", "Outcome": "Experiment results on a large set of real click logs demonstrate the effectiveness of the proposed model compared with several state-of-the-art click models.", "Future Impact": "N/A"}
{"id": "1b0e4045-d39b-4bea-8dec-e747f5c674f5", "Context": "Data uncertainty is inherent in applications such as sensor monitoring systems, location-based services, and biological databases. To manage this vast amount of imprecise information, probabilistic databases have been recently developed.", "Key Idea": "The authors propose two efficient algorithms for the discovery of frequent patterns and association rules from probabilistic data under the Possible World Semantics, which can be extended to discover maximal frequent patterns.", "Method": "The authors propose bottom-up and top-down algorithms for discovering frequent patterns and association rules from probabilistic data.", "Outcome": "The proposed algorithms were validated through extensive experiments using real and synthetic datasets.", "Future Impact": "N/A"}
{"id": "1dea5ec2-d311-4c03-bba5-e38d7a62fbd4", "Context": "The problem of spotting a set of signs occurring in videos with sequences of signs is tackled in this paper.", "Key Idea": "The authors propose to model the spatio-temporal signatures of a sign using an extension of sequential patterns that contain temporal intervals called Sequential Interval Patterns (SIP) and a novel multi-class classifier that organises different sequential interval patterns in a hierarchical tree structure called a Hierarchical SIP Tree (HSP-Tree).", "Method": "The authors evaluate the proposed method on both concatenated sequences of isolated signs and continuous sign sequences and show that the proposed method is superior in robustness and accuracy to a state of the art sign recogniser when applied to spotting a sequence of signs.", "Outcome": "The proposed HSP-Forest classifier is shown to be superior in robustness and accuracy to a state of the art sign recogniser when applied to spotting a sequence of signs.", "Future Impact": "N/A"}
{"id": "1e396f93-a73e-4d33-9a8e-56097a8c3c28", "Context": "Deep learning has yielded state-of-the-art performance on natural language processing tasks including named entity recognition (NER), but it typically requires large amounts of labeled data.", "Key Idea": "The authors demonstrate that the amount of labeled training data can be drastically reduced when deep learning is combined with active learning. They also propose a lightweight CNN-CNN-LSTM model for NER.", "Method": "The authors perform incremental active learning during the training process and apply the proposed model to standard datasets for NER.", "Outcome": "The proposed CNN-CNN-LSTM model achieves nearly state-of-the-art performance on standard datasets for NER while being computationally more efficient than best performing models. The authors are able to nearly match state-of-the-art performance with just 25% of the original training data.", "Future Impact": "N/A"}
{"id": "1e5571af-71cf-40b8-ba2a-18b42cae5b42", "Context": "Sequence mining is the task of extracting meaningful patterns from a sequence of data. Existing sequence mining techniques do not make use of background knowledge.", "Key Idea": "The authors propose a framework for knowledge-based sequence mining using Answer Set Programming (ASP) that allows for the incorporation of background knowledge.", "Method": "The authors demonstrate the ease of extracting condensed patterns using modular extensions of the basic ASP-based approach. They also show how ASP's preference handling capacities can be exploited for mining patterns of interest.", "Outcome": "An empirical study is provided that compares the proposed ASP-based sequence mining approach with a related sequence mining mechanism.", "Future Impact": "N/A"}
{"id": "1ef9b762-e9be-46c5-ad19-090fe16200c4", "Context": "In human-robot interaction, accurately deriving pointing information from a corresponding gesture is an important issue.", "Key Idea": "The authors propose a novel approach that takes into account prior information about the location of possible pointing targets and uses Dempster-Shafer theory of evidence to fuse information from head pose and hand pointing orientation.", "Method": "The authors perform detailed experimental results that validate the effectiveness of the method in realistic application setups.", "Outcome": "The proposed method is able to accurately derive pointing information from a corresponding gesture in realistic application setups.", "Future Impact": "N/A"}
{"id": "2065b977-7782-4981-ad70-3121a2315687", "Context": "In automatic speech recognition, unsupervised language model adaptation is a common problem. The existing methods use unigram LSA for unsupervised LM adaptation.", "Key Idea": "The authors propose a correlated bigram LSA approach for unsupervised LM adaptation which is trained using efficient variational EM and smoothed using fractional Kneser-Ney smoothing. The authors also address the scalability issue to large training corpora by bootstrapping of bigram LSA from unigram LSA.", "Method": "The authors train the correlated bigram LSA model using efficient variational EM and smoothed it using the proposed fractional Kneser-Ney smoothing. The authors address the scalability issue to large training corpora by bootstrapping of bigram LSA from unigram LSA. For LM adaptation, unigram and bigram LSA are integrated into the background N-gram LM via marginal adaptation and linear interpolation respectively.", "Outcome": "Experimental results on the Mandarin RT04 test set show that applying unigram and bigram LSA together yields 6%-8% relative perplexity reduction and 2.5% relative character error rate reduction which is statistically significant compared to applying only unigram LSA. On the large-scale evaluation on Arabic, 3% relative word error rate reduction is achieved which is also statistically significant.", "Future Impact": "N/A"}
{"id": "206d2d53-dbaf-4a2f-810d-856309d8eb83", "Context": "Existing head reenactment systems rely on explicit pose representations, such as facial landmarks or 3D head pose parameters, which are often obtained through external pose estimation algorithms.", "Key Idea": "The authors propose a neural head reenactment system driven by a learned latent pose representation, which is capable of predicting the foreground segmentation alongside the RGB image.", "Method": "The authors train the reenactment system using only image reconstruction losses. The authors test the learned descriptors on pose-related tasks such as keypoint prediction and pose-based retrieval.", "Outcome": "The proposed system is able to reproduce mimics of the driving person and perform cross-person reenactment.", "Future Impact": "The learned descriptors can be used for other pose-related tasks, such as keypoint prediction and pose-based retrieval."}
{"id": "24e29617-a320-450a-aaa5-19d8700d74b7", "Context": "The need for an efficient parallel distributed algorithm for matrix completion that can handle large-scale data and is scalable.", "Key Idea": "The authors propose a new decentralized algorithm called NOMAD (Non-locking, stOchastic Multi-machine algorithm for Asynchronous and Decentralized matrix completion) that uses asynchronous, non-blocking communication between processors and asynchronously transfers the ownership of a variable between processors in a decentralized fashion.", "Method": "The authors perform extensive empirical evaluation of NOMAD on commodity hardware and on a HPC cluster in both multi-core and distributed memory settings.", "Outcome": "NOMAD outperforms synchronous algorithms that require explicit bulk synchronization after every iteration, as shown in the empirical evaluation.", "Future Impact": "NOMAD can potentially be used in various applications that require efficient and scalable matrix completion, such as in recommendation systems, image and video processing, and sensor networks."}
{"id": "29dd9fd3-6c98-4e4b-b70c-0474ff361419", "Context": "Building a deformable shape model for a new species is not always possible due to the lack of 3D data, and there is no accurate shape model available for birds.", "Key Idea": "The authors propose a method to capture new species using an articulated template and images of that species, and learn a shape space that captures variation both among species and within each species from image evidence.", "Method": "The authors fit the articulated template to each training sample and use a low-dimensional embedding to learn a 3D shape space that better reflects the phylogenetic relationships among birds than learned perceptual features.", "Outcome": "The authors learn models of multiple species from the CUB dataset, and contribute new species-specific and multi-species shape models that are useful for downstream reconstruction tasks.", "Future Impact": "N/A"}
{"id": "2a220303-8653-497f-b2b5-c829583c2714", "Context": "Counting and sampling directed acyclic graphs (DAGs) from a Markov equivalence class are fundamental tasks in graphical causal analysis. These tasks have been considered open problems in the area.", "Key Idea": "The authors present polynomial-time algorithms for counting and sampling DAGs from a Markov equivalence class, solving a long-standing open problem.", "Method": "The authors perform experiments comparing their algorithms to state-of-the-art methods.", "Outcome": "The experimental results show that the proposed algorithms significantly outperform state-of-the-art methods.", "Future Impact": "N/A"}
{"id": "2b5cc037-4841-4fb1-85ff-673230198be1", "Context": "Matrix completion is the problem of recovering an incomplete matrix of rank r with columns arriving online over time. This problem is widely applied to recommendation systems, computer vision, and system identification. Prior work in this area has focused on developing algorithms for the noiseless case, but there is a need for algorithms that can tolerate a large amount of noise.", "Key Idea": "The authors propose two algorithms for matrix completion that can tolerate noise and are provable under two realistic noise models. The algorithms are adaptive and perform well experimentally in both synthetic and real-world datasets.", "Method": "The authors present an algorithm for bounded deterministic noise that returns a matrix of small error with sample complexity almost as small as the best prior results in the noiseless case. The authors also present an algorithm for sparse random noise that recovers an μ0-incoherent matrix with high probability and small sample complexity.", "Outcome": "The first algorithm achieves strong guarantee under bounded deterministic noise and the second algorithm achieves strong guarantee under sparse random noise. Both algorithms perform well experimentally in both synthetic and real-world datasets.", "Future Impact": "N/A"}
{"id": "2eb66e5a-472c-4db1-b02f-47fe5eb7e71e", "Context": "Previous work on generative models for text generation rely on syntactic and semantic information such as constituency parses or paraphrase pairs. However, this information can be difficult to obtain and may not always be available.", "Key Idea": "The authors propose a generative model, called QKVAE, that exhibits disentangled latent representations of syntax and semantics without relying on any external syntactic or semantic information, but instead uses the inductive bias found in attention-based architectures such as Transformers.", "Method": "The authors use Attention in the decoder of QKVAE to read latent variables where one latent variable infers keys while another infers values. The authors run experiments on latent representations and syntax/semantics transfer to show that QKVAE displays clear signs of disentangled syntax and semantics.", "Outcome": "The experiments show that QKVAE displays competitive syntax transfer capabilities when compared to supervised models and that comparable supervised models need a fairly large amount of data (more than 50K samples) to outperform it on both syntactic and semantic transfer.", "Future Impact": "N/A"}
{"id": "31ab88b5-e66f-4b69-98b6-7a470dce9875", "Context": "Conditional neural networks play an important role in a number of sequence-to-sequence modeling tasks, including personalized sound enhancement (PSE), speaker dependent automatic speech recognition (ASR), and generative modeling such as text-to-speech synthesis. In conditional neural networks, the output of a model is often influenced by a conditioning vector, in addition to the input. Common approaches of conditioning include input concatenation or modulation with the conditioning vector, which comes at a cost of increased model size.", "Key Idea": "The authors propose a novel approach of neural network conditioning by learning intermediate layer activations based on the conditioning vector.", "Method": "The authors systematically explore and evaluate the proposed conditioning method on the task of PSE and personalized ASR in single speaker scenarios.", "Outcome": "The proposed method is able to produce conditional models with comparable or better quality, while decreasing model sizes.", "Future Impact": "The proposed conditioning method has a broad applicability across a number of application domains and can make the models ideal candidates for resource-efficient on-device deployment."}
{"id": "36d7073a-d006-4a4a-850f-ca7a3f0ca19b", "Context": "Many important problems can be framed as learning from graph data, but there is a lack of a general framework for learning convolutional neural networks for arbitrary graphs with discrete and continuous node and edge attributes.", "Key Idea": "The authors propose a framework for learning convolutional neural networks for arbitrary graphs, by extracting locally connected regions from graphs.", "Method": "The authors demonstrate the proposed framework on established benchmark data sets and compare the learned feature representations with state-of-the-art graph kernels.", "Outcome": "The learned feature representations are competitive with state-of-the-art graph kernels and their computation is highly efficient.", "Future Impact": "N/A"}
{"id": "370141c7-e1bb-4010-9938-efcad6cf2e62", "Context": "Innovations in neural architectures have fostered significant breakthroughs in language modeling and computer vision, but these novel architectures often result in challenging hyper-parameter choices and training instability if the network parameters are not properly initialized.", "Key Idea": "The authors propose GradInit, an automated and architecture agnostic method for initializing neural networks. GradInit adjusts the norm of each network layer so that a single step of SGD or Adam with prescribed hyperparameters results in the smallest possible loss value.", "Method": "The authors introduce a scalar multiplier variable in front of each parameter block and optimize these variables using a simple numerical scheme.", "Outcome": "GradInit accelerates the convergence and test performance of many convolutional architectures, both with or without skip connections, and even without normalization layers. It also improves the stability of the original Transformer architecture for machine translation, enabling training it without learning rate warmup using either Adam or SGD under a wide range of learning rates and momentum coefficients.", "Future Impact": "N/A"}
{"id": "37da719b-8db9-4523-8a4a-3f2eef238978", "Context": "Fragile watermarking methods often use authentication bits to detect tampering, but this can lead to false positives and negatives. Robust spread spectrum based watermarking schemes have been proposed but do not allow for image recovery.", "Key Idea": "The authors propose a fragile watermarking method using self-embedding for tampered image recovery that does not use authentication bits, and combines robust spread spectrum based watermarking, block based embedding, and DCT based compression.", "Method": "The authors perform simulations to test the recovery performance of the proposed watermarking method.", "Outcome": "The proposed watermarking method is able to recover tampered images with high fidelity.", "Future Impact": "The proposed watermarking method could be used in applications where image integrity needs to be ensured and tampered images need to be recovered."}
{"id": "3ac464c2-2214-4bf2-a6b6-03da2498cb03", "Context": "Query scheduling in database management systems has received renewed attention due to the rise of the DaaS model for database deployment, with most research focusing on scheduling algorithms.", "Key Idea": "This paper investigates the use of histograms describing the distribution of likely query execution times as input to the query scheduler and proposes a novel distribution-based scheduling algorithm called Shepherd.", "Method": "The authors perform extensive experimentation with both synthetic and TPC workloads to compare the performance of Shepherd with state-of-the-art point-based methods.", "Outcome": "The results show that Shepherd substantially outperforms state-of-the-art point-based methods.", "Future Impact": "N/A"}
{"id": "3b076d81-3ed0-4d57-84e8-4145f67052bd", "Context": "Referring expressions and other object descriptions can lead to unwanted conversational implicatures if they do not follow the Local Brevity, No Unnecessary Components, and Lexical Preference preference rules.", "Key Idea": "The authors propose a polynomial time generation algorithm that incorporates the Local Brevity, No Unnecessary Components, and Lexical Preference preference rules.", "Method": "The authors compare the computational complexity of incorporating the preference rules into a generation algorithm against alternative formalizations of conversational implicature.", "Outcome": "The authors find that incorporating the preference rules into a generation algorithm is polynomial time, while some alternative formalizations of conversational implicature make the generation task NP-Hard.", "Future Impact": "N/A"}
{"id": "3b6e7572-2ef8-4565-a3b7-301a3fd38acd", "Context": "Backward locking and update locking are well-known sources of inefficiency in backpropagation that prevent from concurrently updating layers. Several works have suggested using local error signals to train network blocks asynchronously to overcome these limitations.", "Key Idea": "The authors propose a differentiable search algorithm named SEDONA to automate the process of finding the best configuration for local training, including how to decouple network blocks and which auxiliary networks to use for each block.", "Method": "The authors perform experiments on VGG and ResNet variants with CIFAR-10, Tiny-ImageNet and ImageNet datasets. They compare the performance of the proposed algorithm to end-to-end backpropagation and other state-of-the-art greedy-learning methods.", "Outcome": "The proposed algorithm can consistently discover transferable decoupled architectures for VGG and ResNet variants. It significantly outperforms the ones trained with end-to-end backpropagation and other state-of-the-art greedy-learning methods in CIFAR-10, Tiny-ImageNet and ImageNet. It also reports up to 2× speedup over backpropagation in total training time.", "Future Impact": "N/A"}
{"id": "4164fd9a-7ab8-4013-b416-a205231f10f2", "Context": "Plan recognition is the problem of inferring the goals and plans of an agent after observing its behavior. Recent approaches use slightly modified planning algorithms to solve this problem without a plan library, assuming actions have deterministic effects and both agent and observer have complete information about the initial state.", "Key Idea": "This paper extends the approach to probabilistic plan recognition by defining the probability of a partially observed execution given a goal in terms of the cost difference of achieving the goal under two conditions: complying with the observations, and not complying with them.", "Method": "The authors use two calls to a classical planner to compute the cost difference and the posterior goal probabilities, without modifying the planner in any way.", "Outcome": "The authors consider a number of examples to illustrate the quality, flexibility, and scalability of the approach.", "Future Impact": "N/A"}
{"id": "432f5702-7b7d-4995-812e-40925f1a18dd", "Context": "Multiple output prediction is a central problem in machine learning, where y is high dimensional and x is either low or high dimensional. The one vs. all approach and several sophisticated multiple output prediction methods have been used.", "Key Idea": "The authors propose a new method for multiple output prediction that involves selecting a small subset of yL dimensions of y and modeling (i) x → yL and (ii) yL → y.", "Method": "The authors perform experiments on multilabel classification and multivariate regression datasets using the proposed method.", "Outcome": "The proposed method outperforms the one vs. all approach as well as several sophisticated multiple output prediction methods.", "Future Impact": "N/A"}
{"id": "438caf1c-5c7e-4283-a3cd-bbab302df185", "Context": "Common acquisition functions for active learning use either uncertainty or diversity sampling, aiming to select difficult and diverse data points from the pool of unlabeled data, respectively.", "Key Idea": "The authors propose an acquisition function, CAL (Contrastive Active Learning), that selects contrastive examples, i.e. data points that are similar in the model feature space and yet the model outputs maximally different predictive likelihoods.", "Method": "The authors compare the proposed acquisition function, CAL, with a diverse set of acquisition functions in four natural language understanding tasks and seven datasets. The authors also conduct an extensive ablation study of their method and analyze all actively acquired datasets.", "Outcome": "The proposed acquisition function, CAL, performs consistently better or equal than the best performing baseline across all tasks, on both in-domain and out-of-domain data.", "Future Impact": "N/A"}
{"id": "45b76955-9670-4664-939c-f5a61eb597df", "Context": "The state of the art in auditing group fairness in ranked lists assumes a logarithmic loss in importance as a function of the rank, and does not account for varying user behaviors or non-binary protected attributes.", "Key Idea": "The authors propose a novel metric for auditing group fairness in ranked lists that models user attention through parametrization and allows non-binary protected attributes.", "Method": "The authors perform three simulated fairness audits using the proposed metric to show that determining fairness of a ranked output necessitates knowledge of the end-users of the particular service.", "Outcome": "The proposed metric is able to better address the human factors inherent in the problem by measuring the whole sociotechnical system, consisting of a ranking algorithm and individuals using it.", "Future Impact": "N/A"}
{"id": "48bacac1-1ca9-4be8-90e6-470596de0e26", "Context": "Recognizing polarity in sentiment analysis requires a list of polar words and phrases. Many studies have investigated (semi-) unsupervised methods of learning polarity of words and phrases.", "Key Idea": "The authors propose a method of building a sentiment analysis lexicon by using structural clues to extract polar sentences from Japanese HTML documents and developing these structural clues to achieve high precision.", "Method": "The authors use a massive collection of HTML documents and extract polar sentences using structural clues. These polar sentences are then used to build a lexicon for sentiment analysis.", "Outcome": "N/A", "Future Impact": "The proposed method of building a sentiment analysis lexicon can be used for other languages and can be applied to other NLP tasks such as opinion mining and subjectivity analysis."}
{"id": "49309d5a-5959-4f8f-ae30-9fd2350f0cbc", "Context": "Existing compression techniques for deep convolutional neural networks (CNNs) struggle to be computationally friendly, despite excelling at reducing model sizes. This is due to the enormous amount of memory and compute resources required by CNNs.", "Key Idea": "The authors present a novel quantization strategy called focused quantization based on power-of-two values that exploits the weight distributions after fine-grained pruning. The method dynamically discovers the most effective numerical representation for weights in layers with varying sparsities.", "Method": "The authors replace multiplications in quantized CNNs with bit-shift operations for efficient inference and couple it with lossless encoding to build a compression pipeline. The authors evaluate the proposed method on ResNet-50 and ResNet-18.", "Outcome": "The proposed method achieves a 18.08x compression ratio (CR) in ResNet-50 with only 0.24% loss in top-5 accuracy, outperforming existing compression methods. The authors found that a fully compressed ResNet-18 is not only higher in CR and top-5 accuracy but also more hardware efficient.", "Future Impact": "N/A"}
{"id": "4e6f8004-9384-4c5c-8d7f-265410a290df", "Context": "Deep learning methods have been proposed for completing partial data from shape acquisition setups, but these methods only complete the partial shape with a single output, ignoring the ambiguity when reasoning the missing geometry.", "Key Idea": "The authors pose a multimodal shape completion problem, in which they seek to complete the partial shape with multiple outputs by learning a one-to-many mapping. The authors develop a method that completes the partial shape via conditional generative modeling, without requiring paired training data.", "Method": "The authors evaluate the approach on several datasets that contain varying forms of shape incompleteness, and compare among several baseline methods and variants of their methods qualitatively and quantitatively.", "Outcome": "The proposed method demonstrates the merit of completing partial shapes with both diversity and quality.", "Future Impact": "N/A"}
{"id": "4fdcceeb-f50f-4c4f-8b92-5985498114f8", "Context": "Recovering the three-dimensional motion of a non-rigid object from a sequence of stereo images is a challenging problem. The object undergoes uniform expansion, three-dimensional shearing about an unknown point in space, and rigid motion. Feature correspondence over multiple frames is assumed.", "Key Idea": "The authors propose a novel solution to the problem of recovering the three-dimensional motion of a non-rigid object from a sequence of stereo images using algebraic geometry, the commutative algebra software package MACAULAY, and the Fortran polynomial continuation program POLSYS.", "Method": "The authors reduce the problem of recovering the three-dimensional motion uniquely to the solution of a set of homogeneous polynomial equations. The authors use the MACAULAY and POLSYS software packages to solve the polynomial equations.", "Outcome": "The proposed solution is shown to determine the motion uniquely with only two (stereo) snapshots and four points correspondence.", "Future Impact": "N/A"}
{"id": "532e797a-4b72-488a-80e4-03713d3c8435", "Context": "The traditional idea of using linear low-order or low-rank shape model for the task of Non-Rigid Structure-from-Motion (NRSfM) has been used. However, this method may not be effective for long monocular video sequences observing a non-rigid object performing recurrent and possibly repetitive dynamic action.", "Key Idea": "The authors propose a new method for NRSfM that exploits the property of shape recurrency, which is a generalized rigidity, and reduces NRSfM problems to rigid ones provided that certain recurrency condition is satisfied.", "Method": "The authors develop efficient algorithms for automatic recurrency detection, as well as camera view clustering via a rigidity-check to implement this idea as a practical approach.", "Outcome": "Experiments on both simulated sequences and real data demonstrate the effectiveness of the method.", "Future Impact": "This paper offers a novel perspective on rethinking structure-from-motion, and the authors hope it will inspire other new problems in the field."}
{"id": "56992082-e04e-4a8b-a985-abfea27fc2e0", "Context": "Dynamic network pruning is a method to achieve runtime acceleration by dynamically determining the inference paths based on different inputs. However, previous methods directly generate continuous decision values for each weight channel, which cannot reflect a clear and interpretable pruning process.", "Key Idea": "The authors propose a method that explicitly models the discrete weight channel selections, which encourages more diverse weights utilization and achieves more sparse runtime inference paths. The authors also propose a novel adversarial example detection algorithm by discriminating the runtime decision features.", "Method": "The authors perform experiments on CIFAR10 and ImageNet datasets. They observe the differences in the layerwise decisions between normal and adversarial examples. They also apply the proposed dynamic network to adversarial example detection.", "Outcome": "The proposed dynamic network achieves higher prediction accuracy under the similar computing budgets on CIFAR10 and ImageNet datasets compared to traditional static pruning methods and other dynamic pruning approaches. The proposed adversarial detection algorithm can significantly improve the state-of-the-art detection rate across multiple attacks.", "Future Impact": "The proposed method can help to build an interpretable and robust model for adversarial example detection."}
{"id": "58279154-e623-46d2-a431-cc409e094e2c", "Context": "Previous approaches to analogy-driven theorem proving are limited and not cognitively adequate. Analogy is typically used to prove theorems by finding similarities between two problems.", "Key Idea": "The authors propose a model of analogy-driven theorem proving that works at the level of proof-plans and uses a source proof-plan to guide the construction of a proof-plan for the target problem, including a reformulation of the source proof-plan.", "Method": "The authors processed several well-known theorems using their analogy-driven proof-plan construction model.", "Outcome": "The proposed model was able to prove several theorems that could not be proven analogically by previous approaches.", "Future Impact": "N/A"}
{"id": "5a3da6ef-67b0-41bc-a994-fc5ff455a27b", "Context": "Online reviews play a crucial role in electronic commerce. However, pervasive spam reviews can mislead customers and defame decent stores. Existing methods did not examine a great portion of singleton reviews which can almost determine a store's rating and impression.", "Key Idea": "The authors propose to detect spam attacks via unusually correlated temporal patterns. They identify and construct multidimensional time series based on aggregate statistics to depict and mine such correlations and propose a hierarchical algorithm to robustly detect time windows where attacks are likely to have happened.", "Method": "The authors conduct experiments to detect singleton review attacks by mapping the problem to an abnormally correlated pattern detection problem.", "Outcome": "The proposed method is effective in detecting singleton review attacks. The authors discover that singleton review is a significant source of spam reviews and largely affects the ratings of online stores.", "Future Impact": "N/A"}
{"id": "5b47ca6b-ff9b-429c-adb1-ad9a171eea0e", "Context": "The problem of building style-adapted maximum entropy language models for speech recognition is addressed, where a large corpus of written language data and a small corpus of speech transcripts are given.", "Key Idea": "The authors investigate a recently proposed Bayesian adaptation method for building style-adapted maximum entropy language models.", "Method": "The authors perform experiments comparing the proposed Bayesian adaptation method to linear interpolation.", "Outcome": "The proposed Bayesian adaptation method outperforms linear interpolation in the experiments.", "Future Impact": "N/A"}
{"id": "5b9f94f9-d93f-455d-a110-007ad67ada6d", "Context": "Existing specification languages for tree-based grammars fail to adequately support identifier management.", "Key Idea": "The authors propose XMG (eXtensible Meta-Grammar) as a solution to the problem, which provides a sophisticated treatment of identifiers.", "Method": "N/A", "Outcome": "N/A", "Future Impact": "XMG can potentially be used in various natural language processing tasks that require tree-based grammars and identifier management."}
{"id": "5c268324-e160-489d-9722-6b59d5e3471b", "Context": "The abstract discusses the problem of lack of accessibility on the web, particularly for marginalized groups such as visually-impaired users.", "Key Idea": "The authors propose a new approach for achieving web accessibility through self-interested web designers and strategic knowledge acquisition mechanisms.", "Method": "N/A", "Outcome": "N/A", "Future Impact": "This approach may lead to a more accessible web, particularly for visually-impaired users, by incentivizing web designers to prioritize accessibility and providing them with the necessary knowledge to do so through mechanisms for eliciting knowledge from marginalized groups."}
{"id": "5d87de73-77d4-4efd-b8e1-d7561b13f69f", "Context": "The task of preposition sense disambiguation is a challenge in NLP, and previous systems have struggled to achieve high accuracy.", "Key Idea": "The authors propose a supervised classification approach that uses linguistically motivated features derived from both sides of the preposition and utilizes the phrase structure.", "Method": "The authors evaluate their system on the SemEval 2007 Preposition Sense Disambiguation datasets and compare its results to those of the systems participating in the workshop. They test the system with five different classifiers.", "Outcome": "The proposed system outperforms the best system in the SemEval task, achieving an increased accuracy.", "Future Impact": "N/A"}
{"id": "5dccca98-2b58-47e3-9b8f-3b1888aa3976", "Context": "The heterogeneity of today's IT environments and the increasing demands from mobile users are major obstacles for the creation of real-time data warehouses.", "Key Idea": "The authors propose a new middleware paradigm called Space-based computing that offers a level of abstraction superior to conventional middleware solutions and seamless integration of mobile devices using open standards.", "Method": "N/A", "Outcome": "N/A", "Future Impact": "The proposed Space-based computing paradigm has the potential to mobilize heterogeneous database and realize the real-time data warehouse vision."}
{"id": "5e1f387c-d883-4d1f-8397-e4a533a3387b", "Context": "Hyperspectral imaging is used in various fields but it is affected by different sources of degradation, and the lack of accurate ground-truth makes restoration tasks challenging. Training deep neural networks for restoration is difficult in contrast to traditional RGB imaging problems.", "Key Idea": "The authors propose a hybrid approach based on sparse coding principles that retain the interpretability of classical techniques encoding domain knowledge with handcrafted image priors, while allowing to train model parameters end-to-end without massive amounts of data.", "Method": "The authors perform experiments on various denoising benchmarks to show the computational efficiency and the performance of the proposed method.", "Outcome": "The proposed method is computationally efficient and significantly outperforms the state of the art on various denoising benchmarks.", "Future Impact": "N/A"}
{"id": "68f8d058-1403-4066-b3d3-a8a2836b35e1", "Context": "Imperfect vector training labels with registration uncertainty are common in applications such as streamline classification on Earth imagery or tissue segmentation on medical imagery. Existing research often focuses on uncertainty in label class semantics or characterizes label registration uncertainty at the pixel level.", "Key Idea": "The authors propose a deep learning framework that can quantify and reduce the registration uncertainty of training labels as well as train neural network parameters simultaneously.", "Method": "The authors propose a registration-uncertainty-aware loss function and design an iterative uncertainty reduction algorithm by re-estimating the posterior of true vector label locations distribution based on a Gaussian process.", "Outcome": "Evaluations on real-world datasets in National Hydrography Dataset refinement show that the proposed approach significantly outperforms several baselines in the registration uncertainty estimations performance and classification performance.", "Future Impact": "N/A"}
{"id": "69aacc53-6730-4db0-b420-9a45b96a642e", "Context": "The problem of finding the configuration of a collection of geometric bodies to satisfy a set of given constraints has been suggested to be solved efficiently by symbolically reasoning about geometry using a degrees of freedom analysis and plan fragments.", "Key Idea": "This paper presents a method for automatically synthesizing plan fragments using first principles about geometric bodies, actions, and topology.", "Method": "The authors use first principles about geometric bodies, actions, and topology to synthesize plan fragments.", "Outcome": "The authors show that the synthesized plan fragments can efficiently find the configuration of a collection of geometric bodies to satisfy a set of given constraints.", "Future Impact": "The proposed method for automatically synthesizing plan fragments has the potential to improve the efficiency and accuracy of geometric reasoning and constraint satisfaction systems."}
{"id": "6dc39f88-d613-4ec0-b70d-d5daa6f3643c", "Context": "Data analysis systems typically execute aggregation queries and produce results that may not be exact, but rather an approximation of the true value. These approximations may not have deterministic bounds.", "Key Idea": "The authors propose BitGourmet, a novel data analysis system that supports deterministic approximate query processing (DAQ), which executes aggregation queries and produces deterministic bounds that are guaranteed to contain the true value.", "Method": "The authors demonstrate BitGourmet by dividing each column vertically, bit-by-bit, and evaluating queries on subsets of these bit vectors. The system uses a specialized query processing engine and a scenario-specific query optimizer that relies on quality and cost models to decide the optimal bit selection and execution plan.", "Outcome": "The proposed system realizes a trade-off between result quality and execution time, making data analysis more interactive.", "Future Impact": "N/A"}
{"id": "6de74297-fb80-448f-b7ae-41f8d9701044", "Context": "Previous literatures use different imaging models to describe central catadioptric cameras and fisheye cameras separately.", "Key Idea": "The authors present a unified imaging model for both central catadioptric cameras and fisheye cameras.", "Method": "The authors show that the proposed unified model can cover some existing models for fisheye cameras and fit well for many actual fisheye cameras used in previous literatures. The authors perform experiments of calibration from some central catadioptric and fisheye images.", "Outcome": "The authors confirm the validity and usefulness of the proposed unified model by experimental results.", "Future Impact": "The proposed unified model enables the use of existing calibration methods for central catadioptric cameras to be directly applied to fisheye cameras and makes the metric calibration from single fisheye image only using projections of lines possible."}
{"id": "6ecf725b-661e-4897-8169-22d71826d0e8", "Context": "Existing Open Information Extraction (OIE) systems lack adaptability to different OIE tasks, which have different requirements.", "Key Idea": "The authors propose a new adaptable and efficient OIE system, OIE@OIA, which follows the methodology of Open Information eXpression (OIX) and parses a sentence to an Open Information Annotation (OIA) Graph.", "Method": "The authors implement an end-to-end OIA generator by annotating a dataset and designing an efficient learning algorithm for the complex OIA graph. They adapt the OIE@OIA system to accomplish three popular OIE tasks.", "Outcome": "The proposed OIE@OIA system achieves new SOTA performances on three popular OIE tasks, showing the great adaptability of the system. It also shows a significant advantage in terms of efficiency as it needs much fewer training samples compared to other end-to-end OIE baselines.", "Future Impact": "N/A"}
{"id": "73e353a8-e0d6-466f-af93-6fccf38fcb18", "Context": "Previous approaches to video-grounded dialogues mostly use dialogue context as a simple text input without modelling the inherent information flows at the turn level.", "Key Idea": "The authors propose to discover information flows among dialogue turns through a semantic graph constructed based on lexical components in each question and answer. They then introduce a new approach that learns to predict reasoning paths over this semantic graph.", "Method": "The authors construct a semantic graph based on lexical components in each question and answer. They then introduce a path prediction model that predicts a path from the current turn through past dialogue turns that contain additional visual cues to answer the current question. The reasoning model sequentially processes both visual and textual information through this reasoning path.", "Outcome": "The experimental results demonstrate the effectiveness of the proposed method and provide insights on how models use semantic dependencies in a dialogue context to retrieve visual cues.", "Future Impact": "N/A"}
{"id": "754f792b-fcf3-42f4-bb2c-5c1dcce21d7a", "Context": "The abstract argues for the use of formal meaning representations for natural language and identifies the problem of identifying the possible antecedents of anaphoric expressions as a challenge for such representations.", "Key Idea": "The authors propose the use of a specific structural property of formal meaning representations that facilitates the identification of possible antecedents of anaphoric expressions, allowing for a richer understanding of anaphora.", "Method": "N/A", "Outcome": "N/A", "Future Impact": "The proposed approach to formal meaning representations has the potential to significantly improve the ability to understand and interpret anaphora in natural language, with potential applications in natural language processing and understanding."}
{"id": "7b0671d7-c8f6-4e81-828b-c73958a6a63a", "Context": "There is a lack of interactive exhibits about medieval music that focus on education, entertainment, and historic authenticity.", "Key Idea": "The authors describe the design experience and lessons learned from creating an interactive exhibit about medieval music that relies on audio as its only feedback channel and focuses on educational value, entertainment aspects, and historic authenticity.", "Method": "N/A", "Outcome": "N/A", "Future Impact": "The paper provides valuable insights for designers and researchers in the field of interactive exhibits and education on how to balance educational value, entertainment aspects, and historic authenticity."}
{"id": "7b21425c-a2b7-4d19-b030-a8350b2a7a80", "Context": "Seq2Seq models are a popular choice for set generation tasks such as entity typing and dialogue emotion tagging. However, these models treat a set as a sequence and do not fully leverage its key properties, namely order-invariance and cardinality.", "Key Idea": "The authors propose a novel algorithm for effectively sampling informative orders over the combinatorial space of label orders. The authors jointly model the set cardinality and output by prepending the set size and taking advantage of the autoregressive factorization used by Seq2Seq models.", "Method": "The authors train a Seq2Seq model on augmented data with signals of order-invariance and cardinality, without any additional annotations.", "Outcome": "Training a Seq2Seq model on this augmented data gets an average relative improvement of 20% on four benchmark datasets across various models: BART, T5, and GPT-3.", "Future Impact": "N/A"}
{"id": "7c065e41-7c2e-430e-a918-6a776037bf50", "Context": "The paper summarizes the discussion of the SIGMOD 2005 panel on Databases and Information Retrieval: Rethinking the Great, which aimed to discuss whether data management systems architectures should be redesigned to merge Database (DB) and Information Retrieval (IR) technologies.", "Key Idea": "N/A", "Method": "N/A", "Outcome": "The panel had very high attendance and generated lively discussions.", "Future Impact": "N/A"}
{"id": "7d850699-212d-466b-976f-0afed0653fef", "Context": "The Helping Our Own (HOO) 2011 Shared Task focused on identifying determiner and preposition errors in non-native English essays. The HOO 2012 Shared Task extended this to include the Cambridge Learner Corpus FCE Dataset.", "Key Idea": "The authors extend their n-gram-based data-driven prediction approach and incorporate word clustering to improve error detection. They also develop a missing determiner detector.", "Method": "The authors perform experiments on the HOO 2012 Shared Task dataset, focusing on three error categories: missing determiner, incorrect determiner, and incorrect preposition.", "Outcome": "The proposed system improved the approach by incorporating word clustering and developing a missing determiner detector.", "Future Impact": "N/A"}
{"id": "802a5b78-a022-4d38-bfb3-f28eee4ef89a", "Context": "Neural network based dependency parsing has been recently studied, which can effectively alleviate the problems of data sparsity and feature engineering by using dense features. However, it is still a challenge to model the complicated syntactic and semantic compositions of the dense features in neural network based methods.", "Key Idea": "The authors propose two heterogeneous gated recursive neural networks, Tree-GRNN and DAG-GRNN, to model the feature combinations for the trees in stack and the feature combinations of the nodes whose dependency relations have not been built yet, respectively.", "Method": "The authors integrate Tree-GRNN and DAG-GRNN to automatically learn the compositions of the dense features for transition-based dependency parsing.", "Outcome": "Experiment results on two prevalent benchmark datasets (PTB3 and CTB5) show the effectiveness of the proposed model.", "Future Impact": "N/A"}
{"id": "80698baf-89cb-4a50-9f5c-0c74151b798b", "Context": "Peer grading in MOOCs (Massive Open Online Courses) is a common practice, where students grade their peers' assignments. However, the motivation of students to perform well during peer grading is not well understood.", "Key Idea": "The authors propose a study to examine how students in a MOOC might be motivated to do a better job during peer grading.", "Method": "The authors conduct a controlled study involving more than one thousand students in a popular MOOC. They ask two specific questions: (1) When a student knows that his or her own peer grading efforts are being examined by peers, does this knowledge alone tend to motivate the student to do a better job when grading assignments? And (2) when a student not only knows that his or her own peer grading efforts are being examined by peers, but he or she is also given a number of other peer grading efforts to evaluate (so the peer graders see how other peer graders evaluate assignments), do both of these together tend to motivate the student to do a better job when grading assignments?", "Outcome": "The study finds strong statistical evidence that ``grading the graders'' tends to increase the quality of peer grading.", "Future Impact": "N/A"}
{"id": "816707fd-9214-4435-ac40-b2655e55c9d0", "Context": "Pretrained language models have achieved superhuman performance on many benchmarks, creating a need for harder tasks.", "Key Idea": "The authors introduce CoDA21, a benchmark that measures natural language understanding capabilities of pretrained language models by evaluating their ability to align definitions with contexts.", "Method": "The authors evaluate the performance of pretrained language models on CoDA21, a benchmark that requires a deep understanding of contexts and definitions, including complex inference and world knowledge.", "Outcome": "The authors find that there is a large gap between human and pretrained language model performance on CoDA21, suggesting that CoDA21 measures an aspect of natural language understanding that is not sufficiently covered in existing benchmarks.", "Future Impact": "CoDA21 could be used to improve pretrained language models by providing a challenging benchmark that measures an aspect of natural language understanding that is not sufficiently covered in existing benchmarks."}
{"id": "8737b031-f77c-4f32-8a68-4be9b0c9ecf8", "Context": "Training a deep network to perform semantic segmentation requires large amounts of labeled data. Researchers have investigated the use of synthetic data, which can be labeled automatically, but a network trained on synthetic data performs relatively poorly on real images.", "Key Idea": "The authors propose a new approach to handle synthetic images that does not require seeing any real images at training time. The authors build on the observation that foreground and background classes are not affected in the same manner by the domain shift.", "Method": "The authors perform experiments on Cityscapes and CamVid datasets with models trained on synthetic data only, using a detection-based manner to handle the foreground classes.", "Outcome": "The authors' experiments evidence the effectiveness of their approach on Cityscapes and CamVid datasets.", "Future Impact": "N/A"}
{"id": "8ae36735-e4ac-48da-bd2b-5538a6a00a73", "Context": "Relational machine learning (RML) is a framework for predicting preferences in large scale networks by jointly modeling user labels and relational structure. However, existing RML approaches do not fully utilize unlabeled instances and have expensive collective inference procedures.", "Key Idea": "This paper proposes a method to overcome these limitations by implementing a maximum entropy constraint on the inference step, correcting bias, and outlining a massively scalable variational inference algorithm for large scale relational network domains.", "Method": "The authors analyze the effect of full semi-supervised RML and implement a maximum entropy constraint on the inference step. They also outline a massively scalable variational inference algorithm for large scale relational network domains and extend it to incorporate the maximum entropy constraint.", "Outcome": "The proposed method demonstrates improvement over a variety of baselines on seven real-world datasets, including large scale networks with over five million edges.", "Future Impact": "N/A"}
{"id": "8aedb046-2f51-4229-bc19-ea6db98355cb", "Context": "Researchers used to describe the inter-connectivity among websites with a HostGraph and adopted the random walk model in the HostGraph to get the ranks of websites. However, the random walk over such a HostGraph is not reasonable because it is not in accordance with the browsing behavior of web surfers.", "Key Idea": "The authors propose a novel method named AggregateRank, which mathematically proves that the probability of visiting a website by the random web surfer should be equal to the sum of the PageRank values of the pages inside that website and can approximate the sum of PageRank accurately with a lower computational complexity than PageRank.", "Method": "The authors mathematically prove the AggregateRank method and evaluate it through theoretical analysis and experiments.", "Outcome": "Both theoretical analysis and experimental evaluation show that AggregateRank is a better method for ranking websites than previous methods.", "Future Impact": "N/A"}
{"id": "927df1bd-273a-4088-8c56-2e79cac37072", "Context": "k-means is a popular data processing algorithm, and a proper initialization of k-means is crucial for obtaining a good final solution. The k-means++ initialization algorithm obtains an initial set of centers that is provably close to the optimum solution, but it is sequential in nature.", "Key Idea": "The authors propose a new algorithm called k-means|| which obtains a nearly optimal solution after a logarithmic number of passes in parallel, outperforming k-means++ in both sequential and parallel settings.", "Method": "The authors prove that the proposed initialization algorithm k-means|| obtains a nearly optimal solution after a logarithmic number of passes and then show that in practice a constant number of passes suffices.", "Outcome": "Experimental evaluation on real-world large-scale data demonstrates that k-means|| outperforms k-means++ in both sequential and parallel settings.", "Future Impact": "N/A"}
{"id": "9292bc08-a70f-4adb-a6d7-920728893a39", "Context": "The paper is based on propositional argumentation systems and monotonic logics. An assumption-based argumentation framework is a special case of this.", "Key Idea": "The authors introduce a number of propositional argumentation systems obtained by gradually extending the underlying language and associated monotonic logics, and show a stronger argumentation system in a full classical language to be equivalent to a system of causal reasoning.", "Method": "The authors use a system of causal reasoning to extend the underlying language and associated monotonic logics.", "Outcome": "The authors establish a correspondence between the argumentation system and the system of causal reasoning.", "Future Impact": "The implications of this correspondence for the respective nonmonotonic theories of argumentation and causal reasoning are discussed."}
{"id": "93bf12a1-2174-43e3-9cd4-c2b8aeed2f93", "Context": "Recent approaches in unsupervised domain mapping involve learning a mapping between two unmatched datasets A and B, by learning both GAB and GBA simultaneously.", "Key Idea": "The authors propose a new method for unsupervised domain mapping that learns GAB without learning GBA, by maintaining the distance between a pair of samples.", "Method": "The authors perform experiments to learn a mapping that maintains the distance between a pair of samples and between different parts of the same sample before and after mapping.", "Outcome": "The proposed method allows for one-sided mapping learning and leads to preferable numerical results over existing circularity-based constraint.", "Future Impact": "N/A"}
{"id": "9748b061-590a-4602-9015-a68e879ffced", "Context": "HCI researchers are looking into using liquid-based materials to create novel interfaces, but existing liquid-based smart material printing systems have limitations such as low printing resolution, small range of printable materials, and lack of customizability.", "Key Idea": "The authors present a design strategy for HCI researchers to build and customize a liquid-based smart material printing platform, called xPrint, with off-the-shelf or easy-to-machine parts. The design includes a magnetic assembly-based modular hardware and an open-source, highly customizable software design and simulation platform.", "Method": "The authors introduce the system design in detail and demonstrate the material variability and customizability through three use cases.", "Outcome": "xPrint has a large range of printable materials from synthesized polymers to natural micro-organism-living cells with a printing resolution from 10μm up to 5mm (droplet size).", "Future Impact": "N/A"}
{"id": "977698a6-56ef-4e57-94c5-b3a68a451a80", "Context": "Emotion cause extraction aims to identify the reasons behind a certain emotion expressed in text. It is a much more difficult task compared to emotion classification.", "Key Idea": "The authors propose a new approach which considers emotion cause identification as a reading comprehension task in QA and uses a new mechanism to store relevant context in different memory slots to model context information.", "Method": "The authors use deep memory networks for emotion cause extraction and evaluate the performance of their proposed approach on a recently released emotion cause dataset.", "Outcome": "The proposed method achieves the state-of-the-art performance on the emotion cause dataset, outperforming a number of competitive baselines by at least 3.01% in F-measure.", "Future Impact": "N/A"}
{"id": "9821d5f7-72b0-4841-a54f-d2af4a04ea3a", "Context": "Inverse rendering is the problem of estimating surface properties of an object from images. In the case of surface texture, it can be approximated by a linear basis. A dichromatic reflectance model is assumed and the challenge is to estimate spherical harmonic illumination coefficients and texture parameters.", "Key Idea": "The authors propose a method to estimate spherical harmonic illumination coefficients and texture parameters in a specular invariant colour subspace by solving a system of bilinear equations. They focus on the case of faces, where both shape and texture can be efficiently described by a linear statistical model.", "Method": "The authors fit a 3D morphable model to a single colour image, accounting for both non-Lambertian specular reflectance and complex illumination of the same light source colour. They solve only convex optimization problems.", "Outcome": "The authors are able to recover statistical texture model parameters with an accuracy comparable to more computationally expensive analysis-by-synthesis approaches.", "Future Impact": "N/A"}
{"id": "9999e1df-f439-4f62-bd03-337e494e9da3", "Context": "Data type encapsulation schemes typically express 'space' operations in a way that is not natural to the base language operators.", "Key Idea": "The authors propose a data type encapsulation scheme that results in a conceptual separation of operators and procedure calls in the base language, leading to a language of considerable expressive power.", "Method": "The authors have implemented the proposed scheme and provide several examples to demonstrate its use.", "Outcome": "N/A", "Future Impact": "The proposed data type encapsulation scheme has the potential to simplify the process of expressing 'space' operations in terms of base language operators, making it easier for developers to write more expressive code."}
{"id": "99bef0ca-923c-480d-a89e-9a2f27e02157", "Context": "Most real-world games and many recreational games are games of incomplete information. Over the last dozen years, abstraction has emerged as a key enabler for solving large incomplete-information games.", "Key Idea": "The authors present a method for solving large incomplete-information games by abstracting the game to generate a smaller, abstract game that is strategically similar to the original game, computing an approximate equilibrium in the abstract game and mapping the strategy back to the original game.", "Method": "The authors review key developments in the field of abstraction for solving large incomplete-information games, present algorithms for information and action abstraction and discuss reverse mapping of opponent's actions into the abstraction.", "Outcome": "N/A", "Future Impact": "The authors discuss other topics of current and future research in the field of abstraction for solving large incomplete-information games."}
{"id": "9b95b592-1562-4ef9-b0ed-e0655fadc73b", "Context": "Current methods for surface matching are limited in their ability to handle large deformations and arbitrary topology changes.", "Key Idea": "The authors propose a new method for surface matching that uses a geodesic distance evolution scheme on a 3-manifold to handle large deformations and topological changes.", "Method": "The authors set up a partial differential equation governing the propagation of surfaces at equal geodesic distance from the given original surface. Using an eulerian formulation with level-sets, it gives stable numerical algorithms for computing distance maps.", "Outcome": "The proposed method for surface matching is able to obtain matching paths as the orbits of the vector field defined as the sum of two distance maps' gradient values, and it can handle the case of large deformation and topological changes.", "Future Impact": "N/A"}
{"id": "9cd7e7e1-8893-4db6-8327-48f098187699", "Context": "Online social networks, such as Twitter, have become an important alternative information channel to traditional media during natural disasters. However, the large volume of messages can lead to information overload for end users.", "Key Idea": "The authors propose the development of an automatic classifier of tweets to filter relevant and non-relevant information during natural disasters.", "Method": "The authors use a dataset from the Chilean earthquake of 2010 to build and validate a ground truth, and test the effect of class imbalance and dimensionality reduction over 5 classifiers.", "Outcome": "The authors show that the performance of the classifiers is affected by class imbalance and dimensionality reduction, providing important considerations for building these systems.", "Future Impact": "N/A"}
{"id": "9f641e23-3886-4ac6-b65e-28db86ee48be", "Context": "Google unveiled the generalized second price (GSP) auction nearly fifteen years ago. The Vickrey-Clarke-Groves (VCG) auction would have been the proper choice according to theoretical accounts, but GSP has succeeded spectacularly.", "Key Idea": "Advertisers' preferences map to a model called value maximization, and for value maximizers, GSP is the truthful auction. This implies an axiomatization of GSP which can be applied much more broadly than the simple model for which GSP was originally designed.", "Method": "N/A", "Outcome": "N/A", "Future Impact": "The axiomatization of GSP can be applied much more broadly than the simple model for which GSP was originally designed. It can recover the folklore definition of GSP when applied to arbitrary single-parameter domains."}
{"id": "a10dafe9-6093-47f0-8429-7b62c46566ea", "Context": "Enterprise mashup scenarios often involve feeds derived from data created primarily for eye consumption, such as email, news, calendars, blogs, and web feeds. These data sources can test the capabilities of current data mashup products, as the attributes needed to perform join, aggregation, and other operations are often buried within unstructured feed text.", "Key Idea": "The authors present the integration of SystemT, an information extraction system from IBM Research, with IBM's InfoSphere MashupHub, which enables the conversion of unstructured text into structured information that can facilitate mashup operations.", "Method": "The authors demonstrate how to build domain-specific annotators with SystemT's declarative rule language, AQL, and how to use these annotators to combine structured and unstructured information in an enterprise mashup.", "Outcome": "N/A", "Future Impact": "N/A"}
{"id": "a1739057-ef00-4b01-9c26-4ab2b5d5708e", "Context": "With the increasing use of data mining tools and techniques, it is envisioned that a Knowledge Discovery and Data Mining System (KDDMS) will have to support and optimize for complex mining queries, specifically in the case of a sequence of queries and multiple simultaneous queries.", "Key Idea": "The authors present a systematic mechanism to optimize for these scenarios, targeting the class of mining queries involving frequent pattern mining on one or multiple datasets by proposing a system architecture and new algorithms.", "Method": "The authors implement and evaluate their system with both real and synthetic datasets, comparing it with systems that do not support caching or optimize for multiple queries.", "Outcome": "The experimental results show that the proposed techniques can achieve a speedup of up to a factor of 9.", "Future Impact": "N/A"}
{"id": "a5bc5ab8-70fb-4dff-824b-7606228e44a9", "Context": "N/A", "Key Idea": "EzMath is a new notation for embedding mathematical expressions in Web pages.", "Method": "N/A", "Outcome": "N/A", "Future Impact": "EzMath has the potential to make it easier for people to add mathematical expressions to web pages."}
{"id": "a722b600-3725-4738-a47b-435aebd63e13", "Context": "Today's market for smart home devices has quickly evolved to include products that monitor, automate, and present themselves as human, which can lead to emergent problems with privacy in people's homes.", "Key Idea": "The authors propose a design philosophy for intelligent agents in the smart home that prioritizes privacy and respect for the user, as an alternative to the current ways that these devices are built.", "Method": "N/A", "Outcome": "N/A", "Future Impact": "The proposed design philosophy represents the first steps towards a more respectful future for smart home devices, and the application of this philosophy to the design of privacy empowering technologies represents a potential improvement for the field."}
{"id": "ad69e31c-2c7f-4db0-916c-3deccaab37fd", "Context": "Go is an ancient board game that has posed unique opportunities and challenges for AI and machine learning, particularly in learning a good evaluation function in a scalable way.", "Key Idea": "The authors propose a machine learning approach that focuses on learning the propensity of local patterns in Go from a library of games. The local tactical information is fed into a recursive neural network, derived from a Bayesian network architecture, to produce local outputs representing local territory ownership probabilities.", "Method": "The authors train the system using 9 × 9 amateur game data and test it on a 19 × 19 professional game data.", "Outcome": "A system trained using only 9 × 9 amateur game data performs surprisingly well on a test set derived from 19 × 19 professional game data.", "Future Impact": "The authors suggest possible directions for further improvements, such as incorporating more sophisticated features and learning from more data."}
{"id": "b0ad60d7-3a3a-42c2-acbc-fba55e708ba0", "Context": "In natural language, the meaning of a lexeme often varies due to the specific surrounding context. Computational approaches to natural language processing rely on a reliable, long-range-context-dependent representation of the meaning of each lexeme that appears in a given sentence.", "Key Idea": "The authors propose a new general technique that produces a context-dependent u0027meaningu0027 representation for a lexeme in a specific surrounding context.", "Method": "The authors perform experiments with a lexicon composed of individual English words and also with a lexicon of individual words and selected phrases.", "Outcome": "The authors' proposed method represents the u0027meaningu0027 of a lexeme in a specific context by a list of semantically replaceable elements, which can be used to compare the u0027meaningu0027 of conceptual units in different contexts and also can serve as features for machine learning approaches to classify semantic roles and relationships.", "Future Impact": "N/A"}
{"id": "b14f2bc1-607f-4d8b-a731-b4afdf30a633", "Context": "Current explanation datasets often employ synthetic data with simple reasoning structures and cannot express more complex reasoning processes, such as the rebuttal to a reasoning step and the degree of certainty of the evidence.", "Key Idea": "The authors propose a comprehensive logical reasoning explanation form that includes three main components: (1) The condition of rebuttal that the reasoning node can be challenged; (2) Logical formulae that uncover the internal texture of reasoning nodes; (3) Reasoning strength indicated by degrees of certainty.", "Method": "The authors evaluate the current best models' performance on this new explanation form.", "Outcome": "The experimental results show that generating reasoning graphs remains a challenging task for current models, even with the help of giant pre-trained language models.", "Future Impact": "N/A"}
{"id": "b391a193-83e3-4f11-801f-1842647d626e", "Context": "Many studies have employed graph-based deep learning methods to exploit the dependencies among facial action units (AU) for the AU detection task. However, the dependencies among AUs in real-world data are often noisy and uncertain.", "Key Idea": "The authors propose an uncertain graph neural network (UGN) to learn the probabilistic mask that simultaneously captures both the individual dependencies among AUs and the uncertainties. The authors also propose an adaptive weighted loss function based on the epistemic uncertainties to adaptively vary the weights of the training samples.", "Method": "The authors conduct experiments on two benchmark datasets, BP4D and DISFA, to demonstrate the effectiveness of the proposed UGN and adaptive weighted loss function.", "Outcome": "The proposed UGN and adaptive weighted loss function achieve the state-of-the-art performance on the two benchmark datasets.", "Future Impact": "N/A"}
{"id": "b6b29c8a-7c8c-444c-b434-2ff9e166d9aa", "Context": "Offline Reinforcement Learning (RL) aims to learn policies from previously collected datasets without exploring the environment. Directly applying off-policy algorithms to offline RL usually fails due to the extrapolation error caused by the out-of-distribution (OOD) actions.", "Key Idea": "The authors propose a purely uncertainty-driven offline algorithm, Pessimistic Bootstrapping for offline RL (PBRL), that conducts uncertainty quantification via the disagreement of bootstrapped Q-functions, and performs pessimistic updates by penalizing the value function based on the estimated uncertainty. The authors further propose a novel OOD sampling method to tackle the extrapolating error.", "Method": "The authors show that such OOD sampling and pessimistic bootstrapping yields provable uncertainty quantifier in linear MDPs, thus providing the theoretical underpinning for PBRL.", "Outcome": "Extensive experiments on D4RL benchmark show that PBRL has better performance compared to the state-of-the-art algorithms.", "Future Impact": "N/A"}
{"id": "bd84a1fd-ee85-4ac9-a6ae-e534b6013506", "Context": "The abstract does not provide enough context, but in general, convolutional networks are a type of neural network commonly used for image classification and other tasks. They are often viewed from the perspective of linear operators or differential equations.", "Key Idea": "The authors propose a harmonic decomposition of convolutional networks, which are expansions into sums of elementary functions of increasing order. These elementary functions are related to the spherical harmonics.", "Method": "The authors establish harmonic decompositions of convolutional networks and use it to characterize the integral operators associated with convolutional networks.", "Outcome": "The harmonic decompositions allow the authors to obtain statistical bounds for convolutional networks.", "Future Impact": "The harmonic decomposition proposed by the authors can potentially be used for better understanding the properties of convolutional networks and improve their performance."}
{"id": "c268a190-6974-4190-8f48-db5dcbda8bc8", "Context": "The data management ecosystem faces a challenge in handling the variety of data, which comes in multiple formats such as relational and (semi-)structured data (i.e. XML). Traditional databases are limited in their ability to handle different types of data formats as they are designed for a single type of data format.", "Key Idea": "The authors propose a multi-model processing framework for relational and semi-structured data (i.e. XML) and a worst-case optimal join algorithm that can guarantee that the intermediate results are no larger than the worst-case join results.", "Method": "The authors perform experiments to compare the running time and intermediate result size of their multi-model algorithm with baseline join methods.", "Outcome": "Preliminary results show that the multi-model algorithm significantly outperforms the baseline join methods in terms of running time and intermediate result size.", "Future Impact": "N/A"}
{"id": "c37e0f9f-1654-4f1f-b812-bf6f67c0c840", "Context": "Deep Learning based AI systems are susceptible to adversarial attacks, which are small perturbations added to inputs that can cause misclassification. Developing defenses against such adversarial attacks is an active research area.", "Key Idea": "The authors propose a novel statistical approach for adversarial detection in image classification, based on constructing a per-class feature distribution and detecting adversaries based on comparison of features of a test image with the feature distribution of its class.", "Method": "The authors make use of various statistical distances such as ED, MMD for adversarial detection and analyze the performance of each metric on MNIST and CIFAR-10 datasets.", "Outcome": "The authors experimentally show that their approach achieves good adversarial detection performance on MNIST and CIFAR-10 datasets irrespective of the attack method, sample size and the degree of adversarial perturbation.", "Future Impact": "N/A"}
{"id": "c3aa9543-0695-42b4-99af-d033e3912801", "Context": "The real estate industry has not attracted much attention from the KDD community despite its enormous size and prominence. This is because the real estate industry did not appreciate the value of data science methods until recently and the Data Science community was not aware of challenging real estate problems.", "Key Idea": "This tutorial provides an introduction to real estate for data scientists and outlines a spectrum of data science problems in the real estate industry, many of which are being tackled by new prop-tech companies.", "Method": "The tutorial presents concrete examples from three real estate companies: Airbnb, Cherre, and Compass, where the authors work.", "Outcome": "N/A", "Future Impact": "This tutorial could lead to more data science research being applied to the real estate industry, and more data scientists becoming interested in working on real estate problems."}
{"id": "c5c22c6f-e9e9-4b0a-ac57-d3baa100033b", "Context": "Stochastic convex optimization problems with a large number of linear constraints arise from SDP-relaxations of combinatorial problems, which involve a number of constraints that is polynomial in the problem dimension. Prior works require full passes over all constraints which can be computationally expensive.", "Key Idea": "The authors propose two novel conditional gradient-based methods for solving structured stochastic convex optimization problems with a large number of linear constraints that only process a subset of the constraints at each iteration.", "Method": "The authors' algorithms rely on variance reduction and smoothing used in conjunction with conditional gradient steps, and are accompanied by rigorous convergence guarantees.", "Outcome": "N/A", "Future Impact": "Preliminary numerical experiments are provided for illustrating the practical performance of the methods."}
{"id": "c676aecf-7468-4258-bb41-22bc1811bc3a", "Context": "Community search, or finding a connected subgraph containing given query nodes in a social network, is a fundamental problem. Most existing community search models focus on the internal cohesiveness of a community.", "Key Idea": "The authors propose a new community search model, DMCS, that finds a community with high modularity, meaning dense connections inside communities and sparse connections to nodes outside the community.", "Method": "The authors prove that the DMCS problem is NP-hard and present new algorithms that run in log-linear time to the graph size. They conduct extensive experimental studies in real-world and synthetic networks.", "Outcome": "The proposed DMCS algorithm achieves up to 8.5 times higher accuracy in terms of NMI than baseline algorithms.", "Future Impact": "N/A"}
{"id": "ca53b2c4-2912-4515-aae6-938c3f268a60", "Context": "The problem of detecting epidemic tendency by mining search logs, and the need for an algorithm that can select epidemic related queries/terms.", "Key Idea": "The authors propose an algorithm that uses click-through information to select epidemic related queries/terms, and a method to model epidemic occurrences and frequencies of epidemic related terms (ERTs) in search logs using linear regression.", "Method": "The authors perform experiments to test the effectiveness of the algorithm in finding ERTs which obtain a high correlation value with epidemic occurrences.", "Outcome": "The proposed algorithm is effective in finding ERTs which obtain a high correlation value with epidemic occurrences. The proposed method performs better when combining different ERTs than using single ERT.", "Future Impact": "N/A"}
{"id": "ccae9338-7379-4af1-8fea-8945ba429c5c", "Context": "Object tracking is a critical and challenging problem in computer vision. More and more researchers are paying attention to applying deep learning to extract powerful features for better tracking accuracy.", "Key Idea": "The authors propose a novel triplet loss function in a Siamese network framework for object tracking, instead of using pairwise loss for training.", "Method": "The authors perform theoretical analysis by comparing gradients and back-propagation, and apply the proposed triplet loss to three real-time trackers based on Siamese network. The authors evaluate the proposed method on several popular tracking benchmarks.", "Outcome": "The proposed method achieves superior tracking performance compared to the baseline trackers and comparable accuracy to recent state-of-the-art real-time trackers.", "Future Impact": "N/A"}
{"id": "ce74316d-c5dc-47f1-b0c4-0591bc3fb4b6", "Context": "Several methods have been proposed to evaluate queries over a native XML DBMS, where the queries specify both path and keyword constraints. These methods broadly consist of graph traversal approaches and approaches based on information-retrieval style inverted lists.", "Key Idea": "The authors propose a strategy that combines the two forms of auxiliary indexes, structure indexes and inverted lists, and a query evaluation algorithm for branching path expressions based on this strategy.", "Method": "The authors perform experiments over the Niagara XML DBMS to evaluate the benefit of integrating the two forms of indexes. They also consider algorithmic issues in evaluating path expression queries when the notion of relevance ranking is incorporated.", "Outcome": "The results show that by integrating the proposed techniques with the Threshold Algorithm, instance optimal algorithms to push down top k computation are obtained.", "Future Impact": "N/A"}
{"id": "db900c02-9a35-4a83-aa19-15b763259100", "Context": "Quantum computing is a powerful computational paradigm with applications in several fields, including machine learning. Deep learning, and in particular Convolutional Neural Networks (CNN), have become essential for applications in signal processing and image recognition. Quantum deep learning remains a challenging problem as it is difficult to implement non-linearities with quantum unitaries.", "Key Idea": "The authors propose a quantum algorithm for evaluating and training deep convolutional neural networks, called QCNN, that reproduces the outputs of classical CNNs and allows for non-linearities and pooling operations.", "Method": "The authors present numerical simulations for the classification of the MNIST dataset to provide practical evidence for the efficiency of the QCNN.", "Outcome": "The QCNN reproduces completely the outputs of the classical CNN and allows for non-linearities and pooling operations. The QCNN is in particular interesting for deep networks and could allow new frontiers in the image recognition domain.", "Future Impact": "The QCNN could allow for many more convolution kernels, larger kernels, high dimensional inputs, and high depth input channels in the image recognition domain."}
{"id": "dca09f6f-b63a-42a1-9eb5-fbfa45bc6389", "Context": "Activity logs collected from wearable devices are a promising source of data for personalized exercise scheduling, workout recommendation, and heart rate anomaly detection. However, such data are heterogeneous, noisy, diverse in scale and resolution, and have complex interdependencies.", "Key Idea": "The authors propose FitRec, a context-aware LSTM-based model that captures the personalized and temporal patterns of fitness data by considering two levels of context information: context within a specific activity, and context across a user's activity history.", "Method": "The authors evaluate the proposed model on a novel dataset containing over 250 thousand workout records coupled with hundreds of millions of parallel sensor measurements and metadata. They demonstrate that the model is able to learn contextual, personalized, and activity-specific dynamics of users' heart rate profiles during exercise.", "Outcome": "The proposed model outperforms baselines on several personalized recommendation tasks.", "Future Impact": "N/A"}
{"id": "dd282632-ee41-45da-add8-d68d89c57e2d", "Context": "Classification activation map (CAM) is a crucial mechanism for weakly supervised object localization (WSOL) which uses the classification structure to generate pixel-wise localization maps. However, CAM directly uses the classifier trained on image-level features to locate objects, making it prefer to discern global discriminative factors rather than regional object cues.", "Key Idea": "The authors propose a plug-and-play mechanism called BagCAMs to better project a well-trained classifier for the localization task without refining or re-training the baseline structure. The authors adopt a proposed regional localizer generation (RLG) strategy to define a set of regional localizers and then derive them from a well-trained classifier.", "Method": "The authors conduct experiments to improve the performance of baseline WSOL methods and evaluate the proposed BagCAMs on three WSOL benchmarks.", "Outcome": "Experiments indicate that adopting the proposed BagCAMs can improve the performance of baseline WSOL methods to a great extent and obtains state-of-the-art performance on three WSOL benchmarks.", "Future Impact": "N/A"}
{"id": "ddf8f49c-342a-4cd0-8b3b-b588af08ed0d", "Context": "Soboroff and Cahan proposed a method for evaluating the performance of retrieval systems without relevance judgments, which is found to be correlated with actual evaluations using relevance judgments in the TREC competition.", "Key Idea": "The authors propose an explanation for this phenomenon by devising a simple measure for quantifying the similarity of retrieval systems and demonstrating that evaluating retrieval systems according to average similarity yields results quite similar to the methodology proposed by Soboroff et al., and these two techniques are in fact highly correlated.", "Method": "The authors use a simple measure for quantifying the similarity of retrieval systems by assessing the similarity of their retrieved results. Then, given a collection of retrieval systems and their retrieved results, they use this measure to assess the average similarity of a system to the other systems in the collection.", "Outcome": "The authors find that evaluating retrieval systems according to average similarity yields results quite similar to the methodology proposed by Soboroff et al., and these two techniques are in fact highly correlated.", "Future Impact": "This study highlights the importance of understanding the underlying mechanism of evaluation methods and potential future work could be to propose new evaluation methods that are not affected by popularity bias."}
{"id": "ded9a095-d94d-4ccd-8825-283ec4bb7093", "Context": "There is increasing interest in the adoption of UX within corporate environments, and there is a need to understand what competencies translate into effective UX design.", "Key Idea": "This paper proposes a co-construction of identity between the designer and their environment, where various factors such as tool and representational knowledge, complexity, and corporate culture influence perceptions of competence in UX over time.", "Method": "A 12-week longitudinal data collection, including surveys and interviews, documents the shift in students' and early professionals' perception of competence as they begin internships and full-time positions in UX.", "Outcome": "The study shows that students' perception of competence in UX shifts over time and is influenced by various factors such as tool and representational knowledge, complexity, and corporate culture.", "Future Impact": "The study suggests opportunities for future research in building a deeper understanding of competency in UX based on this preliminary framing of early UX practice."}
{"id": "dfba01c5-a632-4394-8607-9a32f20e526c", "Context": "Current systems do not automatically build a scene model that contains both 3D geometric information and photometric information under various illumination conditions.", "Key Idea": "The authors propose a system that automatically builds a scene model from real images, which contains both 3D geometric information of the scene structure and its photometric information under various illumination conditions.", "Method": "The authors use structure-from-motion and correlation-based stereo techniques to match pixels between images of different viewpoints and to reconstruct the scene in 3D space. The photometric property is extracted from images taken under different illumination conditions by computing a low-dimensional linear space of the spatio-illumination volume, and is represented by a set of basis images.", "Outcome": "The proposed system can be used to create realistic renderings from different viewpoints and illumination conditions. Applications include object recognition, virtual reality and product advertisement.", "Future Impact": "N/A"}
{"id": "e10b883a-ded6-4b4e-9934-6daba2d2f2b2", "Context": "The problem of designing efficient and effective solutions for large scale similarity search is important. Existing semantic hashing methods represent data examples as compact binary codes through semantic hashing, which has produced promising results with fast search speed and low storage cost. However, these methods model document relationships based on similarity in a keyword feature space, which does not fully reflect semantic relationships that go beyond keyword matching and does not exploit tag information.", "Key Idea": "The authors propose a novel hashing approach, Semantic Hashing using Tags and Topic Modeling (SHTTM), that incorporates both tag information and similarity information from probabilistic topic modeling. A unified framework is designed for ensuring hashing codes to be consistent with tag information by a formal latent factor model and preserving the document topic/semantic similarity.", "Method": "An iterative coordinate descent procedure is proposed for learning the optimal hashing codes. An extensive set of empirical studies on four different datasets has been conducted to demonstrate the advantages of the proposed SHTTM approach against several other state-of-the-art semantic hashing techniques.", "Outcome": "Experimental results indicate that the modeling of tag information and utilizing topic modeling are beneficial for improving the effectiveness of hashing separately, while the combination of these two techniques in the unified framework obtains even better results.", "Future Impact": "N/A"}
{"id": "e1a191db-6463-4be9-883d-dfc7fb05c5f4", "Context": "Dependency parsing is the task of analyzing the grammatical structure of a sentence and representing it as a tree, where nodes represent words and edges represent grammatical relationships between words. Previous methods for dependency parsing do not enforce certain structural properties that can be useful for better representing the set of admissible dependency structures in treebanks and connecting dependency parsing to context-sensitive grammatical formalisms.", "Key Idea": "The authors propose a novel dependency parsing method that enforces two structural properties on dependency trees: bounded block degree and well-nestedness.", "Method": "The authors cast the problem of enforcing these structural properties on dependency trees as an Integer Linear Program and solve it using Lagrangian Relaxation. They then derive a heuristic and an exact method based on a Branch-and-Bound search.", "Outcome": "The proposed methods are efficient and competitive compared to a baseline unconstrained parser, while enforcing structural properties in all cases.", "Future Impact": "The proposed method can lead to better representation of admissible dependency structures in treebanks and provide a way to connect dependency parsing to context-sensitive grammatical formalisms."}
{"id": "e2466d98-98f9-41a8-8a38-e862adc2ed47", "Context": "The study is motivated by the importance of Information Technology (IT) Governance models for public organizations, and a gap in the literature for an IT Governance model that can be adopted by both practitioners and researchers.", "Key Idea": "The authors propose a new IT Governance model that can be adopted by public sector organizations in a simple and dynamic manner.", "Method": "The authors conducted a systematic literature review and an empirical survey using a questionnaire based on the COBIT 4.1 maturity model to investigate IT Governance practice in multiple case studies from the Kingdom of Bahrain.", "Outcome": "The proposed model provides a basic structure of a concept, allowing organizations to gain a better perspective on IT Governance processes and providing a clear focus for decision-making attention.", "Future Impact": "The proposed model forms a basis for further research in IT Governance adoption models and bridges the gap between conceptual frameworks, real life and functioning governance."}
{"id": "e58b9947-7a3a-414d-a0e8-d6cf02ed7127", "Context": "With recent advances in RFID, wireless sensor networks, and Web-based services, physical things are becoming an integral part of the emerging ubiquitous Web. The paper focuses on the things recommendation problem in Internet of Things (IoT).", "Key Idea": "The authors propose a unified probabilistic-based framework that fuses information across relationships between users (i.e., users' social network) and things (i.e., things correlations) to make more accurate recommendations.", "Method": "The authors validate the proposed approach based on an Internet of Things platform and perform experiments to demonstrate its feasibility and effectiveness.", "Outcome": "The proposed approach not only inherits the advantages of matrix factorization but also exploits the merits of social relationships and thing-thing correlations.", "Future Impact": "N/A"}
{"id": "e827ee51-aafd-4f3b-99ca-60a5e289a555", "Context": "The PASCAL 2005 Recognizing Textual Entailment challenge aims to recognize textual entailment, which is the ability to determine if a piece of text implies a given hypothesis.", "Key Idea": "The authors propose a logical approach to recognize textual entailment by extracting atomic propositions from both the text and the entailment hypothesis and expressing them in a custom logical notation.", "Method": "The authors use the output of Link Parser to extract propositions and encode them into a logical notation. To detect independent entailment relations, the system relies on the use of Otter and WordNet.", "Outcome": "The proposed method is used to test the practicability of a purely logical approach for recognizing textual entailment.", "Future Impact": "N/A"}
{"id": "ea414544-c89c-4039-8227-23b11e9a1239", "Context": "Question answering systems that supplement Web search engines struggle to produce single-snippet answers to definition questions.", "Key Idea": "The authors propose a practically unsupervised learning method that uses on-line encyclopedias and dictionaries to generate positive and negative definition examples to train an SVM.", "Method": "The authors perform experiments to compare the proposed method to the alternative of training the system on questions and news articles from TREC.", "Outcome": "The proposed method outperforms the alternative and helps the search engine handle definition questions significantly better.", "Future Impact": "N/A"}
{"id": "eb15ebe7-aa58-4a98-8f9e-939967c6359f", "Context": "Synchronization refers to the problem of inferring the unknown values attached to vertices of a graph where edges are labelled with the ratio of the incident vertices, and labels belong to a group. The synchronization problem on multi-graphs arises when multiple measures are available to model the relationship between two vertices, such as when different sensors measure the same quantity or when the original graph is partitioned into sub-graphs that are solved independently.", "Key Idea": "The authors present MultiSynch, a synchronization algorithm for multi-graphs that is based on a principled constrained eigenvalue optimization, which is a general solution that can cope with any linear group.", "Method": "The authors prove empirically that the baseline solution of reducing multi-graphs to simple ones by averaging their multi-edges falls short and present MultiSynch algorithm for multi-graphs synchronization.", "Outcome": "MultiSynch algorithm is shown to be profitably usable both on synthetic and real problems.", "Future Impact": "N/A"}
{"id": "f23bdd28-b2d6-4a42-a56c-c9774f6451b5", "Context": "With the development of hypersonic vehicles in near space, tracking for them is becoming a new task and hotspot. Current tracking algorithms may not be effective for hypersonic targets, especially for the sliding jump maneuver.", "Key Idea": "The authors propose a learning tracking algorithm that uses a Sine model and the Interacting Multiple Model (IMM) algorithm. The algorithm also learns the target tracking error characteristics to adjust the sampling rate adaptively.", "Method": "The authors compare the proposed algorithm with the single accurate model algorithm and general IMM algorithms with fixed sampling rate. The authors conduct simulation experiments to prove the effectiveness of the proposed algorithm.", "Outcome": "The proposed algorithm improves the tracking accuracy effectively compared to the single accurate model algorithm and general IMM algorithms with fixed sampling rate.", "Future Impact": "N/A"}
{"id": "f2c9f8c3-f9d1-4cae-b7ae-a919ada1daaf", "Context": "Access to online visual search engines implies sharing of private user content - the query images.", "Key Idea": "The authors introduce the concept of targeted mismatch attack for deep learning based retrieval systems, which generates an adversarial image that leads to identical or very similar retrieval results as the user intended query but looks nothing like it.", "Method": "The authors transfer attacks to partially unknown systems by designing various loss functions for the adversarial image construction, including loss functions for unknown global pooling operation or unknown input resolution by the retrieval system.", "Outcome": "The authors evaluate the attacks on standard retrieval benchmarks and compare the results retrieved with the original and adversarial image.", "Future Impact": "The study highlights the potential risks of private user content sharing in online visual search engines and the need for more robust retrieval systems."}
{"id": "f32d6bc3-d75e-4e84-8bfa-3c83578281dc", "Context": "Transaction log analysis is a methodology used to examine user commands and system responses in online information searches. It has been used to aid in the evaluation of information systems and improve existing and future systems.", "Key Idea": "This paper proposes a methodology for monitoring and evaluating information systems using transaction log analysis. It uses stochastic pattern developments within parsed user sessions, mathematical models utilizing Markov chain analysis and state transition probability matrices.", "Method": "The authors obtained machine-readable transaction log tapes from online catalogs and analyzed them using the proposed methodology.", "Outcome": "The results obtained from the analysis of patron use and system response patterns from several online public catalogs have been presented in the paper.", "Future Impact": "The predictive power of the methodology may allow real-time aids to be developed and assist in system design."}
{"id": "f32e53d5-c7f4-407e-a5cb-26fef230b5fd", "Context": "Matrix factorization has been widely adopted for recommendation by learning latent embeddings of users and items from observed user-item interaction data. However, previous methods usually assume the learned embeddings are static or homogeneously evolving with the same diffusion rate.", "Key Idea": "The authors propose a novel dynamic matrix factorization model, named Dynamic Bayesian Logistic Matrix Factorization (DBLMF), which aims to learn heterogeneous user and item embeddings that are drifting with inconsistent diffusion rates.", "Method": "The authors extend logistic matrix factorization to model the probability a user would like to interact with an item at a given timestamp, and a diffusion process to connect latent embeddings over time. An efficient Bayesian inference algorithm has also been proposed to make DBLMF scalable on large datasets.", "Outcome": "The effectiveness of the proposed method has been demonstrated by extensive experiments on real datasets, compared with the state-of-the-art methods.", "Future Impact": "N/A"}
{"id": "f3cef657-1887-42a7-9e11-8fdf54f8fa90", "Context": "Catastrophic forgetting is a major problem in continual learning, which is the ability of a model to learn new tasks without forgetting previously learned ones.", "Key Idea": "The authors propose a new continual learning approach called kernel continual learning, which leverages the non-parametric nature of kernel methods and an episodic memory unit to tackle catastrophic forgetting.", "Method": "The authors use an episodic memory unit that stores a subset of samples for each task to learn task-specific classifiers based on kernel ridge regression. They also introduce variational random features to learn a data-driven kernel for each task and formulate kernel continual learning as a variational inference problem.", "Outcome": "The proposed method is evaluated on four benchmarks and is shown to be effective in tackling catastrophic forgetting.", "Future Impact": "The proposed method can be used to improve continual learning in various applications such as robotics, natural language processing, and computer vision."}
{"id": "f41bfd75-a6b0-44d7-a842-b117797ebd7e", "Context": "In answer extraction, features are generated from surface texts, but the process of generating features from more structured data representations, such as parse trees, is not well-studied.", "Key Idea": "The authors propose and compare three methods for generating features from parse trees: feature vector, string kernel, and tree kernel, for use in Support Vector Machines.", "Method": "The authors perform experiments on the TREC question answering task using features generated from surface texts and parse trees using the proposed methods.", "Outcome": "The results show that features generated from more structured data representations, such as parse trees, significantly improve the performance based on features generated from surface texts.", "Future Impact": "N/A"}
{"id": "f4f1bbaf-c1a2-44d5-8305-27235fa69d62", "Context": "In the field of web mining and web science, as well as data science and data mining, there has been a lot of interest in the analysis of (social) networks. With the growing complexity of heterogeneous data, feature-rich networks have emerged as a powerful modeling approach.", "Key Idea": "The tutorial presents a unified perspective on feature-rich networks, focusing on different modeling approaches such as multiplex and attributed networks.", "Method": "N/A", "Outcome": "N/A", "Future Impact": "The tutorial outlines important principles, methods, tools and future research directions in this emerging field of feature-rich networks."}
{"id": "f64fdfde-7e93-411b-865a-1e29d71c95b2", "Context": "Large-scale topic models are used in many practical applications for feature extraction and dimensionality reduction. Hierarchical topic models (HTMs) are an extension of flat topic models that can learn topics of different levels of abstraction, but existing scalable systems for flat topic models cannot handle HTMs due to their complicated data structures and susceptibility to local optima.", "Key Idea": "The authors propose an efficient partially collapsed Gibbs sampling algorithm for hierarchical latent Dirichlet allocation (hLDA), an initialization strategy to deal with local optima, and efficient data layout and distributed data structures for building scalable systems for HTMs.", "Method": "The authors implement their proposed methods and evaluate their performance on a 131-million-document corpus with 28 billion tokens. They compare their implementation to the previous open-source implementation for hLDA.", "Outcome": "The authors' system is 87 times more efficient than the previous open-source implementation for hLDA, and can scale to thousands of CPU cores. They are able to extract 1,722 topics from the corpus with 50 machines in just 7 hours.", "Future Impact": "N/A"}
{"id": "f82f2e26-5437-4397-b781-50668ce5851b", "Context": "In present Statistical Machine Translation (SMT) systems, alignment is trained in a previous stage as the translation model, and alignment model parameters are not tuned in function of the translation task.", "Key Idea": "The authors propose a novel framework for discriminative training of alignment models with automated translation metrics as maximization criterion, where alignments are optimized for the translation task without the need for link labels at the word level.", "Method": "The authors evaluate the framework in terms of automatic translation evaluation metrics.", "Outcome": "The authors observe an improvement in translation quality.", "Future Impact": "N/A"}
{"id": "fb538ce2-abf4-4bd8-b35c-1bfe3ab9f48e", "Context": "The complex word identification task is important for lexical simplification, which helps improve the readability of texts with challenging words.", "Key Idea": "The authors developed two systems using Naive Bayes and Random Forest classifiers to identify complex words based on various lexical and semantic features.", "Method": "The authors used Naive Bayes and Random Forest classifiers to identify complex words in a sentence. They incorporated rule-based post-processing techniques to improve the performance of the Naive Bayes classifier.", "Outcome": "The Naive Bayes classifier based system achieves the maximum G-score of 76.7%", "Future Impact": "N/A"}
{"id": "feb75e1f-7838-48ca-9a78-cc31b717e5bf", "Context": "Previous work on finding fraudulent reviews on crowd-sourced review platforms mainly focuses on supervised machine learning and textual and stylometry features. These works have limited ground truth data and assume a limited threat model.", "Key Idea": "The authors propose OneReview, a system that finds fraudulent content on a crowd-sourced review site by leveraging correlations with other independent review sites and the use of textual and contextual features. It utilizes Change Point Analysis method and supervised machine learning to detect anomalous changes in a business’ reputation across multiple review sites and identify fraudulent reviews.", "Method": "The authors evaluated their approach using data from two reviewing websites, Yelp and TripAdvisor, and obtained Yelp reviews through the Yelp Data Challenge. They used Change Point Analysis method on the reviews of every business independently on every website and then used their proposed Change Point Analyzer to evaluate change-points, detect those that do not match across the websites, and identify them as suspicious. They used supervised machine learning, utilizing a combination of textual and metadata features to locate fraudulent reviews among the suspicious reviews.", "Outcome": "The authors obtained 97% (+/- 0.01) accuracy, 91% (+/- 0.03) precision and 90% (+/- 0.06) recall in detecting fraudulent reviews. They classified 8% of all reviews as fraudulent. They also detected fraudulent campaigns and identified 3,980 businesses with fraudulent reviews and 14,910 suspected spam.", "Future Impact": "N/A"}
{"id": "fed7302a-43a7-412e-8ace-d07905e38c3c", "Context": "In one-class collaborative filtering, interpreting and modeling the latent signal from the missing class is a challenge.", "Key Idea": "The authors propose a novel Bayesian generative model for implicit collaborative filtering that delineates the odds of a user disliking an item from simply being unaware of it. The latent signal is treated as an unobserved random graph connecting users with items they might have encountered.", "Method": "The authors demonstrate large-scale distributed learning through a combination of stochastic gradient descent and mean field variational inference over random graph samples.", "Outcome": "The proposed model is fine-grained compared to a state-of-the-art baseline on real-world data.", "Future Impact": "N/A"}
{"id": "ffd14676-a525-479f-a74e-2c5d3a85c510", "Context": "There has been a recent revival of interest in parallel systems in which computation is performed by excitatory and inhibitory interactions within a network of relatively simple, neuronlike units. Representing shapes in parallel systems is a complex issue.", "Key Idea": "This paper considers the difficulties involved in representing shapes in parallel systems and suggests ways of overcoming them. It provides a mechanism for shape perception and visual attention.", "Method": "N/A", "Outcome": "N/A", "Future Impact": "The paper's proposed mechanism for shape perception and visual attention can allow a novel interpretation of the Gestalt slogan that the whole is more than the sum of its parts."}
{"id": "adfd8058-64b3-4062-953c-034b732e2fa0", "Context": "Current video compression schemes are based on complex algorithms such as H.264, which may not be efficient in coding certain types of video sequences.", "Key Idea": "The authors propose a video compression scheme based on texture synthesis through Directional Empirical Mode Decomposition (DEMD) algorithm. The proposed scheme decompose P and B-frames into Intrinsic Mode Function (IMF) image and its residue, and only the first level IMF image for P and B frames are coded.", "Method": "The authors perform wavelet decomposition over residual image and use energy level at the HH band as a decision criterion for number of decomposition to be performed for optimum synthesis. The authors also demonstrate the effectiveness of the algorithm in multi-resolution parametric modeling of image data and scalable coding of IMF parameters.", "Outcome": "The proposed scheme demonstrates significant compression with acceptable quality.", "Future Impact": "N/A"}