{"pid": "01f161fe-dd40-45dd-89bd-fb1562771d73", "context": "Capturing contextual information for an event can aid analysts in understanding the factors associated with the event, but it is challenging due to uncertainty of context structure, high dimensional features and adaptation of features over time. Recently, graph representations have rendered helpful on capturing contextual information.", "key_idea": "The author proposed a graph convolutional network for predicting future events. The network model predicts the future events and identifies sequences of dynamic graphs as event context by learning graph representations from historical event documents, employing the hidden word graph features.", "method": "The author utilizes real-world data sets to benchmark the proposed model and compare against various state-of-the-art methods for social event prediction.", "outcome": "The results show that the proposed model is competitive against various state-of-the-art methods for social event prediction.", "future_impact": "N/A", "venue": null, "year": null, "title": "Learning Dynamic Context Graphs for Predicting Social Events"}
{"pid": "01f161fe-dd40-45dd-89bd-fb1562771d73", "context": "Event forecasting with an aim at modeling contextual information is a challenging but important task for applications such as automated analysis generation and resource allocation. Recently, graph representations have demonstrated success in applications such as traffic forecasting, social influence prediction, and visual question answering systems.", "key_idea": "The authors propose a novel graph convolutional network for predicting future events.", "method": "The authors evaluate their approach on multiple real-world data sets.", "outcome": "Experimental results on multiple real-world data sets show that the proposed method is competitive against various state-of-the-art methods for social event prediction.", "future_impact": "N/A", "venue": null, "year": null, "title": "Learning Dynamic Context Graphs for Predicting Social Events"}
{"pid": "07c3daea-a88c-4a67-9aac-20ef0ec62e79", "context": "It is a challenge to maintain awareness of what is meaningful for a certain person, and absence of tools to collect and manage biographical materials happens to biographical for people with Dementia.", "key_idea": "The authors created a web platform that supports the work of psychologists, streamlining the collection of relevant information about people with dementia.", "method": "The authors use a case study with one psychologist and three patients, across a period of two weeks to show the effectiveness of new web platform.", "outcome": "The case study show that web platform make improvements in the collection of meaningful data about a person, and on maintaining awareness of the therapy as a whole.\r\n", "future_impact": "N/A", "venue": null, "year": null, "title": "Enabling Biographical Cognitive Stimulation for People with Dementia"}
{"pid": "07c3daea-a88c-4a67-9aac-20ef0ec62e79", "context": "Non-pharmacological interventions are the most common and arguably most effective for people with dementia. However, some of these approaches have been proven to benefit from the usage of biographical or personalized materials, which are not always easy to obtain and challenging to distinguish what are meaningful for a certain person.", "key_idea": "The authors create a web platform that supports the work of psychologists, streamlining the collection of relevant information about people with dementia.", "method": "The authors conduct a case study with one psychologist and three patients, across a period of two weeks.", "outcome": "Results from a case study with one psychologist and three patients, across a period of two weeks show improvements of the proposed platform in the collection of meaningful data about a person, and on maintaining awareness of the therapy as a whole.", "future_impact": "N/A", "venue": null, "year": null, "title": "Enabling Biographical Cognitive Stimulation for People with Dementia"}
{"pid": "081d6673-3c7c-4aec-b101-cf55d75ac718", "context": "Previous partial permutation synchronization (PPS) algorithms commonly used for multi-object matching is intractable for large scale structure-from-motion datasets.  For pure permutation synchronization, the recent Cycle-Edge Message Passing (CEMP) framework suggests a memory-efficient and fast solution.", "key_idea": "The authors propose an improved algorithm named CEMP-Partial, which can overcome the restriction of CEMP to compact groups, used to estimate the corruption levels of the observed partial permutations. CEMP-Partial allows people to subsequently implement a nonconvex weighted projected power method without the need of spectral initialization. ", "method": "The authors apply CEMP-Partial algorithms on adversarial corruption and on both synthetic and real datasets.", "outcome": "Compared to previous PPS algorithms, CEMP-Partial enjoys lower time and space complexities. Under adversarial corruption, CEMP-Partial is able to exactly classify corrupted and clean partial permutations without additive noise and with certain assumptions. ", "future_impact": "N/A", "venue": null, "year": null, "title": "Fast, Accurate and Memory-Efficient Partial Permutation Synchronization"}
{"pid": "081d6673-3c7c-4aec-b101-cf55d75ac718", "context": "Previous partial permutation synchronization (PPS) algorithms often involve computation-intensive and memory-demanding matrix operations, which are intractable for large scale structure-from-motion datasets. Pure permutation synchronization, such as Cycle-Edge Message Passing (CEMP) framework suggests a memory-efficient and fast solution.", "key_idea": "The authors propose an improved algorithm, CEMP-Partial, for estimating the corruption levels of the observed partial permutations, as well as the resulting new PPS algorithm, MatchFAME (Fast, Accurate and Memory-Efficient Matching), which only involves sparse matrix operations, and thus enjoys lower time and space complexities in comparison to previous PPS algorithms..", "method": "The authors examine the performance of CEMP-Partial under adversarial corruption but without additive noise and with certain assumptions.", "outcome": "The authors prove that CEMP-Partial is able to exactly classify corrupted and clean partial permutations and demonstrate the state-of-the-art accuracy, speed and memory efficiency of our method on both synthetic and real datasets.", "future_impact": "N/A", "venue": null, "year": null, "title": "Fast, Accurate and Memory-Efficient Partial Permutation Synchronization"}
{"pid": "10c15fe5-c315-4b6d-8910-e6bc3279c817", "context": "Most existing methods, including those based on incremental clustering and community detection, learn limited amounts of knowledge as they ignore the rich semantics and structural information contained in social data.  Moreover, they cannot memorize previously acquired knowledge.", "key_idea": "The authors propose a novel Knowledge-Preserving Incremental Heterogeneous Graph Neural Network (KPGNN) for incremental social event detection. ", "method": "The authors conduct experiment to evaluate Knowledge-Preserving Incremental Heterogeneous Graph Neural Network(KPGNN)'s performance on incremental social event detection compared to baseline method's performance.", "outcome": "Extensive experiment results demonstrate the superiority of KPGNN's performance on incremental social event detection over various baselines.", "future_impact": "N/A", "venue": null, "year": null, "title": "Knowledge-Preserving Incremental Social Event Detection via Heterogeneous GNNs"}
{"pid": "10c15fe5-c315-4b6d-8910-e6bc3279c817", "context": "The complexity and streaming nature of social messages make it appealing to address social event detection in an incremental learning setting, where acquiring, preserving, and extending knowledge are major concerns. Most existing methods, including those based on incremental clustering and community detection, learn limited amounts of knowledge as they ignore the rich semantics and structural information contained in social data. Moreover, they cannot memorize previously acquired knowledge.", "key_idea": "Authors propose a novel Knowledge-Preserving Incremental Heterogeneous Graph Neural Network (KPGNN) for incremental social event detection. To acquire more knowledge, KPGNN models complex social messages into unified social graphs to facilitate data utilization and explores the expressive power of GNNs for knowledge extraction. To continuously adapt to the incoming data, KPGNN adopts contrastive loss terms that cope with a changing number of event classes. It also leverages the inductive learning ability of GNNs to efficiently detect events and extends its knowledge from previously unseen data. To deal with large social streams, KPGNN adopts a mini-batch subgraph sampling strategy for scalable training, and periodically removes obsolete data to maintain a dynamic embedding space. ", "method": "Authors setup experiments to compare KPGNN over various baselines.", "outcome": "Extensive experiment results demonstrate the superiority of KPGNN over various baselines.", "future_impact": "N/A", "venue": null, "year": null, "title": "Knowledge-Preserving Incremental Social Event Detection via Heterogeneous GNNs"}
{"pid": "14b0ebd1-b654-4eed-bdd8-ebeb74250b15", "context": "In few-shot relational triple extraction, one seeks to extract relational triples from plain texts by utilizing few annotated samples. Recent work first extracts all entities and then classifies their relations, which ignores the entity discrepancy between relations.", "key_idea": "The author first proposes a novel task decomposition strategy for FS-RTE, which detects relations occurred in a sentence and then extracts the corresponding head/tail entities of the detected relations. To instantiate this strategy, the author also proposes a model that builds a dual-level attention to aggregate relation-relevant information to detect the relation occurrence and utilizes the annotated samples of the detected relations to extract the corresponding head/tail entities.", "method": "The author assesses the performance of the proposed strategy against previous works.", "outcome": "Experimental results show that the proposed model outperforms previous work by an absolute gain (18.98%, 28.85% in F1 in two few-shot settings).", "future_impact": "N/A", "venue": null, "year": null, "title": "Relation-Guided Few-Shot Relational Triple Extraction"}
{"pid": "16c1b4ae-73f8-4c23-8bdb-b931ade1baa5", "context": "Various tasks in decision making and decision support require selecting a preferred subset of items from a given set of feasible items. Recent work in this area considered methods for specifying such preferences based on the attribute values of individual elements within the set. Of these, the approach of (Brafman et al. 2006) appears to be the most general.", "key_idea": "Authors consider the problem of computing an optimal subset given such a specification. Authors consider two algorithm classes for this problem: direct set construction, and implicit enumeration as solutions to appropriate CSPs. New algorithms are presented in each class and compared empirically against previous results.", "method": "Authors compare proposed method with previous methods empirically .", "outcome": "Authors present new algorithms  in each class and compared empirically against previous results.", "future_impact": "N/A", "venue": null, "year": null, "title": "Computing optimal subsets"}
{"pid": "18f27ced-9f37-45d7-9b76-6663c349d408", "context": "Most of existing cross-modal retrieval approaches were proposed to learn a common subspace in a joint manner, where the data from all modalities have to be involved during the whole training process. \r\nIn these approaches, the whole model has to be retrained when handling samples from new modalities.", "key_idea": "The paper introduces a novel cross-modal retrieval method namedScalable Deep Multimodal Learning (SDML), a method that predefines a common subspace to maximize between-class variation and minimize within-class variation. ", "method": "The authors applied SDML on four widely-used benchmark datasets to figure its performance.", "outcome": "SDML could be one of the first works to independently project data of an unfixed number of modalities into a predefined common subspace.\r\nExperimental results on four widely-used benchmark datasets demonstrate that the SDML is effective and efficient in multimodal learning and outperforms the state-of-the-art methods in cross-modal retrieval.", "future_impact": "N/A", "venue": null, "year": null, "title": "Scalable Deep Multimodal Learning for Cross-Modal Retrieval"}
{"pid": "18f27ced-9f37-45d7-9b76-6663c349d408", "context": "Most of existing cross-modal retrieval approaches were proposed to learn a common subspace in a joint manner, where the data from all modalities have to be involved during the whole training process. The optimal parameters of different modality-specific transformations are dependent on each other and the whole model has to be retrained when handling samples from new modalities.", "key_idea": "The author proposes a cross-modal retrieval method that predefines a common subspace, maximizing between-class and minimizing within-class variation, and trains m modality-specific networks for m modalities (one network for each modality) to transform the multimodal data into the predefined common subspace to achieve multimodal learning. The model can train different modality-specific networks independently.", "method": "The author tests the model against four widely-used benchmark datasets for effectiveness and efficiency in multimodal learning.", "outcome": "Experimental results on four widely-used benchmark datasets demonstrate that the proposed method is effective and efficient in multimodal learning and outperforms the state-of-the-art methods in cross-modal retrieval.", "future_impact": "N/A", "venue": null, "year": null, "title": "Scalable Deep Multimodal Learning for Cross-Modal Retrieval"}
{"pid": "192f7803-df4d-40c0-b816-ba34339026b3", "context": "Most current single image SR methods use empirical risk minimisation, often with a pixel-wise mean squared error (MSE) loss, but the outputs from such methods tend to be blurry, over-smoothed and generally appear implausible. A more desirable approach employs Maximum a Posteriori (MAP) inference, preferring solutions that always have a high probability under the image prior, and thus appear more plausible, which is not non-trivial as it requires us to build a model for the image prior from samples. ", "key_idea": "The author introduces new methods for amortised MAP inference by reducing the problem to minimising the cross-entropy between two distributions after using a novel neural network architecture that performs a projection to the affine subspace of valid SR solutions, and then proposes three methods to solve the reduced problem: (1) Generative Adversarial Networks (GAN) (2) denoiser-guided SR which backpropagates gradient-estimates from denoising to train the network, and (3) a baseline method using a maximum-likelihood-trained image prior.", "method": "The author tests the proposed three reduced optimisation problem on real image data.", "outcome": "The experiments show that the GAN based approach performs best on real image data.", "future_impact": "N/A", "venue": null, "year": null, "title": "Amortised MAP Inference for Image Super-resolution"}
{"pid": "1946f496-f6cd-4736-8c30-a6ae70baa8b2", "context": "Due to overly simplified assumption that treat such intrinsic relevance as an atomic query-document-specific parameter, which is solely estimated from historical clicks without using any content information about a document or relationship among the clicked/skipped documents under the same query, existing click models can neither fully explore the information about a document's relevance quality nor make predictions of relevance for any unseen documents.", "key_idea": "The authors proposed a novel Bayesian Sequential State model for modeling the user click behaviors, where the document content and dependencies among the sequential click events within a query are characterized by a set of descriptive features via a probabilistic graphical model.", "method": "The authors conduct experiments on a large set of real click logs to evaluate effectiveness of novel Bayesian Sequential State model ", "outcome": "Experiment results on a large set of real click logs demonstrate the effectiveness of novel Bayesian Sequential State model compared with several state-of-the-art click models.", "future_impact": "N/A", "venue": null, "year": null, "title": "Content-aware click modeling"}
{"pid": "1946f496-f6cd-4736-8c30-a6ae70baa8b2", "context": "One basic modeling assumption of Click models made in existing work is to treat the intrinsic relevance of documents to queries as an atomic query-document-specific parameter. Due to this overly simplified assumption, existing click models can neither fully explore the information about a document's relevance quality nor make predictions of relevance for any unseen documents.", "key_idea": "The authors propose a novel Bayesian Sequential State model for modeling the user click behaviors, where the document content and dependencies among the sequential click events within a query are characterized by a set of descriptive features via a probabilistic graphical model.", "method": "The authors evaluate their model on a large set of real click logs.", "outcome": "Experiment results on a large set of real click logs demonstrate the effectiveness of the proposed model compared with several state-of-the-art click models.", "future_impact": "N/A", "venue": null, "year": null, "title": "Content-aware click modeling"}
{"pid": "1b0e4045-d39b-4bea-8dec-e747f5c674f5", "context": "Probabilistic databases have been recently developed to manage data uncertainty such as sensor monitoring systems, location-based services, and biological databases. The difficulty of a probabilistic database is that it can have an exponential number of possible worlds.", "key_idea": "The author studies the discovery of frequent patterns and association rules from probabilistic data under the Possible World Semantics. The author proposes two efficient algorithms, which discover frequent patterns in bottom-up and top-down manners, both of which can be easily extended to discover maximal frequent patterns.", "method": "The author uses real and synthetic datasets to test the performance of their methods.", "outcome": "The performance of their methods is validated through real and synthetic datasets.", "future_impact": "N/A", "venue": null, "year": null, "title": "Mining uncertain data with probabilistic guarantees"}
{"pid": "1dea5ec2-d311-4c03-bba5-e38d7a62fbd4", "context": "It's challenging to  tackles the problem of spotting a set of signs occuring in videos with sequences of signs. ", "key_idea": "The authors propose a novel multi-class classifier that organises different sequential interval patterns in a hierarchical tree structure called a Hierarchical SIP Tree (HSP-Tree) to tackles the problem of spotting a set of signs occuring in videos with sequences of signs.", "method": "The authors evaluated the HSP-Forest on both concatenated sequences of isolated signs and continuous sign sequences. ", "outcome": "The authors prove that HSP-Forest can be used to spot sequences of signs that occur in an input video and the proposed method is superior in robustness and accuracy to a state of the art sign recogniser when applied to spotting a sequence of signs.", "future_impact": "N/A", "venue": null, "year": null, "title": "Sign Spotting Using Hierarchical Sequential Patterns with Temporal Intervals"}
{"pid": "1e396f93-a73e-4d33-9a8e-56097a8c3c28", "context": "Although deep learning has yielded state-of-the-art performance on many natural language processing tasks including named entity recognition (NER), it typically requires large amounts of labeled data. ", "key_idea": "The authors introduce a lightweight architecture for NER, viz., the CNN-CNN-LSTM model consisting of convolutional character and word encoders and a long short term memory (LSTM) tag decoder to speed up active learning.", "method": "The authors evaluate CNN-CNN-LSTM model performance on standard datasets.", "outcome": "CNN-CNN-LSTM model achieves nearly state-of-the-art performance on standard datasets for the task while being computationally much more efficient than best performing models. \r\nDuring the training process, incremental active learning has been carried out, CNN-CNN-LSTM mode are able to nearly match state-of-the-art performance with just 25% of the original training data.", "future_impact": "N/A", "venue": null, "year": null, "title": "Deep Active Learning for Named Entity Recognition"}
{"pid": "1e396f93-a73e-4d33-9a8e-56097a8c3c28", "context": "Deep learning has yielded state-of-the-art performance on many natural language processing tasks including named entity recognition (NER). However, this typically requires large amounts of labeled data.", "key_idea": "The authors demonstrate that the amount of labeled training data can be drastically reduced when deep learning is combined with active learning, and introduce a lightweight architecture for NER, viz., the CNN-CNN-LSTM model consisting of convolutional character and word encoders and a long short term memory (LSTM) tag decoder to speed up the process.", "method": "The authors evaluate their method on standard datasets.", "outcome": "The proposed model achieves nearly state-of-the-art performance on standard datasets for the task while being computationally much more efficient than best performing models. The authors carry out incremental active learning, during the training process, and are able to nearly match state-of-the-art performance with just 25% of the original training data.", "future_impact": "N/A", "venue": null, "year": null, "title": "Deep Active Learning for Named Entity Recognition"}
{"pid": "1ef9b762-e9be-46c5-ad19-090fe16200c4", "context": "Accurately deriving pointing information from a corresponding gesture is an important issue in human-robot interaction.", "key_idea": "Based on the fact that in most applications it is the pointed object rather than the actual pointing direction which is important, authors formulate a novel approach which takes into account prior information about the location of possible pointing targets. \r\nTo decide about the pointed object, the proposed approach uses the Dempster-Shafer theory of evidence to fuse information from two different input streams: head pose, estimated by visually tracking the off-plane rotations of the face, and hand pointing orientation.", "method": "Authors design detailed experiments to validate the propose method in  realistic application setups..", "outcome": "Authors present detailed experimental results that validate the effectiveness of the method in realistic application setups.", "future_impact": "N/A", "venue": null, "year": null, "title": "Visual estimation of pointed targets for robot guidance via fusion of face pose and hand orientation"}
{"pid": "29dd9fd3-6c98-4e4b-b70c-0474ff361419", "context": "Animals are diverse in shape, but building a deformable shape model for a new species is not always possible due to the lack of 3D data.", "key_idea": "The authors present a method to capture new species using an articulated template and images of that species. They learn models of multiple species from the CUB dataset, and contribute new species-specific and multi-species shape models that are useful for downstream reconstruction tasks.", "method": "The authors compare their learned 3D shape space with learned perceptual features.", "outcome": "Using a low-dimensional embedding, the authors show that the learned 3D shape space better reflects the phylogenetic relationships among birds than learned perceptual features.", "future_impact": "N/A", "venue": null, "year": null, "title": "Birds of a Feather: Capturing Avian Shape Models from Images"}
{"pid": "29dd9fd3-6c98-4e4b-b70c-0474ff361419", "context": "Building a deformable shape model for a new species is not always possible due to the lack of 3D data.", "key_idea": "The authors propose a method to capture new species using an articulated template and images of that species. ", "method": "The authors learn models of multiple species from the CUB dataset, and contribute new species-specific and multi-species shape models that are useful for downstream reconstruction tasks. Using a low-dimensional embedding, the authors compare learned 3D shape space with learned perceptual features.", "outcome": "Experiments prove that learned 3D shape space better reflects the phylogenetic relationships among birds than learned perceptual features.", "future_impact": "N/A", "venue": null, "year": null, "title": "Birds of a Feather: Capturing Avian Shape Models from Images"}
{"pid": "2b5cc037-4841-4fb1-85ff-673230198be1", "context": "It's challenging to design provable algorithms that can recover an incomplete m* n matrix of rank r, while being tolerant to a large amount of noises, with small sample complexity. ", "key_idea": "The authors propose algorithms that can recover an incomplete m* n matrix of rank r, providing strong guarantee under two realistic noise models.", "method": "The authors compare new algorithms performance in both bounded deterministic noise and noiseless case.\r\nThe authors study the new algorithms performance under scenario where the hidden matrix lies on a mixture of subspaces.\r\nThe authors conduct experiments to evaluate new algorithms performance in both synthetic and real-world datasets.", "outcome": "The authors prove that new algorithms can return a matrix of a small error, with sample complexity almost as small as the best prior results in the noiseless case and new algorithms perform well experimentally in both synthetic and real-world datasets.\r\nThe sample complexity can be even smaller when apply new algorithms under scenario where the hidden matrix lies on a mixture of subspaces .", "future_impact": "N/A", "venue": null, "year": null, "title": "Noise-Tolerant Life-Long Matrix Completion via Adaptive Sampling"}
{"pid": "2b5cc037-4841-4fb1-85ff-673230198be1", "context": "The problem of life-long matrix completion is widely applied to recommendation system, computer vision, system identification. The challenge is to design provable algorithms tolerant to a large amount of noises, with small sample complexity.", "key_idea": "The authors give algorithms achieving strong guarantee under two realistic noise models.", "method": "The authors evaluate their method in both synthetic and real-world datasets.\r\n", "outcome": "The theoretical result advances the state-of-the-art work and matches the lower bound in a worst case.. The proposed algorithms also perform well experimentally in both synthetic and real-world datasets.", "future_impact": "N/A", "venue": null, "year": null, "title": "Noise-Tolerant Life-Long Matrix Completion via Adaptive Sampling"}
{"pid": "2eb66e5a-472c-4db1-b02f-47fe5eb7e71e", "context": "How to use the Inductive Bias in Transformers for Unsupervised Disentanglement is under explored.", "key_idea": "Authors propose a generative model, dubbed QKVAE, that uses Attention in its decoder to read latent variables where one latent variable infers keys while another infers values.\r\nThe model relies solely on the inductive bias found in attention-based architectures such as Transformers.", "method": "Authors run experiments on latent representations and experiments on syntax/semantics transfer.", "outcome": "Authors show that QKVAE displays clear signs of disentangled syntax and semantics. Authors also show that the model displays competitive syntax transfer capabilities when compared to supervised models and that comparable supervised models need a fairly large amount of data (more than 50K samples) to outperform it on both syntactic and semantic transfer.", "future_impact": "N/A", "venue": null, "year": null, "title": "Exploiting Inductive Bias in Transformers for Unsupervised Disentanglement of Syntax and Semantics with VAEs"}
{"pid": "2eb66e5a-472c-4db1-b02f-47fe5eb7e71e", "context": "Previous generative model for text generation need syntactic information such as constituency parses, or semantic information such as paraphrase pairs.", "key_idea": "The authors propose a generative model for text generation, which exhibits disentangled latent representations of syntax and semantics, QKVAE.", "method": "The authors use their proposed QKVAE run experiments on latent representations and experiments on syntax/semantics transfer", "outcome": "The experiments on latent representations and experiments on syntax/semantics transfer show that QKVAE displays clear signs of disentangled syntax and semantics. The authors also show that the model displays competitive syntax transfer capabilities when compared to supervised models and that comparable supervised models need a fairly large amount of data (more than 50K samples) to outperform it on both syntactic and semantic transfer", "future_impact": "N/A", "venue": null, "year": null, "title": "Exploiting Inductive Bias in Transformers for Unsupervised Disentanglement of Syntax and Semantics with VAEs"}
{"pid": "31ab88b5-e66f-4b69-98b6-7a470dce9875", "context": "Common approaches of conditioning include input concatenation or modulation with the conditioning vector, which comes at a cost of increased model size.", "key_idea": "The authors introduce a novel approach of neural network conditioning by learning intermediate layer activations based on the conditioning vector.", "method": "The authors systematically explore novel neural network conditioning approach and conduct experiment to compare novel neural network conditioning approach's performance to traditional conditioning methods.", "outcome": "Experiments demonstrate that conditional  models using learned activation functions can have comparable or better quality than traditional methods, while decreasing model sizes, thus making them ideal candidates for resource-efficient on-device deployment.", "future_impact": "This novel neural network conditioning approach may have a broad applicability of the proposed technique across a number of application domains.", "venue": null, "year": null, "title": "Conditioning Sequence-to-sequence Networks with Learned Activations"}
{"pid": "31ab88b5-e66f-4b69-98b6-7a470dce9875", "context": "In conditional neural networks, the output of a model is often influenced by a conditioning vector, in addition to the input. Common approaches of conditioning include input concatenation or modulation with the conditioning vector, which comes at a cost of increased model size.", "key_idea": "The author introduces a novel approach of neural network conditioning by learning intermediate layer activations based on the conditioning vector.", "method": "As exemplary target use-cases the author considers (i) the task of PSE as a pre-processing technique for improving telephony or pre-trained ASR performance under noise, and (ii) personalized ASR in single speaker scenarios.", "outcome": "The learned activation functions can produce conditional models with comparable or better quality, while decreasing model sizes, thus making them ideal candidates for resource-efficient on-device deployment. The author finds that conditioning via activation function learning is an effective modeling strategy.", "future_impact": "Conditioning via activation function learning has a broad applicability of the proposed technique across a number of application domains.", "venue": null, "year": null, "title": "Conditioning Sequence-to-sequence Networks with Learned Activations"}
{"pid": "36d7073a-d006-4a4a-850f-ca7a3f0ca19b", "context": "Numerous important problems can be framed as learning from graph data.", "key_idea": "The author proposes a framework for learning convolutional neural networks for arbitrary graphs, where the graphs may be undirected, directed, and with both discrete and continuous node and edge attributes. The author presents a general approach to extracting locally connected regions from graphs analogous to image-based convolutional networks.", "method": "The authors test the learned feature representations and computation efficiency proposed framework on established benchmark data sets.", "outcome": "Using established benchmark data sets, the author demonstrates that the learned feature representations are competitive with state of the art graph kernels and that their computation is highly efficient.", "future_impact": "N/A", "venue": null, "year": null, "title": "Learning convolutional neural networks for graphs"}
{"pid": "36d7073a-d006-4a4a-850f-ca7a3f0ca19b", "context": "Numerous important problems can be framed as learning from graph data.", "key_idea": "The authors propose a framework for learning convolutional neural networks for arbitrary graphs.", "method": "The authors evaluated their proposed framework on established benchmark data sets.", "outcome": "The authors demonstrate that the learned feature representations are competitive with state of the art graph kernels and that their computation is highly efficient on established benchmark data sets.", "future_impact": "N/A", "venue": null, "year": null, "title": "Learning convolutional neural networks for graphs"}
{"pid": "370141c7-e1bb-4010-9938-efcad6cf2e62", "context": "Novel architectures often result in challenging hyper-parameter choices and training instability if the network parameters are not properly initialized. A number of architecture-specific initialization schemes have been proposed, but these schemes are not always portable to new architectures.", "key_idea": "This paper presents GradInit, an automated and architecture agnostic method for initializing neural networks. GradInit is based on a simple heuristic; the norm of each network layer is adjusted so that a single step of SGD or Adam with prescribed hyperparameters results in the smallest possible loss value.", "method": "The authors test convergence and test performance of many convolutional architectures of Gradlnit. And compare Gradlnit's stability with original Transformer architectures' stability for machine translation.", "outcome": "GradInit accelerates the convergence and test performance of many convolutional architectures, both with or without skip connections, and even without normalization layers. GradInit also improves the stability of the original Transformer architecture for machine translation, enabling training it without learning rate warmup using either Adam or SGD under a wide range of learning rates and momentum coefficients. ", "future_impact": "N/A", "venue": null, "year": null, "title": "GradInit: Learning to Initialize Neural Networks for Stable and Efficient Training."}
{"pid": "370141c7-e1bb-4010-9938-efcad6cf2e62", "context": "Novel neural architectures often result in challenging hyper-parameter choices and training instability if the network parameters are not properly initialized. Previously proposed architecture-specific initialization schemes are not always portable to new architectures.", "key_idea": "The author proposes an automated and architecture agnostic method for initializing neural networks, where the norm of each network layer is adjusted so that a single step of SGD or Adam with prescribed hyperparameters results in the smallest possible loss value. The adjustment is done by introducing a scalar multiplier variable in front of each parameter block, and then optimizing these variables using a simple numerical scheme.", "method": "The author tests the proposed approach\u2019s performance against many convolutional architectures, both with or without skip connections, or without normalization layers. They also test stability of the approach against the original Transformer architecture for machine translation.", "outcome": "The proposed approach accelerates the convergence and test performance of many convolutional architectures, both with or without skip connections, and even without normalization layers. It also improves the stability of the original Transformer architecture for machine translation, enabling training it without learning rate warmup using either Adam or SGD under a wide range of learning rates and momentum coefficients.", "future_impact": "N/A", "venue": null, "year": null, "title": "GradInit: Learning to Initialize Neural Networks for Stable and Efficient Training."}
{"pid": "3ac464c2-2214-4bf2-a6b6-03da2498cb03", "context": "Query scheduling, a fundamental problem in database management systems, has recently received a renewed attention, perhaps in part due to the rise of the database as a service\" (DaaS) model for database deployment. While there has been a great deal of work investigating different scheduling algorithms, there has been comparatively little work investigating what the scheduling algorithms can or should know about the queries to be scheduled.", "key_idea": "The authors investigate the efficacy of using histograms describing the distribution of likely query execution times as input to the query scheduler and propose a novel distribution-based scheduling algorithm, Shepherd.", "method": "The authors evaluate their Shepherd through extensive experimentation with both synthetic and TPC workloads and compare it with state-of-the-art point-based methods .", "outcome": "The authors show that their Shepherd substantially outperforms state-of-the-art point-based methods through extensive experimentation with both synthetic and TPC workloads.", "future_impact": "N/A", "venue": null, "year": null, "title": "Distribution-based query scheduling"}
{"pid": "3ac464c2-2214-4bf2-a6b6-03da2498cb03", "context": "While there has been a great deal of work investigating different scheduling algorithms in database management systems, there has been comparatively little work investigating what the scheduling algorithms can or should know about the queries to be scheduled.", "key_idea": "The author proposes a novel distribution-based scheduling algorithm.", "method": "The author compares the proposed algorithm with state-of-the-art point-based methods through extensive experimentation with both synthetic and TPC workloads.", "outcome": "The author shows that the proposed algorithm substantially outperforms state-of-the-art point-based methods through extensive experimentation with both synthetic and TPC workloads.", "future_impact": "N/A", "venue": null, "year": null, "title": "Distribution-based query scheduling"}
{"pid": "3b6e7572-2ef8-4565-a3b7-301a3fd38acd", "context": "Backward locking and update locking are sources of inefficiency in backpropagation that prevent from concurrently updating layers. Using local error signals to train network blocks asynchronously are suggested to overcome these limitations, but they often require numerous iterations of trial-and-error to find the best configuration for local training.", "key_idea": "The authors propose a differentiable search algorithm named SEDONA to automate process, carrying on numerous iterations of trial-and-error to find the best configuration for local training, including how to decouple network blocks and which auxiliary networks to use for each block.", "method": "The authors apply SEDONA search algorithm on VGG and ResNet and record the time of backpropagation after using SEDONA search algorithm.", "outcome": "SEDONA search algorithm consistently discover transferable decoupled architectures for VGG and ResNet variants, and significantly outperforms the ones trained with end-to-end backpropagation and other state-of-the-art greedy-leaning methods in CIFAR-10, Tiny-ImageNet and ImageNet.\r\nThere are 2\u00d7 speedup over backpropagation in total training time due to improved parallelism by local training.", "future_impact": "N/A", "venue": null, "year": null, "title": "SEDONA: Search for Decoupled Neural Networks toward Greedy Block-wise Learning"}
{"pid": "3b6e7572-2ef8-4565-a3b7-301a3fd38acd", "context": "Backward locking and update locking are well-known sources of inefficiency in backpropagation that prevent from concurrently updating layers. Several works have recently suggested using local error signals to train network blocks asynchronously to overcome these limitations. However, they often require numerous iterations of trial-and-error to find the best configuration for local training, including how to decouple network blocks and which auxiliary networks to use for each block. ", "key_idea": "Authors propose a differentiable search algorithm named SEDONA to automate this process.", "method": "Authors test the proposed method against other SOTA methods, in CIFAR-10, Tiny-ImageNet and ImageNet. ", "outcome": "Experimental results show that our algorithm can consistently discover transferable decoupled architectures for VGG and ResNet variants, and significantly outperforms the ones trained with end-to-end backpropagation and other state-of-the-art greedy-leaning methods in CIFAR-10, Tiny-ImageNet and ImageNet. Authors also report up to 2\u00d7 speedup over backpropagation in total training time.", "future_impact": "N/A", "venue": null, "year": null, "title": "SEDONA: Search for Decoupled Neural Networks toward Greedy Block-wise Learning"}
{"pid": "432f5702-7b7d-4995-812e-40925f1a18dd", "context": "Conditional modeling x \u2192 y is a central problem in machine learning, and a substantial research effort is devoted to such modeling when x is high dimensional.", "key_idea": "The authors consider conditional modeling x \u2192 y with a high dimensional y by selecting a small subset yL of the dimensions of y, modeling (i) x \u2192 yL and (ii) yL \u2192 y and composing these two models.", "method": "The authors run multilabel classification and multivariate regression experiments on several datasets.", "outcome": "Multilabel classification and multivariate regression experiments on several datasets show that this method outperforms the one vs. all approach as well as several sophisticated multiple output prediction methods.", "future_impact": "N/A", "venue": null, "year": null, "title": "The Landmark Selection Method for Multiple Output Prediction"}
{"pid": "432f5702-7b7d-4995-812e-40925f1a18dd", "context": "Conditional modeling x \u2192 y is a central problem in machine learning.", "key_idea": "The authors propose an method that composing two models, one is modeling (i) x \u2192 yL and the other one is modeling (ii) yL \u2192 y on selecting a small subset yL of the dimensions of y, and obtain a conditional model x \u2192 y that possesses convenient statistical properties in the end.", "method": "The authors product multilabel classification and multivariate regression experiments on several dataset to evaluate the performance of new method.", "outcome": "The new method, composing two models, outperforms the one vs. all approach as well as several sophisticated multiple output prediction methods on multilabel classification and multivariate regression tasks.", "future_impact": "N/A", "venue": null, "year": null, "title": "The Landmark Selection Method for Multiple Output Prediction"}
{"pid": "438caf1c-5c7e-4283-a3cd-bbab302df185", "context": "Common acquisition functions for active learning use either uncertainty or diversity sampling, aiming to select difficult and diverse data points from the pool of unlabeled data, respectively.", "key_idea": "Leveraging the best of uncertainty and diversity sampling, the author proposes an acquisition function that opts for selecting contrastive examples, which are data points that are similar in the model feature space and yet the model outputs maximally different predictive likelihoods.", "method": "The author compares the proposed approach with a diverse set of acquisition functions in four natural language understanding tasks and seven datasets. The author also conducts an extensive ablation study of the method and analyzes all actively acquired datasets.", "outcome": "The experiments show that proposed approach performs consistently better or equal than the best performing baseline across all tasks, on both in-domain and out-of-domain data. The proposed method also achieves a better trade-off between uncertainty and diversity compared to other strategies.", "future_impact": "N/A", "venue": null, "year": null, "title": "Active Learning by Acquiring Contrastive Examples."}
{"pid": "438caf1c-5c7e-4283-a3cd-bbab302df185", "context": "Common acquisition functions for active learning use either uncertainty or diversity sampling, aiming to select difficult and diverse data points from the pool of unlabeled data, respectively.", "key_idea": "The authors propose an acquisition function that opts for selecting \"contrastive examples\", i.e. data points that are similar in the model feature space and yet the model outputs maximally different predictive likelihoods.", "method": "The authors compare our approach, CAL (Contrastive Active Learning), with a diverse set of acquisition functions in four natural language understanding tasks and seven datasets. They also conduct an extensive ablation study of the proposed method", "outcome": "The experiments show that CAL performs consistently better or equal than the best performing baseline across all tasks, on both in-domain and out-of-domain data. An extensive ablation study of the proposed method and further analysis show that CAL achieves a better trade-off between uncertainty and diversity compared to other strategies.", "future_impact": "N/A", "venue": null, "year": null, "title": "Active Learning by Acquiring Contrastive Examples."}
{"pid": "45b76955-9670-4664-939c-f5a61eb597df", "context": "auditing group fairness in ranked lists is an important problem.", "key_idea": "Authors introduce a novel metric for auditing group fairness in ranked lists. Authors first offer a blueprint for modeling of user attention. Second, authors allow non-binary protected attributes to enable investigating inherently continuous attributes (e.g., political alignment on the liberal to conservative spectrum) as well as to facilitate measurements across aggregated sets of search results, rather than separately for each result list.", "method": "Authors use the proposed metric to perform three simulated fairness audits.", "outcome": "The proposed metrics are able to better address the human factors inherent in this problem. Authors show that determining fairness of a ranked output necessitates knowledge (or a model) of the end-users of the particular service. Depending on their attention distribution function, a fixed ranking of results can appear biased both in favor and against a protected group1.", "future_impact": "N/A", "venue": null, "year": null, "title": "Quantifying the Impact of User Attentionon Fair Group Representation in Ranked Lists"}
{"pid": "45b76955-9670-4664-939c-f5a61eb597df", "context": "Previous metrics for auditing group fairness in ranked lists cannot exclude the inherent human factors.", "key_idea": "The authors introduce a novel metric for auditing group fairness in ranked lists, which can be able to better address the human factors inherent in this problem.", "method": "The authors use novel metric to perform three simulated fairness audits.", "outcome": "The authors conclude that determining fairness of a ranked output necessitates knowledge (or a model) of the end-users of the particular service. Depending on attention distribution function, a fixed ranking of results can appear biased both in favor and against a protected group1.", "future_impact": "N/A", "venue": null, "year": null, "title": "Quantifying the Impact of User Attentionon Fair Group Representation in Ranked Lists"}
{"pid": "48bacac1-1ca9-4be8-90e6-470596de0e26", "context": "Recognizing polarity requires a list of polar words and phrases. For the purpose of building such lexicon automatically, a lot of studies have investigated (semi-) unsupervised method of learning polarity of words and phrases.", "key_idea": "Authors propose to use structural clues that can extract polar sentences from Japanese HTML documents, and build lexicon from the extracted polar sentences. The key idea is to develop the structural clues so that it achieves extremely high precision at the cost of recall.", "method": "Authors design experiments with massive collection of HTML documents.", "outcome": "The proposed method can effectively achieve high precision with low recall.", "future_impact": "N/A", "venue": null, "year": null, "title": "Building Lexicon for Sentiment Analysis from Massive Collection of HTML Documents"}
{"pid": "48bacac1-1ca9-4be8-90e6-470596de0e26", "context": "Recognizing polarity requires a list of polar words and phrases. In order to building such lexicon automatically, many studies have investigated (semi-)unsupervised method of learning polarity of words and phrases. ", "key_idea": "The authors explore to use structural clues that can extract polar sentences from Japanese HTML documents, and build lexicon from the extracted polar sentences and develop the structural clues so that it achieves extremely high precision at the cost of recall.", "method": "The author use structural clues that can extract polar sentences from Japanese HTML documents, and build lexicon from the extracted polar sentences.", "outcome": "The author prepare enough polar sentence corpus used to recognizing polarity.", "future_impact": "N/A", "venue": null, "year": null, "title": "Building Lexicon for Sentiment Analysis from Massive Collection of HTML Documents"}
{"pid": "49309d5a-5959-4f8f-ae30-9fd2350f0cbc", "context": "CNNs poses a challenge in deploying them on constrained devices since it requires enormous amount of memory and compute resources. Existing compression techniques, while excelling at reducing model sizes, struggle to be computationally friendly.", "key_idea": "The authors propose a novel quantization strategy based on power-of-two values, which exploits the weight distributions after fine-grained pruning when attending to the statistical properties of sparse CNNs and present focused quantization.", "method": "The authors evaluate novel quantization strategy CR and top-5 accuracy on ResNet-50 and ResNet-18", "outcome": "In ResNet-50, novel quantization strategy achieved a 18.08x CR with only 0.24% loss in top-5 accuracy, outperforming existing compression methods.\r\nOn ResNet-18, novel quantization not only achieved higher R and top-5 accuracy, but also achieved more hardware efficient as it requires fewer logic gates to implement when compared to other state-of-the-art quantization methods assuming the same throughput.", "future_impact": "N/A", "venue": null, "year": null, "title": "Focused Quantization for Sparse CNNs"}
{"pid": "49309d5a-5959-4f8f-ae30-9fd2350f0cbc", "context": "Deep convolutional neural networks (CNNs) are powerful tools for a wide range of vision tasks, but the enormous amount of memory and compute resources required by CNNs poses a challenge in deploying them on constrained devices. Existing compression techniques, while excelling at reducing model sizes, struggle to be computationally friendly.", "key_idea": "The authors present focused quantization, a novel quantization strategy based on power-of-two values, which exploits the weight distributions after fine-grained pruning, based on the statistical properties of sparse CNNs.", "method": "The authors apply their proposed compression method on ResNet-50 and ResNet-18.", "outcome": "In ResNet-50, the proposed compression method achieved a 18.08x CR with only 0.24% loss in top-5 accuracy, outperforming existing compression methods. The authors also fully compress a ResNet-18 and find that it is not only higher in CR and top-5 accuracy, but also more hardware efficient", "future_impact": "N/A", "venue": null, "year": null, "title": "Focused Quantization for Sparse CNNs"}
{"pid": "4e6f8004-9384-4c5c-8d7f-265410a290df", "context": "Several deep learning methods have been proposed for completing partial data from shape acquisition setups, i.e., filling the regions that were missing in the shape. These methods, however, only complete the partial shape with a single output, ignoring the ambiguity when reasoning the missing geometry. ", "key_idea": "Authors pose a multi-modal shape completion problem, in which authors seek to complete the partial shape with multiple outputs by learning a one-to-many mapping. Authors develop the first multimodal shape completion method that completes the partial shape via conditional generative modeling, without requiring paired training data. Authors' approach distills the ambiguity by conditioning the completion on a learned multimodal distribution of possible results.", "method": "Authors build a testbed on several datasets that contain varying forms of shape incompleteness, and compare among several baseline methods and variants of proposed methods qualitatively and quantitatively.", "outcome": "Authors extensively evaluate the approach on several datasets that contain varying forms of shape incompleteness, and compare among several baseline methods and variants of our methods qualitatively and quantitatively, demonstrating the merit of proposed method in completing partial shapes with both diversity and quality.", "future_impact": "N/A", "venue": null, "year": null, "title": "Multimodal Shape Completion via Conditional Generative Adversarial Networks"}
{"pid": "4e6f8004-9384-4c5c-8d7f-265410a290df", "context": "Several deep learning methods have been proposed for completing partial data from shape acquisition setups, i.e., filling the regions that were missing in the shape. These methods, however, only complete the partial shape with a single output, ignoring the ambiguity when reasoning the missing geometry.", "key_idea": "The authors propose a multi-modal shape completion problem, in which they seek to complete the partial shape with multiple outputs by learning a one-to-many mapping. They further develop the first multimodal shape completion method that completes the partial shape via conditional generative modeling, without requiring paired training data.", "method": "The authors extensively evaluate the approach on several datasets that contain varying forms of shape incompleteness, and compare among several baseline methods.", "outcome": "The variants of the proposed methods qualitatively and quantitatively demonstrate the merit in completing partial shapes with both diversity and quality.", "future_impact": "N/A", "venue": null, "year": null, "title": "Multimodal Shape Completion via Conditional Generative Adversarial Networks"}
{"pid": "4fdcceeb-f50f-4c4f-8b92-5985498114f8", "context": "The problem of recovering the three-dimensional motion of a non-rigid object from a sequence of stereo images is complex. Because the object undergoes uniform expansion and three-dimensional shearing about an unknown point in space, in addition to being subjected to rigid motion. ", "key_idea": "The authors propose that the problem of recovering the three-dimensional motion uniquely can be reduced to the (unique) solution of a set of homogeneous polynomial equations using algebraic geometry, the commutative algebra software package, MACAULAY, and the Fortran polynomial continuation program POLSYS.", "method": "The authors use this idea in solving the problem that how to determine the motion uniquely with four points correspondence.", "outcome": "With four points correspondence, only two (stereo) snapshots are needed to determine the motion uniquely.", "future_impact": "N/A", "venue": null, "year": null, "title": "The recovery of non-rigid motion from stereo images"}
{"pid": "532e797a-4b72-488a-80e4-03713d3c8435", "context": "Previous research proposes the traditional idea of using linear low-order or low-rank shape model for the task of Non-Rigid Structure-from-Motion (NRSfM).", "key_idea": "The authors propose a new method for Non-Rigid Structure-from-Motion (NRSfM) from a long monocular video sequence observing a non-rigid object performing recurrent and possibly repetitive dynamic action.", "method": "The authors evaluate their proposed method on both simulated sequences and real data.", "outcome": "Experiments on both simulated sequences and real data demonstrate the effectiveness of the method.", "future_impact": "This paper offers a novel perspective on rethinking structure-from-motion, so it can potentially inspire other new problems in the field.", "venue": null, "year": null, "title": "Structure from Recurrent Motion: From Rigidity to Recurrency"}
{"pid": "532e797a-4b72-488a-80e4-03713d3c8435", "context": "Traditional idea to approach the task of Non-Rigid Structure-from-Motion is by using linear low-order or low-rank shape model.", "key_idea": "The author develops algorithms for automatic recurrency detection and camera view clustering via a rigidity-check by applying standard rigid-SfM techniques to the reconstruction of non-rigid dynamic shapes.", "method": "The author performs experiments on the proposed algorithms with simulated sequences and real data.", "outcome": "Experiments on both simulated sequences and real data demonstrate the effectiveness of the method.", "future_impact": "Since this paper offers a novel perspective on rethinking structure-from-motion, the author hopes it will inspire other new problems in the field.", "venue": null, "year": null, "title": "Structure from Recurrent Motion: From Rigidity to Recurrency"}
{"pid": "56992082-e04e-4a8b-a985-abfea27fc2e0", "context": "Dynamic network pruning achieves runtime acceleration by dynamically determining the inference paths based on different inputs. However, previous methods directly generate continuous decision values for each weight channel, which cannot reflect a clear and interpretable pruning process.", "key_idea": "The author proposes to explicitly model the discrete weight channel selections, which encourages more diverse weights utilization, and achieves more sparse runtime inference paths. The author also proposes a novel adversarial example detection algorithm by discriminating the runtime decision features.", "method": "The author compares the prediction accuracy of the proposed network on the similar computing budgets on CIFAR10 and ImageNet datasets with traditional static pruning methods and other dynamic pruning approaches.", "outcome": "Experiments show that the proposed dynamic network achieves higher prediction accuracy under the similar computing budgets on CIFAR10 and ImageNet datasets compared to traditional static pruning methods and other dynamic pruning approaches.", "future_impact": "The proposed adversarial detection algorithm can significantly improve the state-of-the-art detection rate across multiple attacks, which provides an opportunity to build an interpretable and robust model.", "venue": null, "year": null, "title": "Dynamic Network Pruning with Interpretable Layerwise Channel Selection"}
{"pid": "56992082-e04e-4a8b-a985-abfea27fc2e0", "context": "Previous dynamic network pruning methods directly generate continuous decision values for each weight channel, which cannot reflect a clear and interpretable pruning process. \r\nThere are clear differences in the layerwise decisions between normal and adversarial examples. ", "key_idea": "The authors propose to explicitly model the discrete weight channel selections, which encourages more diverse weights utilization, and achieves more sparse runtime inference paths.\r\nThe authors propose a novel adversarial example detection algorithm by discriminating the runtime decision features.", "method": "The authors compare their novel dynamic network with  traditional static pruning methods and other dynamic pruning approaches on CIFAR10 and ImageNet datasets under the similar computing budgets.", "outcome": "Novel dynamic network achieves higher prediction accuracy under the similar computing budgets on CIFAR10 and ImageNet datasets compared to traditional static pruning methods and other dynamic pruning approaches. \r\nThe proposed adversarial detection algorithm can significantly improve the state-of-the-art detection rate across multiple attacks.", "future_impact": "The proposed adversarial detection algorithm provides an opportunity to build an interpretable and robust model.", "venue": null, "year": null, "title": "Dynamic Network Pruning with Interpretable Layerwise Channel Selection"}
{"pid": "5a3da6ef-67b0-41bc-a994-fc5ff455a27b", "context": "Due to the pervasive spam reviews, customers can be misled to buy low-quality products, while decent stores can be defamed by malicious reviews.\r\nExisting methods do not adequately address this large subset of reviews.", "key_idea": "The authors propose addressing the issue of spam in singleton reviews via unusually correlated temporal patterns. And the authors propose a hierarchical algorithm to robustly detect the time windows where spam attacks are likely to have happened. ", "method": "The authors conduct the experiment to evaluate the ability of detecting singleton review attacks using unusually correlated temporal patterns and hierarchical algorithm.", "outcome": "Experimental results show that the proposed method is effective in detecting singleton review attacks.  ", "future_impact": "N/A", "venue": null, "year": null, "title": "Review spam detection via temporal pattern discovery"}
{"pid": "5a3da6ef-67b0-41bc-a994-fc5ff455a27b", "context": "In reality, a great portion (u003e 90% in the data we study) of the reviewers write only one review (singleton review).  However, existing methods did not examine this larger part of the reviews.\r\n\r\nAuthors observe that the normal reviewersu0027 arrival pattern is stable and uncorrelated to their rating pattern temporally. In contrast, spam attacks are usually bursty and either positively or negatively correlated to the rating", "key_idea": "Authors identify and construct multidimensional time series based on aggregate statistics, in order to depict and mine such correlations. In this way, the singleton review spam detection problem is mapped to a abnormally correlated pattern detection problem. Authors propose a hierarchical algorithm to robustly detect the time windows where such attacks are likely to have happened.", "method": "Authors setup benchmark to detect singleton review attacks.", "outcome": " Experimental results show that the proposed method is effective in detecting singleton review attacks. We discover that singleton review is a significant source of spam reviews and largely affects the ratings of online stores.", "future_impact": "N/A", "venue": null, "year": null, "title": "Review spam detection via temporal pattern discovery"}
{"pid": "5dccca98-2b58-47e3-9b8f-3b1888aa3976", "context": "The heterogeneity of current IT environments and the increasing demands from mobile users are major obstacles to achieve real-time data integration and processing", "key_idea": "The authors a new middleware paradigm, Space based computing, to meet all kinds of demands. ", "method": "The authors use new middleware paradigm to create real-time data warehouses.  ", "outcome": " Space based computing is a level of abstraction superior to conventional middleware solutions, including distributed transactions and the seamless integration of mobile devices using open standards, crossing the borders between heterogeneous platforms and systems. ", "future_impact": "N/A", "venue": null, "year": null, "title": "The zero-delay data warehouse: mobilizing heterogeneous database"}
{"pid": "5e1f387c-d883-4d1f-8397-e4a533a3387b", "context": "Hyperspectral imaging offers new perspectives for diverse applications, but the spectral diversity of information comes at the expense of various sources of degradation, and the lack of accurate ground-truth \"clean\" hyperspectral signals acquired on the spot makes restoration tasks challenging.", "key_idea": "The authors propose a hybrid approach based on sparse coding principles that retain the interpretability of classical techniques encoding domain knowledge with handcrafted image priors, while allowing to train model parameters end-to-end without massive amounts of data.", "method": "The authors evaluate their proposed method on various denoising benchmarks.", "outcome": "The authors show on various denoising benchmarks that the proposed method is computationally efficient and significantly outperforms the state of the art.", "future_impact": "N/A", "venue": null, "year": null, "title": "A Trainable Spectral-Spatial Sparse Coding Model for Hyperspectral Image Restoration."}
{"pid": "5e1f387c-d883-4d1f-8397-e4a533a3387b", "context": "Hyperspectral imaging offers new perspectives for diverse applications. Unfortunately, the spectral diversity of information comes at the expense of various sources of degradation, and the lack of accurate ground-truth \"clean\" hyperspectral signals acquired on the spot makes restoration tasks challenging. In particular, training deep neural networks for restoration is difficult, in contrast to traditional RGB imaging problems.", "key_idea": "Authors advocate instead for a hybrid approach based on sparse coding principles that retain the interpretability of classical techniques encoding domain knowledge with handcrafted image priors, while allowing to train model parameters end-to-end without massive amounts of data.", "method": "Authors conduct experiments on various denoising benchmarks.", "outcome": "Authors show that, on various denoising benchmarks the proposed method is computationally efficient and significantly outperforms the state of the art.", "future_impact": "N/A", "venue": null, "year": null, "title": "A Trainable Spectral-Spatial Sparse Coding Model for Hyperspectral Image Restoration."}
{"pid": "68f8d058-1403-4066-b3d3-a8a2836b35e1", "context": "Raster imagery features and imperfect vector training labels have registration uncertainty.\r\nThe problem is challenging due to the gap between the vector representation of class labels and the raster representation of image features and the need for training neural networks with uncertain label locations.", "key_idea": "The authors propose a novel learning framework that explicitly quantifies vector labels' registration uncertainty and a registration-uncertainty-aware loss function and design an iterative uncertainty reduction algorithm by re-estimating the posterior of true vector label locations distribution based on a Gaussian process.", "method": "The authors evaluate novel learning framework on real-world datasets in National Hydrography Dataset refinement ", "outcome": "Evaluations on real-world datasets in National Hydrography Dataset refinement show that the novel learning framework significantly outperforms several baselines in the registration uncertainty estimations performance and classification performance.", "future_impact": "N/A", "venue": null, "year": null, "title": "Quantifying and Reducing Registration Uncertainty of Spatial Vector Labels on Earth Imagery"}
{"pid": "68f8d058-1403-4066-b3d3-a8a2836b35e1", "context": "The problem of quantifying and reducing the registration uncertainty of training labels is important but challenging. Existing research on uncertain training labels often focuses on uncertainty in label class semantics or characterizes label registration uncertainty at the pixel level (not contiguous vectors).", "key_idea": "The authors propose a deep learning framework that can quantify and reduce the registration uncertainty of training labels as well as train neural network parameters simultaneously, specifically, a registration-uncertainty-aware loss function and an iterative uncertainty reduction algorithm by re-estimating the posterior of true vector label locations distribution based on a Gaussian process.", "method": "The authors evaluate the proposed method on real-world datasets in National Hydrography Dataset refinement and compare it with several baselines.", "outcome": "Evaluations on real-world datasets in National Hydrography Dataset refinement show that the proposed approach significantly outperforms several baselines in the registration uncertainty estimations performance and classification performance.", "future_impact": "N/A", "venue": null, "year": null, "title": "Quantifying and Reducing Registration Uncertainty of Spatial Vector Labels on Earth Imagery"}
{"pid": "69aacc53-6730-4db0-b420-9a45b96a642e", "context": "An important problem in geometric reasoning is to find the configuration of a collection of geometric bodies so as to satisfy a set of given constraints. ", "key_idea": "The authors introduce an approach solving geometric reasoning problem efficiently by symbolically reasoning about geometry using a degrees of freedom analysis. ", "method": "The authors use new method to show how these plan fragments can be automatically synthesized using first principles about geometric bodies, actions, and topology.", "outcome": "New method can efficiently solve geometric configuration problems, satisfying a new constraint while preserving existing constraints.", "future_impact": "N/A", "venue": null, "year": null, "title": "Planning from first principles for geometric constraint satisfaction"}
{"pid": "6de74297-fb80-448f-b7ae-41f8d9701044", "context": "Since there are two kinds of omnidirectional cameras often used in computer vision: central catadioptric cameras and fisheye cameras, previous literatures use different imaging models to describe them separately. ", "key_idea": "The authors propose a unified imaging model, which can cover some existing models for fisheye cameras and fit well for many actual fisheye cameras used in previous literatures.", "method": "The authors compare unified imaging model with other. existing methods for fisheye cameras in the literatures on the metric calibration from single fisheye image and evaluate unified imaging model on alibration from some central catadioptric and fisheye images.", "outcome": "While the existing methods for fisheye cameras in the literatures are all non-metric, unified imaging model only use projections of lines on the metric calibration from single fisheye image and experimental results of calibration from some central catadioptric and fisheye images confirm the validity and usefulness of our new unified model.", "future_impact": "N/A", "venue": null, "year": null, "title": "Can We Consider Central Catadioptric Cameras and Fisheye Cameras within a Unified Imaging Model"}
{"pid": "6de74297-fb80-448f-b7ae-41f8d9701044", "context": "There are two kinds of omnidirectional cameras often used in computer vision: central catadioptric cameras and fisheye cameras. Previous literatures use different imaging models to describe them separately.", "key_idea": "The authors present a unified imaging model, which can be considered as an extension of the unified imaging model for central catadioptric cameras proposed by Geyer and Daniilidis.", "method": "The authors evaluate their unified model by calibrating some central catadioptric and fisheye images.", "outcome": "Experimental results of calibration from some central catadioptric and fisheye images confirm the validity and usefulness of the new unified model.", "future_impact": "N/A", "venue": null, "year": null, "title": "Can We Consider Central Catadioptric Cameras and Fisheye Cameras within a Unified Imaging Model"}
{"pid": "6ecf725b-661e-4897-8169-22d71826d0e8", "context": "Different Open Information Extraction (OIE) tasks require different types of information, so the OIE field requires strong adaptability of OIE algorithms to meet different task requirements.", "key_idea": "The authors designs a new adaptable and efficient OIE system - OIE@OIA as a solution to the adaptability problem in existing OIE systems.", "method": "The authors conduct experiments to evaluate OIE@OIA system on three popular OIE tasks and compare it with other end-to-end OIE baselines.", "outcome": "On three popular OIE tasks, OIE@OIA achieves new SOTA performances,  showing the great adaptability. And compared to other end-to-end OIE baselines that need millions of samples for training, OIE@OIA needs much fewer training samples (12K), showing a significant advantage in terms of efficiency.", "future_impact": "N/A", "venue": null, "year": null, "title": "OIE@OIA: an Adaptable and Efficient Open Information Extraction Framework"}
{"pid": "6ecf725b-661e-4897-8169-22d71826d0e8", "context": "Different Open Information Extraction (OIE) tasks require different types of information, so the OIE field requires strong adaptability of OIE algorithms to meet different task requirements.", "key_idea": "The authors discuss the adaptability problem in existing OIE systems and design a new adaptable and efficient OIE system - OIE@OIA as a solution.", "method": "The authors use the proposed OIE@OIA system to accomplish three popular OIE tasks, and compare it to other end-to-end OIE baselines.", "outcome": "The experimental show that the proposed OIE@OIA achieves new SOTA performances on three popular OIE tasks, showing the great adaptability of OIE@OIA system. Furthermore, compared to other end-to-end OIE baselines that need millions of samples for training, OIE@OIA needs much fewer training samples (12K), showing a significant advantage in terms of efficiency.", "future_impact": "N/A", "venue": null, "year": null, "title": "OIE@OIA: an Adaptable and Efficient Open Information Extraction Framework"}
{"pid": "7b21425c-a2b7-4d19-b030-a8350b2a7a80", "context": "Conditional set generation learns a mapping from an input sequence of tokens to a set. Several NLP tasks, such as entity typing and dialogue emotion tagging, are instances of set generation. Seq2Seq models, a popular choice for set generation, treat a set as a sequence and do not fully leverage its key properties, namely order-invariance and cardinality.", "key_idea": "The authors propose a novel algorithm for effectively sampling informative orders over the combinatorial space of label orders, which is a model-independent data augmentation approach that endows any Seq2Seq model with the signals of order-invariance and cardinality.", "method": "The authors train several Seq2Seq models based their method and evaluate these models on four benchmark datasets.", "outcome": "Training a Seq2Seq model on this augmented data (without any additional annotations) gets an average relative improvement of 20% on four benchmark datasets across various models: BART, T5, and GPT-3.", "future_impact": "N/A", "venue": null, "year": null, "title": "Conditional set generation using Seq2seq models"}
{"pid": "7b21425c-a2b7-4d19-b030-a8350b2a7a80", "context": "Seq2Seq models, a popular choice for set generation, treat a set as a sequence and do not fully leverage its key properties, namely order-invariance and cardinality.", "key_idea": "The authors propose a novel algorithm for effectively sampling informative orders over the combinatorial space of label orders. This method is a model-independent data augmentation approach that endows any Seq2Seq model with the signals of order-invariance and cardinality. ", "method": "The authors train a Seq2Seq model on new augmented data (without any additional annotations) to evaluate performance across various models: BART, T5, and GPT-3.", "outcome": "Training a Seq2Seq model on augmented data (without any additional annotations) gets an average relative improvement of 20% on four benchmark datasets across various models: BART, T5, and GPT-3. ", "future_impact": "N/A", "venue": null, "year": null, "title": "Conditional set generation using Seq2seq models"}
{"pid": "802a5b78-a022-4d38-bfb3-f28eee4ef89a", "context": "It is still a challenge problem to sufficiently model the complicated syntactic and semantic compositions of the dense features in neural network based methods.", "key_idea": "The authors propose two heterogeneous gated recursive neural networks: tree structured gated recursive neural network (Tree-GRNN) and directed acyclic graph structured gated recursive neural network (DAG-GRNN) and integrate them to automatically learn the compositions of the dense features for transition-based dependency parsing.", "method": "The authors applied tree structured gated recursive neural network (Tree-GRNN) and directed acyclic graph structured gated recursive neural network (DAG-GRNN) on two prevalent benchmark datasets (PTB3 and CTB5) to check their effectiveness.", "outcome": "Experiments conducted on two benchmark datasets, PTB3 and CTB5, demonstrate the effectiveness of the proposed models, tree structured gated recursive neural network (Tree-GRNN) and directed acyclic graph structured gated recursive neural network (DAG-GRNN).", "future_impact": "N/A", "venue": null, "year": null, "title": "Transition-based Dependency Parsing Using Two Heterogeneous Gated Recursive Neural Networks"}
{"pid": "802a5b78-a022-4d38-bfb3-f28eee4ef89a", "context": "Recently, neural network based dependency parsing has attracted much interest, which can effectively alleviate the problems of data sparsity and feature engineering by using the dense features. However, it is still a challenge problem to sufficiently model the complicated syntactic and semantic compositions of the dense features in neural network based methods.", "key_idea": "The authors propose two heterogeneous gated recursive neural networks: tree structured gated recursive neural network (Tree-GRNN) and directed acyclic graph structured gated recursive neural network (DAG-GRNN), and the integration of both networks.", "method": "The authors evaluated their proposed networks on two prevalent benchmark datasets (PTB3 and CTB5).", "outcome": "Experiment results on two prevalent benchmark datasets (PTB3 and CTB5) show the effectiveness of our proposed model.", "future_impact": "N/A", "venue": null, "year": null, "title": "Transition-based Dependency Parsing Using Two Heterogeneous Gated Recursive Neural Networks"}
{"pid": "816707fd-9214-4435-ac40-b2655e55c9d0", "context": "Pretrained language models (PLMs) have achieved superhuman performance on many benchmarks, creating a need for harder tasks. ", "key_idea": "The authors introduce CoDA21 (Context Definition Alignment), a challenging benchmark that measures natural language understanding (NLU) capabilities of PLMs.", "method": "The authors use CoDA21 as benchmark to compare human and PLM's natural language understanding (NLU) capabilities.", "outcome": "Human has much better performance on natural language understanding(NLU) capabilities than Pretrained language models (PLM).\r\nCoDA21 measures an aspect of NLU that is not sufficiently covered in existing benchmarks.", "future_impact": "N/A", "venue": null, "year": null, "title": "CoDA21: Evaluating Language Understanding Capabilities of NLP Models With Context-Definition Alignment"}
{"pid": "816707fd-9214-4435-ac40-b2655e55c9d0", "context": "Pretrained language models (PLMs) have achieved superhuman performance on many benchmarks, creating a need for harder tasks.", "key_idea": "We introduce CoDA21 (Context Definition Alignment), a challenging benchmark that measures natural language understanding (NLU) capabilities of PLMs: Given a definition and a context each for k words, but not the words themselves, the task is to align the k definitions with the k contexts.", "method": "The author compares the performance of human and pretrained language models on the proposed benchmark.", "outcome": "There is a large gap between human and PLM performance, suggesting that CoDA21 measures an aspect of NLU that is not sufficiently covered in existing benchmarks.", "future_impact": "N/A", "venue": null, "year": null, "title": "CoDA21: Evaluating Language Understanding Capabilities of NLP Models With Context-Definition Alignment"}
{"pid": "8737b031-f77c-4f32-8a68-4be9b0c9ecf8", "context": "A network trained on synthetic data performs relatively poorly on real images. Although this can be addressed by domain adaptation, existing methods all require having access to real images during training.", "key_idea": "The authors introduce a drastically different way to handle synthetic images that does not require seeing any real images at training time.", "method": "The authors evaluate new method on Cityscapes and CamVid with models trained on synthetic data only.", "outcome": "Experiments results prove the effectiveness of new method on Cityscapes and CamVid with models trained on synthetic data only.", "future_impact": "N/A", "venue": null, "year": null, "title": "Effective Use of Synthetic Data for Urban Scene Semantic Segmentation"}
{"pid": "8737b031-f77c-4f32-8a68-4be9b0c9ecf8", "context": "Training a deep network to perform semantic segmentation requires large amounts of labeled data. The use of synthetic data to alleviate the manual effort of annotating will result in poorer performance, and existing methods to resolve this all require having access to real images during training.", "key_idea": "The authors introduce a way to handle synthetic images that does not require seeing any real images at training time.", "method": "The authors train their models using the proposed approach on Cityscapes and CamVid, using synthetic data only.", "outcome": "The experiments evidence the effectiveness of the proposed approach on Cityscapes and CamVid with models trained on synthetic data only.", "future_impact": "N/A", "venue": null, "year": null, "title": "Effective Use of Synthetic Data for Urban Scene Semantic Segmentation"}
{"pid": "8ae36735-e4ac-48da-bd2b-5538a6a00a73", "context": "Relational machine learning (RML) is an excellent framework for problems that require accurate probability estimates to determine the correct answer as it jointly models the user labels given their attributes and the relational structure. However, existing RML approaches have limitations that prevent their application in large scale domains.", "key_idea": "The authors propose a method, implementing a maximum entropy constraint on the inference step, can solve the limitations of Relational machine learning (RML).", "method": "The authors conduct experiments over a variety of baselines on seven real world datasets to evaluate new method.", "outcome": "Experiments prove new method's improvement over a variety of baselines on seven real world datasets, including large scale networks with over five million edges.", "future_impact": "N/A", "venue": null, "year": null, "title": "Overcoming Relational Learning Biases to Accurately Predict Preferences in Large Scale Networks"}
{"pid": "8ae36735-e4ac-48da-bd2b-5538a6a00a73", "context": "Relational machine learning (RML), combined with semi-supervised learning methods, is an excellent framework to provide better contents to uses based on the traits they posted on social networking sites. However, existing RML approaches have several limitations that prevent their application in large scale domains.", "key_idea": "The authors find the limitation of the collective inference methods of full semi-supervised RML and implement a maximum entropy constraint on the inference step to correct this.", "method": "The authors evaluate their proposed method on seven real world datasets, including large scale networks with over five million edges, and compare it to a variety of baselines.", "outcome": "The authors demonstrate their method's improvement over a variety of baselines on seven real world datasets, including large scale networks with over five million edges.", "future_impact": "N/A", "venue": null, "year": null, "title": "Overcoming Relational Learning Biases to Accurately Predict Preferences in Large Scale Networks"}
{"pid": "8aedb046-2f51-4229-bc19-ea6db98355cb", "context": " In order to get the ranks of websites, researchers used to describe the inter-connectivity among websites with a so-called HostGraph in which the nodes denote websites and the edges denote linkages between websites, and then adopted the random walk model in the HostGraph. However, the random walk over such a HostGraph is not reasonable because it is not in accordance with the browsing behavior of web surfers. Therefore, the derivate rank cannot represent the true probability of visiting the corresponding website.", "key_idea": "Authors mathematically prove that the probability of visiting a website by the random web surfer should be equal to the sum of the PageRank values of the pages inside that website. Authors also propose a novel method named AggregateRank, which can not only approximate the sum of PageRank accurately, but also have a lower computational complexity than PageRank. ", "method": "Authors discuss the propose methods in theory and experiments.", "outcome": "Both theoretical analysis and experimental evaluation show that AggregateRank is a better method for ranking websites than previous methods.", "future_impact": "N/A", "venue": null, "year": null, "title": "AggregateRank: bringing order to web sites"}
{"pid": "927df1bd-273a-4088-8c56-2e79cac37072", "context": "k-means remains one of the most popular data processing algorithms.  The recently proposed k-means++ initialization algorithm achieves a proper initialization, obtaining an initial set of centers that is provably close to the optimum solution. A major downside of the k-means++ is its inherent sequential nature, which limits its applicability to massive data: one must make k passes over the data to find a good initial set of centers.", "key_idea": "Authors show how to drastically reduce the number of passes needed to obtain, in parallel, a good initialization. \r\nAuthors prove that our proposed initialization algorithm k-means|| obtains a nearly optimal solution after a logarithmic number of passes, and then show that in practice a constant number of passes suffices.", "method": "Authors evaluate  k-means|| and k-means++ (as a baseline) on real-world large-scale data.", "outcome": "Experimental evaluation on real-world large-scale data demonstrates that k-means|| outperforms k-means++ in both sequential and parallel settings.", "future_impact": "N/A", "venue": null, "year": null, "title": "Scalable k-means++"}
{"pid": "927df1bd-273a-4088-8c56-2e79cac37072", "context": "K-means remains one of the most popular data processing algorithms. K-means++ initialization algorithm achieves this, obtaining an initial set of centers that is provably close to the optimum solution.  A major downside of the k-means++ is its inherent sequential nature, which limits its applicability to massive data.", "key_idea": "This paper introduces an initialization algorithm k-means||, designed to reduce the number of sequential passes required by k-means++ while maintaining nearly optimal initialization quality. ", "method": "The authors try to use experiment to prove that k-means|| algorithm obtains a nearly optimal solution after a logarithmic number of passes, and a constant number of passes suffices in practice.", "outcome": "Experimental evaluation on real-world large-scale data demonstrates that k-means|| outperforms k-means++ in both sequential and parallel settings.", "future_impact": "N/A", "venue": null, "year": null, "title": "Scalable k-means++"}
{"pid": "9748b061-590a-4602-9015-a68e879ffced", "context": "HCI researchers who are looking into using liquid-based materials (e.g., hydrogels) to create novel interfaces have the increasing requirements.", "key_idea": "The paper introduces a design strategy named xPrint, that allows HCI researchers to build and customize a smart material printing platform using off-the-shelf or easily machinable parts. \r\n", "method": "These modularized parts of xPrint can be easily and precisely reconfigured with off-the-shelf or easy-to-machine parts that can meet different processing requirements such as mechanical mixing, chemical reaction, light activation, and solution vaporization.  ", "outcome": "xPrint supports an open-source, highly customizable software design and simulation platform, which is applicable for simulating and facilitating smart material constructions.  And xPrint has a large range of printable materials from synthesized polymers to natural micro-organism-living cells with a printing resolution from 10\u03bcm up to 5mm (droplet size).", "future_impact": "N/A", "venue": null, "year": null, "title": "xPrint: A Modularized Liquid Printer for Smart Materials Deposition"}
{"pid": "9748b061-590a-4602-9015-a68e879ffced", "context": "There have been increasing requirements of HCI researchers who are looking into using liquid-based materials (e.g., hydrogels) to create novel interfaces.", "key_idea": "The author presents a design for HCI researchers to build and customize a liquid-based smart material printing platform. The design consists a hardware of a magnetic assembly-based modular design, modularized to be easily and precisely reconfigured with off-the-shelf or easy-to-machine parts to meet different processing requirements, and it also supports open-source, highly customizable software design and simulation platform.", "method": "The author compares the design with inkjet or pneumatic syringe-based printing systems on its range of printable material, and applies the design on three use cases to demonstrate the material variability and the customizability for users with different demands.", "outcome": "Compared to inkjet or pneumatic syringe-based printing systems, the proposed design has a large range of printable materials from synthesized polymers to natural micro-organism-living cells with a printing resolution from 10\u03bcm up to 5mm (droplet size). The design is also demonstrated for material variability and the customizability for users with different demands.", "future_impact": "The design strategy is beneficial for HCI researchers to build and customize a liquid-based smart material printing platform with off-the-shelf or easy-to-machine parts.", "venue": null, "year": null, "title": "xPrint: A Modularized Liquid Printer for Smart Materials Deposition"}
{"pid": "977698a6-56ef-4e57-94c5-b3a68a451a80", "context": "Emotion cause extraction aims to identify the reasons behind a certain emotion expressed in text, which is a much more difficult task compared to emotion classification. Recent research has advances in using deep memory networks for question answering (QA).", "key_idea": "The authors propose a new approach which considers emotion cause identification as a reading comprehension task in QA. Inspired by convolutional neural networks, they also propose a new mechanism to store relevant context in different memory slots to model context information.", "method": "The authors evaluate their proposed approach on a recently released emotion cause dataset.", "outcome": "The proposed approach can extract both word level sequence features and lexical features. Performance evaluation shows that the proposed method achieves the state-of-the-art performance on a recently released emotion cause dataset, outperforming a number of competitive baselines by at least 3.01% in F-measure.", "future_impact": "N/A", "venue": null, "year": null, "title": "A Question Answering Approach for Emotion Cause Extraction"}
{"pid": "977698a6-56ef-4e57-94c5-b3a68a451a80", "context": "Emotion cause extraction is more challenging than emotion classification and aims to identify the reasons behind a certain emotion expressed in text. The recent approach uses deep memory networks for question answering.", "key_idea": "The author proposes a mechanism to emotion cause extraction to store relevant context in different memory slots to model context information. The proposed approach can extract both word level sequence features and lexical features.", "method": "The author assesses the performance of the proposed approach against a recently released emotion cause database.", "outcome": "Performance evaluation shows that the author\u2019s method achieves the state-of-the-art performance on a recently released emotion cause dataset, outperforming a number of competitive baselines by at least 3.01% in F-measure.", "future_impact": "N/A", "venue": null, "year": null, "title": "A Question Answering Approach for Emotion Cause Extraction"}
{"pid": "9cd7e7e1-8893-4db6-8327-48f098187699", "context": "During recent years the online social networks (in particular Twitter) have become an important alternative information channel to traditional media during natural disasters, but the amount and diversity of messages poses the challenge of information overload to end users.", "key_idea": "Authors develop an automatic classifier of tweets to feed a mobile application that reduces the difficulties that citizens face to get relevant information during natural disasters. Authors present in detail the process to build a classifier that filters tweets relevant and non-relevant to an earthquake.", "method": "Using a dataset from the Chilean earthquake of 2010, authors build and validate a ground truth, and then they contribute by presenting in detail the effect of class imbalance and dimensionality reduction over 5 classifiers.", "outcome": "Authors show that the performance of classifiers is affected by these variables, providing important considerations at the moment of building these systems.", "future_impact": "N/A", "venue": null, "year": null, "title": "Identifying Relevant Messages in a Twitter-based Citizen Channel for Natural Disaster Situations"}
{"pid": "9cd7e7e1-8893-4db6-8327-48f098187699", "context": "During recent years the online social networks (in particular Twitter) have become an important alternative information channel to traditional media during natural disasters, but the amount and diversity of messages poses the challenge of information overload to end users.", "key_idea": "The authors present in detail the process to build a classifier that filters tweets relevant and non-relevant to an earthquake.", "method": "The authors build their models and validate a ground truth on a dataset from the Chilean earthquake of 2010.", "outcome": "The authors show how the performance of classifiers that filters tweets relevant and non-relevant to an earthquake is affected by class imbalance and dimensionality reduction.", "future_impact": "The research can provide important considerations at the moment of building classifiers that filters information about natural disasters.", "venue": null, "year": null, "title": "Identifying Relevant Messages in a Twitter-based Citizen Channel for Natural Disaster Situations"}
{"pid": "9f641e23-3886-4ac6-b65e-28db86ee48be", "context": "Nearly fifteen years ago, Google unveiled the generalized second price (GSP) auction, which is theoretically wrong. However, GSP succeeded spectacularly despite the fact that the Vickrey-Clarke-Groves (VCG) auction would have been the proper choice.", "key_idea": "The authors justify for GSP's success.", "method": "The authors make justification based on advertisers' preferences map to a model called value maximization.", "outcome": "The authors show that through the lens of value maximization, GSP becomes a powerful auction, sound in its principles and elegant in its simplicity.", "future_impact": "N/A", "venue": null, "year": null, "title": "GSP: The Cinderella of Mechanism Design"}
{"pid": "a10dafe9-6093-47f0-8429-7b62c46566ea", "context": "Enterprise mashup scenarios often involve feeds derived from data created primarily for eye consumption, such as email, news, calendars, blogs, and web feeds. These data sources can test the capabilities of current data mashup products, as the attributes needed to perform join, aggregation, and other operations are often buried within unstructured feed text. Information extraction technology is a key enabler in such scenarios, using annotators to convert unstructured text into structured information that can facilitate mashup operations.", "key_idea": "Authors present the integration of SystemT, an information extraction system from IBM Research, with IBMu0027s InfoSphere MashupHub.", "method": "Authors show demos on how to build domain-specific annotators with SystemTu0027s declarative rule language, AQL, and how to use these annotators to combine structured and unstructured information in an enterprise mashup.", "outcome": "Authors show that the proposed SystemT can be used to build domain-specific annotators with declarative rule language, AQL, and these annotators can combine structured and unstructured information in an enterprise mashup.", "future_impact": "N/A", "venue": null, "year": null, "title": "Enabling enterprise mashups over unstructured text feeds with InfoSphere MashupHub and SystemT"}
{"pid": "a1739057-ef00-4b01-9c26-4ab2b5d5708e", "context": "The use of data mining tools and techniques is increasing.", "key_idea": "The authors envision that a Knowledge Discovery and Data Mining System (KDDMS) will have to support and optimize for two scenarios. They further propose a systematic mechanism to optimize for these two cases, and a system architecture along with new algorithms for this purpose.", "method": "The authors implement and evaluate their system with both real and synthetic datasets.", "outcome": "The experimental results show that our techniques can achieve a speedup of up to a factor of 9, compared with the systems which do not support caching or optimize for multiple queries.", "future_impact": "N/A", "venue": null, "year": null, "title": "A framework to support multiple query optimization for complex mining tasks"}
{"pid": "a1739057-ef00-4b01-9c26-4ab2b5d5708e", "context": "With an increasing use of data mining tools and techniques, authors envision that a Knowledge Discovery and Data Mining System (KDDMS) will have to support and optimize for the following scenarios: 1) Sequence of Queries: A user may analyze one or more datasets by issuing a sequence of related complex mining queries, and 2) Multiple Simultaneous Queries: Several users may be analyzing a set of datasets concurrently, and may issue related complex queries.", "key_idea": "Authors presents a systematic mechanism to optimize for the above cases, targetting the class of mining queries involving frequent pattern mining on one or multiple datasets. Authors present a system architecture and propose new algorithms for this purpose. Authors show the design of a knowledgeable cache which can store the past query results from queries on multiple datasets. Authors present algorithms which enable the use of the results stored in such a cache to further optimize multiple queries.", "method": "Authors evaluate the system with both real and synthetic datasets", "outcome": "Experimental results show that our techniques can achieve a speedup of up to a factor of 9, compared with the systems which do not support caching or optimize for multiple queries.", "future_impact": "N/A", "venue": null, "year": null, "title": "A framework to support multiple query optimization for complex mining tasks"}
{"pid": "a722b600-3725-4738-a47b-435aebd63e13", "context": "Today's market for smart home devices has quickly evolved to include products that monitor, automate, and present themselves as human. ", "key_idea": "Authors develop a design philosophy for intelligent agents in the smart home that can act as an alternative to the ways that these devices are currently built.", "method": "Authors apply the design philosophy to the design of privacy empowering technologies.", "outcome": "Authors argue that this work marks the first steps from the devices of the present towards a more respectful future.", "future_impact": "N/A", "venue": null, "year": null, "title": "A Design Philosophy for Agents in the Smart Home"}
{"pid": "ad69e31c-2c7f-4db0-916c-3deccaab37fd", "context": "Go is an ancient board game that poses unique opportunities and challenges for AI and machine learning.", "key_idea": "The author proposes a system that is capable of automatically learning the propensity of local patterns from a library of games through a recursive neural network. The network integrates local information across the board and produces local outputs that represent local territory ownership probabilities, which then provides an effective strategic evaluation function on the expected area at the end of the game.", "method": "The author tests the system by training on 9 \u00d7 9 amateur game data and testing on 19 \u00d7 19 professional game data.", "outcome": "A system trained using only 9 \u00d7 9 amateur game data performs surprisingly well on a test set derived from 19 \u00d7 19 professional game data.", "future_impact": "N/A", "venue": null, "year": null, "title": "A Scalable Machine Learning Approach to Go"}
{"pid": "b0ad60d7-3a3a-42c2-acbc-fba55e708ba0", "context": " In natural language, the meaning of a lexeme often varies due to the specific surrounding context. Computational approaches to natural language processing can benefit from a reliable, long-range-context-dependent representation of the meaning of each lexeme that appears in a given sentence. ", "key_idea": "Authors develope a general new technique that produces a context-dependent u0027meaningu0027 representation for a lexeme in a specific surrounding context. \r\n The u0027meaningu0027 of a lexeme in a specific context is represented by a list of semantically replaceable elements the members of which are other lexemes from our experimental lexicon.", "method": "Authors perform experiments with a lexicon composed of individual English words and also with a lexicon of individual words and selected phrases.", "outcome": "The lists generated by the propose technique can be used to compare the u0027meaningu0027 of conceptual units (individual words or frequently-occurring phrases) in different contexts and also can serve as features for machine learning approaches to classify semantic roles and relationships.", "future_impact": "N/A", "venue": null, "year": null, "title": "A powerful and general approach to context exploitation in natural language processing"}
{"pid": "b0ad60d7-3a3a-42c2-acbc-fba55e708ba0", "context": "Computational approaches to natural language processing can benefit from a reliable, long-range-context-dependent representation of the meaning of each lexeme that appears in a given sentence. ", "key_idea": "The authors developed a general new technique that produces a context-dependent 'meaning' representation for a lexeme in a specific surrounding context. ", "method": "The authors have performed experiments with a lexicon composed of individual English words and also with a lexicon of individual words and selected phrases to evaluate the effectiveness new technique, that produces a context-dependent 'meaning' representation for a lexeme in a specific surrounding context. ", "outcome": "The resulting lists generated by new technique can be used to compare the 'meaning' of conceptual units (individual words or frequently-occurring phrases) in different contexts and also can serve as features for machine learning approaches to classify semantic roles and relationships.", "future_impact": "N/A", "venue": null, "year": null, "title": "A powerful and general approach to context exploitation in natural language processing"}
{"pid": "b14f2bc1-607f-4d8b-a731-b4afdf30a633", "context": "Current explanation datasets often employ synthetic data with simple reasoning structures. Therefore, it cannot express more complex reasoning processes, such as the rebuttal to a reasoning step and the degree of certainty of the evidence.", "key_idea": "The authors propose a comprehensive benchmark to investigate models' logical reasoning capabilities in complex real-life scenarios, as well as a logical reasoning explanation form.", "method": "The authors evaluate the current best models' performance on their proposed new explanation form.", "outcome": "The experimental results show that generating reasoning graphs remains a challenging task for current models, even with the help of giant pre-trained language models.", "future_impact": "N/A", "venue": null, "year": null, "title": "MetaLogic: Logical Reasoning Explanations with Fine-Grained Structure"}
{"pid": "b14f2bc1-607f-4d8b-a731-b4afdf30a633", "context": "Current explanation datasets often employ synthetic data with simple reasoning structures. Therefore, it cannot express more complex reasoning processes, such as the rebuttal to a reasoning step and the degree of certainty of the evidence.", "key_idea": "The authors propose a comprehensive logical reasoning explanation form including rebuttal conditions, logical formulae, and reasoning strength to investigate models' logical reasoning capabilities in complex real-life scenarios. ", "method": "The authors evaluate the current best models' performance on this new comprehensive logical reasoning explanation form.", "outcome": "The experimental results show that generating reasoning graphs remains a challenging task for current models, even with the help of giant pre-trained language models.", "future_impact": "N/A", "venue": null, "year": null, "title": "MetaLogic: Logical Reasoning Explanations with Fine-Grained Structure"}
{"pid": "b391a193-83e3-4f11-801f-1842647d626e", "context": "Capturing the dependencies among different facial action units (AU) is extremely important for the AU detection task, but the dependencies among AUs in real world data are often noisy and uncertain. Many studies have employed graph-based deep learning methods to exploit the dependencies among AUs.", "key_idea": "The authors propose an uncertain graph neural network (UGN) to learn the probabilistic mask that simultaneously captures both the individual dependencies among AUs and the uncertainties. They further propose an adaptive weighted loss function based on the epistemic uncertainties to adaptively vary the weights of the training samples during the training process to account for unbalanced data distributions among AUs.", "method": "They analyze how the uncertainties are related to the performance of AU detection and conduct extensive experiments on two benchmark datasets, i.e., BP4D and DISFA.", "outcome": "Extensive experiments, conducted on two benchmark datasets, i.e., BP4D and DISFA, demonstrate our method achieves the state-of-the-art performance.", "future_impact": "N/A", "venue": null, "year": null, "title": "Uncertain Graph Neural Networks For Facial Action Unit Detection"}
{"pid": "b391a193-83e3-4f11-801f-1842647d626e", "context": "Capturing the dependencies among different facial action units (AU) is extremely important for the AU detection task.\r\nMany studies have employed graph-based deep learning methods to exploit the dependencies among AUs. However, the dependencies among AUs in real world data are often noisy and the uncertainty is essential to be taken into consideration.", "key_idea": "Authors propose an uncertain graph neural network (UGN) to learn the probabilistic mask that simultaneously captures both the individual dependencies among AUs and the uncertainties. Further, authors propose an adaptive weighted loss function based on the epistemic uncertainties to adaptively vary the weights of the training samples during the training process to account for unbalanced data distributions among AUs. ", "method": "Authors conduct experiments on two benchmark datasets, i.e., BP4D and DISFA.", "outcome": "Extensive experiments, conducted on two benchmark datasets, i.e., BP4D and DISFA, demonstrate the proposed method achieves the state-of-the-art performance.", "future_impact": "N/A", "venue": null, "year": null, "title": "Uncertain Graph Neural Networks For Facial Action Unit Detection"}
{"pid": "b6b29c8a-7c8c-444c-b434-2ff9e166d9aa", "context": "Directly applying off-policy algorithms to offline RL usually fails due to the extrapolation error caused by the out-of-distribution (OOD) actions. Previous methods tackle such problem by penalizing the Q-values of OOD actions or constraining the trained policy to be close to the behavior policy, which typically prevent the generalization of value functions beyond the offline data and also lack precise characterization of OOD data.", "key_idea": "The authors propose Pessimistic Bootstrapping for offline RL (PBRL), a purely uncertainty-driven offline algorithm without explicit policy constraints, and further propose a novel OOD sampling method to tackle the extrapolating error.", "method": "The authors conduct extensive experiments to evaluate their proposed method on D4RL benchmark.", "outcome": "The authors show that their proposed OOD sampling and pessimistic bootstrapping yields provable uncertainty quantifier in linear MDPs. Extensive experiments on D4RL benchmark further show that the proposed PBRL has better performance compared to the state-of-the-art algorithms.", "future_impact": "N/A", "venue": null, "year": null, "title": "Pessimistic Bootstrapping for Uncertainty-Driven Offline Reinforcement Learning"}
{"pid": "b6b29c8a-7c8c-444c-b434-2ff9e166d9aa", "context": "Previous methods tackle problem that off-policy algorithms failures due to the extrapolation error caused by the out-of-distribution (OOD) actions by penalizing the Q-values of OOD actions or constraining the trained policy to be close to the behavior policy. And these methods typically prevent the generalization of value functions beyond the offline data and also lack precise characterization of OOD data. ", "key_idea": "The authors propose Pessimistic Bootstrapping for offline RL (PBRL), a purely uncertainty-driven offline algorithm without explicit policy constraints and further propose a novel OOD sampling method to tackle the extrapolating error.", "method": "The authors evaluate Pessimistic Bootstrapping for offline RL (PBRL) performance on D4RL benchmark.", "outcome": "The authors prove OOD sampling and pessimistic bootstrapping yields provable uncertainty quantifier in linear MDPs, thus providing the theoretical underpinning for PBRL. \r\nExtensive experiments on D4RL benchmark show that PBRL has better performance compared to the state-of-the-art algorithms.", "future_impact": "N/A", "venue": null, "year": null, "title": "Pessimistic Bootstrapping for Uncertainty-Driven Offline Reinforcement Learning"}
{"pid": "c268a190-6974-4190-8f48-db5dcbda8bc8", "context": "Data varies in multiple formats such as relational and (semi-)structured data. Traditional database handles a single type of data format and thus its ability to deal with different types of data formats is limited.", "key_idea": "The author proposes a multi-model processing framework for relational and semi-structured data, and designs a worst-case optimal join algorithm. The salient feature of the algorithm is that it can guarantee that the intermediate results are no larger than the worst-case join results.", "method": "The author assesses the proposed algorithm against the baseline join model on unning time and intermediate result size.", "outcome": "The multi-model algorithm significantly outperforms the baseline join methods in terms of running time and intermediate result size.", "future_impact": "N/A", "venue": null, "year": null, "title": "Worst Case Optimal Joins on Relational and XML data"}
{"pid": "c268a190-6974-4190-8f48-db5dcbda8bc8", "context": "In recent data management ecosystem, one of the greatest challenges is the data variety. Data varies in multiple formats such as relational and (semi-)structured data. Traditional database handles a single type of data format and thus its ability to deal with different types of data formats is limited.", "key_idea": "The authors propose a multi-model processing framework for relational and semi-structured data (i.e. XML), and design a worst-case optimal join algorithm.", "method": "The authors compare their algorithm with baseline join methods", "outcome": "Preliminary results show that the proposed multi-model algorithm significantly outperforms the baseline join methods in terms of running time and intermediate result size.", "future_impact": "N/A", "venue": null, "year": null, "title": "Worst Case Optimal Joins on Relational and XML data"}
{"pid": "c37e0f9f-1654-4f1f-b812-bf6f67c0c840", "context": "Recent research on neural networks has shown the susceptibility of deep networks to adversarial attacks by adding small perturbations to the inputs which can fool a deep network into misclassifying them. Current developed defenses against such adversarial attacks are using robust models that are immune to such adversaries and detecting such adversarial inputs.", "key_idea": "The author present a statistical approach for adversarial detection in image classification, which is based on constructing a per-class feature distribution and detecting adversaries based on comparison of features of a test image with the feature distribution of its class. The author uses various statistical distances such as ED and MMD for adversarial detection and analyzes the performance of each metric.", "method": "The author uses MNIST and CIFAR-10 datasets, and various attack methods, sample sizes and degrees of adversarial perturbation to test the effectiveness of the proposal.", "outcome": "The proposed method achieves good adversarial detection performance on MNIST and CIFAR-10 datasets irrespective of the attack method, sample size and the degree of adversarial perturbation.", "future_impact": "N/A", "venue": null, "year": null, "title": "Attack Agnostic Statistical Method for Adversarial Detection"}
{"pid": "c37e0f9f-1654-4f1f-b812-bf6f67c0c840", "context": "Susceptibility of deep networks to adversarial attacks - a technique of adding small perturbations to the inputs which can fool a deep network into misclassifying them.", "key_idea": "The authors present a novel statistical approach, based on constructing a per-class feature distribution and detecting adversaries based on comparison of features of a test image with the feature distribution of its class, for adversarial detection in image classification. ", "method": "The authors make use of various statistical distances such as ED (Energy Distance), MMD (Maximum Mean Discrepancy) for adversarial detection, and analyze the performance of each metric to evaluate new statistical approach's  adversarial detection performance on MNIST and CIFAR-10 datasets.", "outcome": "New statistical approach achieves good adversarial detection performance on MNIST and CIFAR-10 datasets irrespective of the attack method, sample size and the degree of adversarial perturbation.", "future_impact": "N/A", "venue": null, "year": null, "title": "Attack Agnostic Statistical Method for Adversarial Detection"}
{"pid": "c5c22c6f-e9e9-4b0a-ac57-d3baa100033b", "context": " Instances of structured stochastic convex optimization problems with a large number of linear constraints naturally arise from SDP-relaxations of combinatorial problems, which involve a number of constraints that is polynomial in the problem dimension.", "key_idea": "Authors propose two novel conditional gradient-based methods for solving structured stochastic convex optimization problems with a large number of linear constraints. The most important feature of proposed framework is that only a subset of the constraints is processed at each iteration, thus gaining a computational advantage over prior works that require full passes. ", "method": "Authors conduct rigorous convergence analysis theoretically. They also provide preliminary numerical experiments.", "outcome": "Proposed algorithms rely on variance reduction and smoothing used in conjunction with conditional gradient steps, and are accompanied by rigorous convergence guarantees. Preliminary numerical experiments are provided for illustrating the practical performance of the methods.", "future_impact": "N/A", "venue": null, "year": null, "title": "Conditional gradient methods for stochastically constrained convex minimization"}
{"pid": "c676aecf-7468-4258-bb41-22bc1811bc3a", "context": "Most of the existing community search models only focus on the internal cohesiveness of a community, and a high-quality community often has dense connections inside communities and sparse connections to the nodes outside the community. Modularity in community search is not practiced and challenging.", "key_idea": "The author designs a first-ever graph modularity on community search and tries to efficiently address density modularity community search by using algorithms that run in log-linear time to the graph size.", "method": "The author tests the proposed algorithms by conducting studies in real-world and synthetic networks.", "outcome": "The author\u2019s algorithm achieves up to 8.5 times higher accuracy in terms of NMI than baseline algorithms.", "future_impact": "N/A", "venue": null, "year": null, "title": "DMCS : Density Modularity based Community Search"}
{"pid": "c676aecf-7468-4258-bb41-22bc1811bc3a", "context": "Most of the existing community search models only focus on the internal cohesiveness of a community. \r\nWhile modularity has been popularly used in community detection (without query nodes), it has not been adopted for community search and its application in community search (related to query nodes) brings in new challenges. ", "key_idea": "The authors design a new graph modularity function named Density Modularity, and the community search based on the density modularity, termed as DMCS, is to find a community in a social network that contains all the query nodes and has high density-modularity.  And the authors present new algorithms that run in log-linear time to the graph size to address DMCS.", "method": "The authors conduct extensive experimental studies using new algorithm to address the community search based on the density modularity(DMCS) problem in real-world and synthetic networks in terms of NMI.", "outcome": " New algorithm solving the community search based on the density modularity(DMCS) problem achieves up to 8.5 times higher accuracy in terms of NMI than baseline algorithms.", "future_impact": "N/A", "venue": null, "year": null, "title": "DMCS : Density Modularity based Community Search"}
{"pid": "ca53b2c4-2912-4515-aae6-938c3f268a60", "context": "The problem of detecting epidemic tendency is important.", "key_idea": "Authors propose an algorithm based on click-through information to select epidemic related queries/terms. Authors adopt linear regression to model epidemic occurrences and frequencies of epidemic related terms (ERTs) in search logs.", "method": "Authors design experiments to find epidemic related terms (ERTs).", "outcome": "Experimental results show the proposed algorithm is effective in finding ERTs which obtain a high correlation value with epidemic occurrences. Authors also find the proposed method performs better when combining different ERTs than using single ERT.", "future_impact": "N/A", "venue": null, "year": null, "title": "Detecting epidemic tendency by mining search logs"}
{"pid": "ccae9338-7379-4af1-8fea-8945ba429c5c", "context": "Object tracking is still a critical and challenging problem with many applications in computer vision. For this challenge, more and more researchers pay attention to applying deep learning to get powerful feature for better tracking accuracy.", "key_idea": "The authors propose a novel triplet loss to extract expressive deep feature for object tracking by adding it into Siamese network framework instead of pairwise loss for training.", "method": "The authors propose a theoretical analysis by combining comparison of gradients and back-propagation, to prove the effectiveness of their proposed method. They apply the proposed triplet loss for three real-time trackers based on Siamese network on several popular tracking benchmarks.", "outcome": "The experimental results on several popular tracking benchmarks show that the proposed methods operate at almost the same frame-rate with baseline trackers and achieve superior tracking performance than them, as well as the comparable accuracy with recent state-of-the-art real-time trackers.", "future_impact": "N/A", "venue": null, "year": null, "title": "Triplet Loss in Siamese Network for Object Tracking"}
{"pid": "ccae9338-7379-4af1-8fea-8945ba429c5c", "context": "Object tracking is still a critical and challenging problem with many applications in computer vision. For this challenge, more and more researchers pay attention to applying deep learning to get powerful feature for better tracking accuracy", "key_idea": "Authors propose  a novel triplet loss is proposed to extract expressive deep feature for object tracking by adding it into Siamese network framework instead of pairwise loss for training. Without adding any inputs, the proposed approach is able to utilize more elements for training to achieve more powerful feature via the combination of original samples. Furthermore, authors propose a theoretical analysis by combining comparison of gradients and back-propagation, to prove the effectiveness of our method.", "method": "Authors conduct experiments on several popular tracking benchmarks.", "outcome": "Results on several popular tracking benchmarks show the proposed variants operate at almost the same frame-rate with baseline trackers and achieve superior tracking performance than them, as well as the comparable accuracy with recent state-of-the-art real-time trackers.", "future_impact": "N/A", "venue": null, "year": null, "title": "Triplet Loss in Siamese Network for Object Tracking"}
{"pid": "ce74316d-c5dc-47f1-b0c4-0591bc3fb4b6", "context": "Several methods have been proposed to evaluate queries over a native XML DBMS and these methods  broadly consist of graph traversal approaches, optimized with auxiliary structures known as structure indexes; and approaches based on information-retrieval style inverted lists. ", "key_idea": "The authors propose a strategy that combines the two forms of auxiliary indexes, and a query evaluation algorithm for branching path expressions based on this strategy.", "method": "The authors perform experiments over the Niagara XML DBMS to evaluate benefits of new strategy.", "outcome": "Experiments over the Niagara XML DBMS show the benefit of integrating the two forms of indexes. Integrating the techniques that combines the two forms of auxiliary indexes with the Threshold Algorithm proposed by Fagin et al., instance optimal algorithms to push down top k computation has been obtained.", "future_impact": "N/A", "venue": null, "year": null, "title": "On the integration of structure indexes and inverted lists"}
{"pid": "ce74316d-c5dc-47f1-b0c4-0591bc3fb4b6", "context": "Several methods have been proposed to evaluate queries over a native XML DBMS, where the queries specify both path and keyword constraints. These broadly consist of graph traversal approaches, optimized with auxiliary structures known as structure indexes; and approaches based on information-retrieval style inverted lists.", "key_idea": "The authors propose a strategy that combines the two forms of auxiliary indexes, and a query evaluation algorithm for branching path expressions based on this strategy. They further integrate these techniques with the Threshold Algorithm proposed by Fagin et al., and obtain instance optimal algorithms to push down top k computation.", "method": "The authors conduct experiments over the Niagara XML DBMS", "outcome": "The experiments over the Niagara XML DBMS show the benefit of adapting their proposed stratgey.", "future_impact": "N/A", "venue": null, "year": null, "title": "On the integration of structure indexes and inverted lists"}
{"pid": "db900c02-9a35-4a83-aa19-15b763259100", "context": "Quantum computing is a powerful computational paradigm with applications in several fields and deep learning is essential for applications in signal processing and image recognition. Quantum deep learning, however, remains a challenging problem, as it is difficult to implement non linearities with quantum unitaries.", "key_idea": "The authors propose a quantum algorithm for evaluating and training deep convolutional neural networks with potential speedups over classical CNNs for both the forward and backward passes.", "method": "The authors evaluate their proposed method using the classification of the MNIST dataset.", "outcome": "The authors present numerical simulations for the classification of the MNIST dataset to provide practical evidence for the efficiency of the QCNN.", "future_impact": "N/A", "venue": null, "year": null, "title": "Quantum Algorithms for Deep Convolutional Neural Networks"}
{"pid": "db900c02-9a35-4a83-aa19-15b763259100", "context": "Quantum deep learning remains a challenging problem, as it is difficult to implement non linearities with quantum unitaries.", "key_idea": "The author proposes a quantum algorithm for evaluating and training deep convolutional neural networks with potential speedups over classical CNNs for both the forward and backward passes. The quantum CNN (QCNN) reproduces completely the outputs of the classical CNN and allows for non linearities and pooling operations and it is in particular interesting for deep networks and could allow new frontiers in the image recognition domain.", "method": "The author presents numerical simulations for the classification of the MNIST dataset.", "outcome": "The numerical simulations for the classification of the MNIST dataset provide practical evidence for the efficiency of the QCNN.", "future_impact": "N/A", "venue": null, "year": null, "title": "Quantum Algorithms for Deep Convolutional Neural Networks"}
{"pid": "dca09f6f-b63a-42a1-9eb5-fbfa45bc6389", "context": "Activity logs collected from wearable devices (e.g. Apple Watch, Fitbit, etc.) are a promising source of data to facilitate a wide range of applications such as personalized exercise scheduling, workout recommendation, and heart rate anomaly detection. However, such data are heterogeneous, noisy, diverse in scale and resolution, and have complex interdependencies, making them challenging to model.", "key_idea": "Authors develop context-aware sequential models to capture the personalized and temporal patterns of fitness data. Specifically, they propose FitRec - an LSTM-based model that captures two levels of context information: context within a specific activity, and context across a user's activity history.", "method": "Authors  evaluate our model on a novel dataset containing over 250 thousand workout records coupled with hundreds of millions of parallel sensor measurements (e.g. heart rate, GPS) and metadata. ", "outcome": "Authors  demonstrate that the model is able to learn contextual, personalized, and activity-specific dynamics of users' heart rate profiles during exercise. \r\nAuthors also evaluate the proposed model against baselines on several personalized recommendation tasks, showing the promise of using wearable data for activity modeling and recommendation.", "future_impact": "N/A", "venue": null, "year": null, "title": "Modeling Heart Rate and Activity Data for Personalized Fitness Recommendation"}
{"pid": "dca09f6f-b63a-42a1-9eb5-fbfa45bc6389", "context": "Since data collected from wearable devices are heterogeneous, noisy, diverse in scale and resolution, and have complex interdependencies, it's challenging to model these data.", "key_idea": "The authors propose FitRec, an LSTM-based model, which is a context-aware sequential models to capture the personalized and temporal patterns of fitness data.", "method": "The authors evaluate FitRec model on a novel dataset containing over 250 thousand workout records coupled with hundreds of millions of parallel sensor measurements (e.g. heart rate, GPS) and metadata. And the authors compare FitRec model against baselines on several personalized recommendation tasks.", "outcome": "FitRec model is able to learn contextual, personalized, and activity-specific dynamics of users' heart rate profiles during exercise. FitRec model have better performance on several personalized recommendation task than baselines.", "future_impact": "FitRec model provides better promise of using wearable data for activity modeling and recommendation.", "venue": null, "year": null, "title": "Modeling Heart Rate and Activity Data for Personalized Fitness Recommendation"}
{"pid": "dd282632-ee41-45da-add8-d68d89c57e2d", "context": "Classification activation map (CAM) is a crucial mechanism for weakly supervised object localization (WSOL). However, CAM directly uses the classifier trained on image-level features to locate objects, making it prefers to discern global discriminative factors rather than regional object cues, so only the discriminative locations are activated when feeding pixel-level features into this classifier.", "key_idea": "The authors elaborate a plug-and-play mechanism called BagCAMs to better project a well-trained classifier for the localization task without refining or re-training the baseline structure.", "method": "The authors evaluate BagCAMs on three WSOL benchmarks and compare it to baseline WSOL methods.", "outcome": "Experiments indicate that adopting the proposed BagCAMs can improve the performance of baseline WSOL methods to a great extent and obtains state-of-the-art performance on three WSOL benchmarks.", "future_impact": "N/A", "venue": null, "year": null, "title": "Bagging Regional Classification Activation Maps for Weakly Supervised Object Localization."}
{"pid": "dd282632-ee41-45da-add8-d68d89c57e2d", "context": "Classification activation map (CAM), utilizing the classification structure to generate pixel-wise localization maps, is a crucial mechanism for weakly supervised object localization (WSOL). However, CAM directly uses the classifier trained on image-level features to locate objects, making it prefers to discern global discriminative factors rather than regional object cues. Thus only the discriminative locations are activated when feeding pixel-level features into this classifier. ", "key_idea": "Authors propose a plug-and-play mechanism called BagCAMs to better project a well-trained classifier for the localization task without refining or re-training the baseline structure. BagCAMs adopts a proposed regional localizer generation (RLG) strategy to define a set of regional localizers and then derive them from a well-trained classifier. These regional localizers can be viewed as the base learner that only discerns region-wise object factors for localization tasks, and their results can be effectively weighted by our BagCAMs to form the final localization map. ", "method": "Authors experiment on three eakly supervised object localization (WSOL) benchmarks.", "outcome": "Authors show that adopting our proposed BagCAMs can improve the performance of baseline WSOL methods to a great extent and obtains state-of-the-art performance on three WSOL benchmarks. ", "future_impact": "N/A", "venue": null, "year": null, "title": "Bagging Regional Classification Activation Maps for Weakly Supervised Object Localization."}
{"pid": "ddf8f49c-342a-4cd0-8b3b-b588af08ed0d", "context": "Soboroff, Nicholas and Cahan proposed a method for evaluating the performance of retrieval systems without relevance judgments and demonstrated that the system evaluations produced by their methodology are correlated with actual evaluations using relevance judgments in the TREC competition.", "key_idea": "The authors propose an explanation for phenomenon, the system evaluations are correlated with actual evaluations using relevance judgments in the TREC competition.", "method": "The authors devise a simple measure for quantifying the similarity of retrieval systems by assessing the similarity of their retrieved results and they use this measure to assess the average similarity of a system to the other systems in the collection. ", "outcome": "The authors prove that evaluating retrieval systems according to average similarity yields results  are quite similar to the methodology proposed by Soboroff et~al and these two techniques are in fact highly correlated. ", "future_impact": "N/A", "venue": null, "year": null, "title": "On the effectiveness of evaluating retrieval systems in the absence of relevance judgments"}
{"pid": "ddf8f49c-342a-4cd0-8b3b-b588af08ed0d", "context": "Soboroff, Nicholas and Cahan recently proposed a method for evaluating the performance of retrieval systems without relevance judgments. They demonstrated that the system evaluations produced by their methodology are correlated with actual evaluations using relevance judgments in the TREC competition.", "key_idea": "The authors propose an explanation for the phenomenon that the system evaluations produced by the methodology introduced by Soboroff et al. are correlated with actual evaluations using relevance judgments in the TREC competition.", "method": "The authors devise a simple measure for quantifying the similarity of retrieval systems by assessing the similarity of their retrieved results. Then, they compare the measured similarity and compare it the the results yielded by the methodology proposed by Soboroff et al.", "outcome": "The authors demonstrate that evaluating retrieval systems according to average similarity yields results quite similar to the methodology proposed by Soboroff et al., and they further demonstrate that these two techniques are in fact highly correlated.", "future_impact": "N/A", "venue": null, "year": null, "title": "On the effectiveness of evaluating retrieval systems in the absence of relevance judgments"}
{"pid": "ded9a095-d94d-4ccd-8825-283ec4bb7093", "context": "There has been increasing interest in the adoption of UX within corporate environments, and what competencies translate into effective UX design.", "key_idea": "The authors address the space between pedagogy and UX practice through the lens of competence, with the goal of understanding how students are initiated into the practice community, how their perception of competence shifts over time, and what factors influence this shift.", "method": "The authors collect data from surveys and interviews. Students and early professionals were asked to assess their level of competence and factors that influenced competence.", "outcome": "A co-construction of identity between the designer and their environment is proposed, with a variety of factors relating to tool and representational knowledge, complexity, and corporate culture influencing perceptions of competence in UX over time.", "future_impact": "The authors address opportunities for future research, particularly in building an understanding of competency in UX based on this preliminary framing of early UX practice.", "venue": null, "year": null, "title": "Evolution of design competence in UX practice"}
{"pid": "e10b883a-ded6-4b4e-9934-6daba2d2f2b2", "context": "Designing efficient and effective solutions for large scale similarity search is an important research problem, and one popular strategy is to represent data examples as compact binary codes through semantic hashing. Many existing semantic hashing methods generate binary codes for documents by modeling document relationships based on similarity in a keyword feature space, which has two major limitations.", "key_idea": "The authors propose a novel hashing approach, Semantic Hashing using Tags and Topic Modeling (SHTTM), to incorporate both the tag information and the similarity information from probabilistic topic modeling.", "method": "The authors evaluate the proposed SHTTM on four different datasets and compare it with several other state-of-the-art semantic hashing techniques.", "outcome": "An extensive set of empirical studies on four different datasets has been conducted to demonstrate the advantages of the proposed SHTTM approach against several other state-of-the-art semantic hashing techniques. Furthermore, experimental results indicate that the modeling of tag information and utilizing topic modeling are beneficial for improving the effectiveness of hashing separately, while the combination of these two techniques in the unified framework obtains even better results.", "future_impact": "N/A", "venue": null, "year": null, "title": "Semantic hashing using tags and topic modeling"}
{"pid": "e10b883a-ded6-4b4e-9934-6daba2d2f2b2", "context": "There are two major limitations in existing semantic hashing methods: (1) Tag information is often associated with documents in many real world applications, but has not been fully exploited yet; (2) The similarity in keyword feature space does not fully reflect semantic relationships that go beyond keyword matching.", "key_idea": "The authors proposes a novel hashing approach, Semantic Hashing using Tags and Topic Modeling (SHTTM), to incorporate both the tag information and the similarity information from probabilistic topic modeling. ", "method": "The authors conduct an extensive set of empirical studies on four different datasets to evaluate the proposed SHTTM approach against several other state-of-the-art semantic hashing techniques.", "outcome": "Experimental results indicate that the modeling of tag information and utilizing topic modeling are beneficial for improving the effectiveness of hashing separately, while the combination of these two techniques in the unified framework obtains even better results.", "future_impact": "N/A", "venue": null, "year": null, "title": "Semantic hashing using tags and topic modeling"}
{"pid": "e58b9947-7a3a-414d-a0e8-d6cf02ed7127", "context": "With recent advances in radio-frequency identification (RFID), wireless sensor networks, and Web-based services, physical things are becoming an integral part of the emerging ubiquitous Web.", "key_idea": "Authors propose a unified probabilistic based framework by fusing information across relationships between users (i.e., social network) and things (i.e., things correlations) to make more accurate recommendations. The proposed approach not only inherits the advantages of the matrix factorization, but also exploits the merits of social relationships and thing-thing correlations", "method": "Authors design experiments on an Internet of Things platform.", "outcome": "Authors validate their approach based on an Internet of Things platform and the experimental results demonstrate its feasibility and effectiveness.", "future_impact": "N/A", "venue": null, "year": null, "title": "Exploring recommendations in internet of things"}
{"pid": "e58b9947-7a3a-414d-a0e8-d6cf02ed7127", "context": "With recent advances in radio-frequency identification (RFID), wireless sensor networks, and Web-based services, physical things are becoming an integral part of the emerging ubiquitous Web.", "key_idea": "The authors propose a unified probabilistic based framework by fusing information across relationships between users (i.e., users' social network) and things (i.e., things correlations) to make more accurate recommendations.", "method": "The authors validate their approach based on an Internet of Things platform.", "outcome": "The proposed approach not only inherits the advantages of the matrix factorization, but also exploits the merits of social relationships and thing-thing correlations. The experimental results demonstrate its feasibility and effectiveness.", "future_impact": "N/A", "venue": null, "year": null, "title": "Exploring recommendations in internet of things"}
{"pid": "eb15ebe7-aa58-4a98-8f9e-939967c6359f", "context": "Many papers try to address the synchronization problem on multi-graphs, that are graphs with more than one edge connecting the same pair of nodes.  The baseline solution reduces multi-graphs to simple ones by averaging their multi-edges, however this approach falls short.", "key_idea": "The author present a synchronization algorithm, named MultiSynch, for multi-graphs that is based on a principled constrained eigenvalue optimization.", "method": "The authors apply MultiSynch algorithm on any linear group and multi-graphs synthetic problems and real problems.", "outcome": "The experiment proves that MultiSynch is a general solution that can cope with any linear group and this  algorithm may be profitably usable both on synthetic and real problems.", "future_impact": "N/A", "venue": null, "year": null, "title": "Synchronization of Group-labelled Multi-graphs."}
{"pid": "eb15ebe7-aa58-4a98-8f9e-939967c6359f", "context": "Synchronization refers to the problem of inferring the unknown values attached to vertices of a graph where edges are labelled with the ratio of the incident vertices, and labels belong to a group. ", "key_idea": "Authors show that baseline solution reduces multi-graphs to simple ones by averaging their multi-edges, however this approach falls short because: i) averaging is well defined only for some groups and ii) the resulting estimator is less precise and accurate.\r\nAuthors present MultiSynch, a synchronization algorithm for multi-graphs that is based on a principled constrained eigenvalue optimization.\r\n", "method": "Authors conduct experiments on synthetic and real problems.", "outcome": "Authors argue that MultiSynch is a general solution that can cope with any linear group and is show to be profitably usable both on synthetic and real problems.", "future_impact": "N/A", "venue": null, "year": null, "title": "Synchronization of Group-labelled Multi-graphs."}
{"pid": "f23bdd28-b2d6-4a42-a56c-c9774f6451b5", "context": "Tracking for hypersonic vehicles in near space is becoming a new task and hotspot.", "key_idea": "The authors introduce a learning tracking algorithm for hypersonic targets, especially for the sliding jump maneuver.", "method": "The authors compare the proposed algorithm with the single accurate model algorithm and general IMM algorithms with fixed sampling rate on simulation experiments.", "outcome": "Through simulation experiments it is proved that the algorithm in this paper can improve the tracking accuracy effectively.", "future_impact": "N/A", "venue": null, "year": null, "title": "Learning Algorithm for Tracking Hypersonic Targets in Near Space"}
{"pid": "f23bdd28-b2d6-4a42-a56c-c9774f6451b5", "context": "Tracking hypersonic vehicles in near space such as X-51A, HTV-2 is becoming a new task and hotspot.", "key_idea": "The authors introduce a learning tracking algorithm for hypersonic targets, especially for the sliding jump maneuver. ", "method": "The authors conduct simulation experiments and compare new algorithm with the single accurate model algorithm and general IMM algorithms with fixed sampling rate.", "outcome": "Simulation experiments prove that the algorithm in this paper can improve the tracking accuracy effectively.\r\n", "future_impact": "N/A", "venue": null, "year": null, "title": "Learning Algorithm for Tracking Hypersonic Targets in Near Space"}
{"pid": "f2c9f8c3-f9d1-4cae-b7ae-a919ada1daaf", "context": "Transferring attacks to fully unseen networks is challenging. ", "key_idea": "The authors introduce the concept of targeted mismatch attack for deep learning based retrieval systems to generate an adversarial image to conceal the query image and try to design various loss functions for the adversarial image construction.", "method": "The authors evaluate the attacks on standard retrieval benchmarks and compare the results retrieved with the original and adversarial image.\r\n", "outcome": "After designing various loss functions for the adversarial image construction, attacks to partially unknown systems are successful.", "future_impact": "N/A", "venue": null, "year": null, "title": "Targeted Mismatch Adversarial Attack: Query With a Flower to Retrieve the Tower"}
{"pid": "f32d6bc3-d75e-4e84-8bfa-3c83578281dc", "context": "Transaction log analysis represents a powerful methodology which allows examination of both user commands and system responses when conducting an online information search.", "key_idea": "The authors propose a way that obtain machine-readable transaction log tapes from online catalogs and subsequently analyze using stochastic pattern developments within parsed user sessions, mathematical models utilizing Markov chain analysis and the development of state transition probability matrices.", "method": "The authors apply this way that obtain machine-readable transaction log tapes from online catalogs on several online public catalogs.", "outcome": "The probability of proceeding from one user or system state to another state has been proved.\r\nUsing this methodology, patron use and system response patterns from several online public catalogs can be obtained by transaction log tapes.", "future_impact": "N/A", "venue": null, "year": null, "title": "Monitoring and evaluation of information systems via transaction log analysis"}
{"pid": "f32e53d5-c7f4-407e-a5cb-26fef230b5fd", "context": "Matrix factorization has been widely adopted for recommendation by learning latent embeddings of users and items from observed user-item interaction data. Previous methods usually wrongly assume the learned embeddings are static or homogeneously evolving with the same diffusion rate, while users' preferences and item attributes heterogeneously drift over time.\r\n", "key_idea": "The author proposes a novel dynamic matrix factorization model that learns heterogeneous user and item embeddings that are drifting with inconsistent diffusion rates by extending logistic matrix factorization to model the probability a user would like to interact with an item at a given timestamp, and a diffusion process to connect latent embeddings over time. An efficient Bayesian inference algorithm has also been proposed to make the model scalable on large datasets.", "method": "The author compares the effectiveness of the proposed method with the state-of-the-art methods on extensive experiments on real datasets.", "outcome": "The effectiveness of the proposed method has been demonstrated by extensive experiments on real datasets, compared with the state-of-the-art methods.", "future_impact": "N/A", "venue": null, "year": null, "title": "Dynamic Bayesian Logistic Matrix Factorization for Recommendation with Implicit Feedback"}
{"pid": "f32e53d5-c7f4-407e-a5cb-26fef230b5fd", "context": "Since users preferences and item attributes heterogeneously drift over time, previous methods, which usually assume the learned embeddings are static or homogeneously evolving with the same diffusion rate, is not valid in most scenarios.", "key_idea": "The authors proposed a novel dynamic matrix factorization model, named Dynamic Bayesian Logistic Matrix Factorization (DBLMF), which aims to learn heterogeneous user and item embeddings that are drifting with inconsistent diffusion rates. And the authors proposed an efficient Bayesian inference algorithm.", "method": "The authors conduct extensive experiments on real datasets to evaluate effectiveness of Dynamic Bayesian Logistic Matrix Factorization (DBLMF) and other state-of-the-art methods.", "outcome": "With an efficient Bayesian inference algorithm, Dynamic Bayesian Logistic Matrix Factorization (DBLMF) method is scalable on large dataset. Compared with other state-of-the-art methods, DBLMF is more effective on real datasets.", "future_impact": "N/A", "venue": null, "year": null, "title": "Dynamic Bayesian Logistic Matrix Factorization for Recommendation with Implicit Feedback"}
{"pid": "f3cef657-1887-42a7-9e11-8fdf54f8fa90", "context": "Catastrophic forgetting may be a significant challenge in continual learning.", "key_idea": "The authors introduce a simple but effective variant of continual learning named kernel continual learning that leverages the non-parametric nature of kernel methods to tackle catastrophic forgetting. This method not requires memory replay and systematically avoids task interference in the classifiers.", "method": "The authors apply kernel continual learning on different tasks and evaluate results on four benchmarks.", "outcome": "Using kernel continual learning, more informative kernels specific to each task can be generated, and the coreset size can be reduced to achieve more compact memory, resulting in more efficient continual learning based on episodic memory. Kernel continual learning demonstrates the effectiveness and promise of kernels for continual learning on four benchmarks.", "future_impact": "N/A", "venue": null, "year": null, "title": "Kernel Continual Learning"}
{"pid": "f64fdfde-7e93-411b-865a-1e29d71c95b2", "context": "Large-scale topic models serve as basic tools for feature extraction and dimensionality reduction and hierarchical topic models (HTMs) are able to learn topics of different levels of abstraction. However, existing scalable systems for flat topic models cannot handle HTMs, due to their complicated data structures.", "key_idea": "The authors propose an efficient partially collapsed Gibbs sampling algorithm for hLDA, as well as an initialization strategy to deal with local optima introduced by tree-structured models. They further identify new system challenges in building scalable systems for HTMs, and propose efficient data layout.", "method": "The authors evaluate the proposed method on a 131-million-document corpus with 28 billion tokens, which is 4--5 orders of magnitude larger than previously used corpus.", "outcome": "Empirical studies show that the proposed system is 87 times more efficient than the previous open-source implementation for hLDA, and can scale to thousands of CPU cores. The distributed implementation is also scalable on a 131-million-document corpus with 28 billion tokens, extracting 1,722 topics from the corpus with 50 machines in just 7 hours.", "future_impact": "N/A", "venue": null, "year": null, "title": "Scalable training of hierarchical topic models"}
{"pid": "f64fdfde-7e93-411b-865a-1e29d71c95b2", "context": "Large-scale topic models serve as basic tools for feature extraction and dimensionality reduction in many practical applications. As a natural extension of flat topic models, hierarchical topic models (HTMs) are able to learn topics of different levels of abstraction, which lead to deeper understanding and better generalization than their flat counterparts. However, existing scalable systems for flat topic models cannot handle HTMs, due to their complicated data structures such as trees and concurrent dynamically growing matrices, as well as their susceptibility to local optima.", "key_idea": "Authors propose an efficient partially collapsed Gibbs sampling algorithm for hLDA, as well as an initialization strategy to deal with local optima introduced by tree-structured models. Authors also identify new system challenges in building scalable systems for HTMs, and propose efficient data layout for vectorizing HTM as well as distributed data structures including dynamic matrices and trees.", "method": "Authors setup experiments to compare the proposed method with  previous open-source implementation for hierarchical latent Dirichlet allocation (hLDA).", "outcome": "Empirical studies show that proposed system is 87 times more efficient than the previous open-source implementation for hLDA, and can scale to thousands of CPU cores. Authors demonstrate the scalability on a 131-million-document corpus with 28 billion tokens, which is 4--5 orders of magnitude larger than previously used corpus.", "future_impact": "N/A", "venue": null, "year": null, "title": "Scalable training of hierarchical topic models"}
{"pid": "f82f2e26-5437-4397-b781-50668ce5851b", "context": "In present Statistical Machine Translation (SMT) systems, alignment is trained in a previous stage as the translation model. Consequently, alignment model parameters are not tuned in function of the translation task, but only indirectly.", "key_idea": "The authors propose a novel framework for discriminative training of alignment models with automated translation metrics as maximization criterion.", "method": "The authors evaluate the proposed framework in terms of automatic translation evaluation metrics", "outcome": "The evaluation of the proposed framework in terms of automatic translation evaluation metrics shows an improvement of translation quality is observed.", "future_impact": "N/A", "venue": null, "year": null, "title": "Discriminative Alignment Training without Annotated Data for Machine Translation"}
{"pid": "f82f2e26-5437-4397-b781-50668ce5851b", "context": "Since in present Statistical Machine Translation (SMT) systems, alignment is trained in a previous stage as the translation model, so, alignment model parameters are not tuned in function of the translation task, but only indirectly.", "key_idea": "The authors propose a novel framework for discriminative training of alignment models with automated translation metrics as maximization criterion. ", "method": "The authors evaluate novel framework in terms of automatic translation evaluation metrics.", "outcome": "This method optimize alignments in translation task and no link labels at the word level are needed.\r\nAn improvement of translation quality is observed when evaluating novel framework in terms of automatic translation evaluation metrics.", "future_impact": "N/A", "venue": null, "year": null, "title": "Discriminative Alignment Training without Annotated Data for Machine Translation"}
{"pid": "fb538ce2-abf4-4bd8-b35c-1bfe3ab9f48e", "context": "The complex word identification task refers to the process of identifying difficult words in a sentence from the perspective of readers belonging to a specific target audience. Lexical simplification helps in improving the readability of texts consisting of challenging words.", "key_idea": "The author develops two systems using various lexical and semantic features to identify complex words, one using Naive Bayes and another based on Random Forest Classifiers.", "method": "The author tests the perfromance Naive Bayes classifier based system by incorporating rule based post-processing techniques and using G-score as an indicator.", "outcome": "The Naive Bayes classifier based system achieves the maximum G-score of 76.7% after incorporating rule based post-processing techniques.", "future_impact": "N/A", "venue": null, "year": null, "title": "JU_NLP at SemEval-2016 Task 11: Identifying Complex Words in a Sentence."}
{"pid": "feb75e1f-7838-48ca-9a78-cc31b717e5bf", "context": "Many business engaged in reputation management by using armies of accounts post reviews to influence a business\u2019 average review score. Unfortunately, most of previous work use supervised machine learning, and only focus on textual and stylometry features, and ground truth data they gained is not large and comprehensive .", "key_idea": "The authors propose a system for finding fraudulent content on a crowd-sourced review site named OneReview, leveraging correlations with other independent review sites, and the use of textual and contextual features. OneReview focuses on isolating anomalous changes in a business\u2019 reputation across multiple review sites, to locate malicious activity without relying on specific patterns. And it uses supervised machine learning, utilizing a combination of textual and metadata features to locate fraudulent reviews among the suspicious reviews. ", "method": "The authors evaluate OneReview approach with data from two reviewing websites, Yelp and TripAdvisor, to find fraudulent activity on Yelp. The authors obtain Yelp reviews through the Yelp Data Challenge and use our Change Point Analyzer to correlate this with data crawled from TripAdvisor. And finally use a combination of our change point analysis and crowd-labeling to create a set of 5,655 labeled reviews as evaluation dataset.", "outcome": "The authors used k-cross validation(k=5) on  ground truth and obtained 97% accuracy, 91% precision and 90% recall. Besides, authors use this model to identify 3,980 businesses with fraudulent reviews and 14,910 suspected spam, where at least 40% of their reviews are classified as fraudulent.", "future_impact": "N/A", "venue": null, "year": null, "title": "Lightning Talk - Think Outside the Dataset: Finding Fraudulent Reviews using Cross-Dataset Analysis"}
{"pid": "feb75e1f-7838-48ca-9a78-cc31b717e5bf", "context": "Many crowd-sourced review platforms, such as Yelp, TripAdvisor, and Foursquare, have sprung up to provide a shared space for people to write reviews and rate local businesses.  Some might also engage in reputation management, which could range from rewarding their customers for a favorable review, or a complex review campaign, where armies of accounts post reviews to influence a business\u2019 average review score.", "key_idea": "Authors propose OneReview , a system for finding fraudulent content on a crowd-sourced review site, leveraging correlations with other independent review sites, and the use of textual and contextual features. ", "method": "OneReview utilizes Change Point Analysis method on the reviews of every business independently on every website, and then uses our proposed Change Point Analyzer to evaluate change-points, detect those that do not match across the websites, and identify them as suspicious.  Then, it uses supervised machine learning, utilizing a combination of textual and metadata features to locate fraudulent reviews among the suspicious reviews.", "outcome": "Authors used k-cross validation (k=5) on our ground truth and obtained 97% (+/- 0.01) accuracy, 91% (+/- 0.03) precision and 90% (+/- 0.06) recall.\r\nOneReview identified 3,980 businesses with fraudulent reviews, as well as, 14,910 suspected spam, where at least 40% of their reviews are classified as fraudulent.", "future_impact": "N/A", "venue": null, "year": null, "title": "Lightning Talk - Think Outside the Dataset: Finding Fraudulent Reviews using Cross-Dataset Analysis"}
{"pid": "fed7302a-43a7-412e-8ace-d07905e38c3c", "context": "The bane of one-class collaborative filtering is interpreting and modelling the latent signal from the missing class. ", "key_idea": "Authors present a novel Bayesian generative model for implicit collaborative filtering. It forms a core component of the Xbox Live architecture, and unlike previous approaches, delineates the odds of a user disliking an item from simply being unaware of it. \r\nAuthors demonstrate how large-scale distributed learning can be achieved through a combination of stochastic gradient descent and mean field variational inference over random graph samples.", "method": "Authors design fine-grained comparison of the proposed method against a state of the art baseline on real world data..", "outcome": "The proposed method is better than state of the art baseline on real world data in fine-grained comparison.", "future_impact": "N/A", "venue": null, "year": null, "title": "One-class collaborative filtering with random graphs"}
